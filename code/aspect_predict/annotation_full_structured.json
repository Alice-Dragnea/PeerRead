[{"IMPACT": 2, "SUBSTANCE": 2, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper reframes feed forward neural networks as a multi-agent system. It seems to start from the wrong premise that multi-layer neural networks were created expressed as full matrix multiplications", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "718", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": 2, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The term strategy is a bit ambiguous. Could you please explain more in formal terms what is strategy? Is r the discounted Return at time t, or the reward at time t? Could the author compare the method", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "684", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": 1, "SUBSTANCE": 2, "CLARITY": 2, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "Unfortunately, the paper is not clear enough for me to understand what is being proposed. At a high-level the authors seem to propose a generalization of the standard layered neural architecture (of w", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "718", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": 3, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper proposes a neural network architecture for car state prediction while driving based on competitive learning. Competitive learning creates several duplicates of the baseline neural architect", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "785", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This work reframes paragraph vectors from a generative point of view and in so doing, motivates the existing method of inferring paragraph vectors as well as applying a L2 regularizer on the paragraph", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "732", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a neural network architecture and training procedure for predicting the speed of a vehicle several seconds into the future based on video and vehicle state input. The architectur", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "785", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 1, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "The authors apply the commonly used Fast RCNN detection system to pedestrian detection. They use EdgeBoxes object proposals and incorporate batch norm into their network. Results are shown on the INRI", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 1, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "766", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a maximum total correlation procedure, adds a target and then adds noise perturbations. Technical issues: The move from (1) to (2) is problematic. Yes it is a lower bound, but by", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "777", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is an incremental result (several related results that the authors of the paper mentioned here were already published). The authors claim that they can get rid of the technical assumptions from t", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "451", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "this paper proposes a model for representing unseen words in a neural language model. the proposed model achieves poor results in LM and a slight improvement over a baseline model. this work needs a m", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "685", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 4, "SUBSTANCE": 4, "CLARITY": 4, "MEANINGFUL_COMPARISON": 5, "COMMENTS": "The paper proposes a new criterion (sample importance) to study the impact of samples during the training of deep neural networks. This criterion is not clearly defined (the term \\phi^t_{i,j} is never", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "591", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 4, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary For several algorithms, previous research has shown that the halting time follows a two-parameter distribution (the so-called universal property investigated by the authors). In this work, the", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "743", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "this paper proposes to use feed-forward neural networks to learn similarity preserving embeddings. They also use the proposed idea to represent out-of-vocabulary words using the words in given context", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "756", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a new regularization technique for neural networks, which seeks to maximize correlation between input variables, latent variables and outputs. This is achieved by defining a measure", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": 4, "ID": "777", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper explores different strategies for instance-level image retrieval with deep CNNs. The approach consists of extracting features from a network pre-trained for image classification (e.g. VGG),", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "772", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": 4, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "The paper under consideration proposes a set of procedures for incrementally expanding a residual network by adding layers via a boosting criterion. The main barrier to publication is the weak empiric", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 1, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "683", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": 3, "SUBSTANCE": 1, "CLARITY": 4, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper aims at attacking the problem of preselecting deep learning model structures for new domains. It reported a series of experiments on various small tasks and feed-forward DNNs. It claims tha", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "555", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an extension of neural network language (NLM) models to better handle large vocabularies. The main idea is to obtain word embeddings by combining character-level embeddings with a ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "685", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": 3, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The authors propose two variational methods based on the theme of posterior approximations which may not have a tractable density. The first is from another ICLR submission on \"amortized SVGD\" (Wang a", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "641", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 1, "SUBSTANCE": 1, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The paper proposes a model that aims at learning to label nodes of graph in a semi-supervised setting. The idea of the model is based on the use of the graph structure to regularize the representation", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "661", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper investigates the hessian of small deep networks near the end of training. The main result is that many eigenvalues are approximately zero, such that the Hessian is highly singular, which me", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "623", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 1, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper addresses the problem of learning compact binary data representations. I have a hard time understanding the setting and the writing of the paper is not making it any easier. For example I ca", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "781", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "Summary === This paper presents tic-tac-toe as toy problem for investigating CNNs. A dataset is created containing tic-tac-toe boards where one player is one move away from winning and a CNN is traine", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "741", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper considers an alternate formulation of Kernel PCA with rank constraints incorporated as a regularization term in the objective. The writing is not clear. The focus keeps shifting from estima", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "735", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": 4, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper proposes a process to mine rules from vector space representations learned from KBs (using nonnegative RESCAL). The paper is nicely written. But its motivations are unclear: what is the und", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "637", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 2, "MEANINGFUL_COMPARISON": null, "COMMENTS": "UPDATE: I have read the authors' rebuttal and also the other comments in this paper's thread. My thoughts have not changed. The authors propose using a mixture prior rather than a uni-modal prior for ", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "706", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper proposes an algorithm for polynomial feature expansion on CSR matrices, which reduces the time complexity of the standard method by a factor d^k where d is the density of the sparse matrix.", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "739", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes combining different modalities of product content (e.g. review text, images, co-purchase info ...etc) in order to learn one unified product representation for recommender systems. ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "582", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a similarity encoder based on a standard feed-forward neural network with the aim of generating similarity-preserving embeddings. The approach is utilized to generate a simple ex", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "756", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 2, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Update: I thank the author for his comments! At this point, the paper is still not suitable for publication, so I'm leaving the rating untouched. This paper proposes a transfer learning method address", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "655", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper shows how spin glass techniques that were introduced in Choromanska et al. to analyze surface loss of deep neural networks can be applied to deep residual networks. This is an interesting c", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "622", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper summary: the authors proposed to use EdgeBoxes + Fast-RCNN with batch normalization for pedestrian detection Review summary: results do not cover enough datasets, the reported results do not imp", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "766", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper proposes to leverage \"surprisal\" as top-down signal in RNN. More specifically author uses the error corresponding to the previous prediction as an extra input at the current timestep in a L", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "793", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes to use a hierarchical softmax to speed up attention based memory addressing in memory augmented network (e.g. NTM, memNN). The model build a hierarchical softmax on top of the inpu", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "782", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "It is not clear to me at all what this paper is contributing. Deep CCA (Andrew et al, 2013) already gives the gradient derivation of the correlation objective with respect to the network outputs which", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "575", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper describes an approach to predict (unseen) future frames of a video given a set of known past frames. The approach is based on a CNN that, in contrast to most related papers, work in the spa", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "612", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper takes a model based on that of Graves and retrofits it with a representation derived from the work of Plamondon. part of the goal of deep learning has been to avoid the use of hand-crafted ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "581", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors have put forward a sincere effort to investigate the \"fundamental nature of learning representations in neural networks\", a topic of great interest and importance to our field. They propos", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "687", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes to prune a neural network by removing neurons whose operation is highly correlated with other neurons. The idea is nice and somewhat novel - most pruning methods concentrate on remo", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "695", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors argues that the standard ancestral sampling from stochastic autoencoders (such as the Variational Autoencoder and the Adversarial Autoencoder) imposes the overly-restrictive constraint tha", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "789", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "In the question response the authors mention and compare other works such as \"Learning to Learn by Gradient Descent by Gradient Descent\", but the goal of current work and that work is quite different.", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "767", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 1, "SUBSTANCE": 1, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The authors present methods to speed-up gradient descent by leveraging asynchronicity in a layer-wise manner. While they obtain up-to 1.7x speedup compared to synchronous training, their baseline is w", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "617", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 2, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes to use the representation learning approach of [Jonschkowski & Brock, 2015] with a deep network as function approximator. The general task and approach are interesting, but contribu", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 4, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "714", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The manuscript is a bit scattered and hard to follow. There is technical depth but the paper doesn't do a good job explaining what shortcoming the proposed methods are overcoming and what baselines th", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "574", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper proposes a new method, interior gradients, for analysing feature importance in deep neural networks. The interior gradient is the gradient measured on a scaled version of the input. The int", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "747", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents iterative PoWER, an off-policy variation on PoWER, a policy gradient algorithm in the reward-weighted family. I'm not familiar enough with this type lower bound scheme to comment o", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "688", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 1, "SUBSTANCE": 1, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "Authors investigate how to use pretrained CNNs for retrieval and perform an extensive evaluation of the influence of various parameters. For detailed comments on everything see the questions I posted ", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "772", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work proposes a convolutional architecture for any graph-like input data (where the structure is example-dependent), or more generally, any data where the input dimensions that are related by a s", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "609", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper proposes a boosting based ensemble procedure for residual networks by adopting the Deep Incremental Boosting method that was used for CNN's(Mosca & Magoulas, 2016a). At each step t, a new b", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "683", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper studies some special cases of neural networks and datasets where optimization fails. Most of the considered models and datasets are however highly constructed and do not follow the basic hyp", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "624", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The multiagent system is proposed as a generalization of neural network. The proposed system can be used with less restrictive network structures more efficiently by computing only those necessary com", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "718", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The authors propose methods for wild variational inference, in which the variational approximating distribution may not have a directly accessible density function. Their approach is based on the Stai", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "641", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": 2, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The authors introduce a semi-supervised method for neural networks, inspired from label propagation. The method appears to be exactly the same than the one proposed in (Weston et al, 2008) (the author", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "661", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "(paper summary) The authors introduce the notion of sample importance, meant to measure the influence of a particular training example on the training of a deep neural network. This quantity is closel", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "591", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "1029 tic-tac-toe boards are rendered (in various ways). These 1029 boards are legal boards where the next legal play can end the game. There are 18 categories of such boards -- 9 for the different loc", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "741", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 4, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This paper introduces CoopNets, an algorithm which trains a Deep-Energy Model (DEM, the descriptor) with the help of an auxiliary directed bayes net, e.g. the generator. The descriptor is trained via ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "633", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 1, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I find this paper extremely hard to read. The main promise of the paper is to train models for combinatorial search procedures, especially for dynamic programming to learn where to split and merge. Th", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "746", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 5, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors present here a new algorithm for the effective calculation of polynomial features on Sparse Matrices. The key idea is to use a proper mapping between matrices and their polynomial versions", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": 3, "APPROPRIATENESS": 2, "ID": "739", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": null, "SUBSTANCE": 1, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The paper presents a way to \"learn\" approximate data structures. They train neural networks (ConvNets here) to perform as an approximate abstract data structure by having an L2 loss (for the unrolled ", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 5, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "606", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 5, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The problem of utilizing all available information (across modalities) about a product to learn a meaningful \"joint\" embedding is an interesting one, and certainly seems like it a promising direction ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "582", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 2, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an idea of looking n-steps backward when modelling sequences with RNNs. The proposed RNN does not only use the previous hidden state (t-1) but also looks further back ( (t - k) ste", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "564", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper presents a method for embedding data instances into a low-dimensional space that preserves some form of similarity. Although the paper presents this notion as new, basically every pre-train", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "756", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "This paper proposes relation networks in order to model the pairwise interactions between objects in a visual scene. The model is very straight forward, first an MLP (with shared weights) is applied t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "530", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a multimodal neural machine translation that is based upon previous work using variational methods but attempts to ground semantics with images. Considering way to improve translat", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "627", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose to combine a CCA objective with a downstream loss. This is a really nice and natural idea. However, both the execution and presentation leave a lot to be desired in the current ver", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "575", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The paper proposes to enhance the attention mechanism for sentiment classification by using global context computed by a Bi-LSTM. The proposed models outperform many existing models in the literature ", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "692", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The paper presents a method for sequence generation with a known method applied to feature extracted from another existing method. The paper is heavily oriented towards to chosen technologies and lack", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "581", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 1, "SUBSTANCE": 1, "CLARITY": null, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "I did enjoy reading some of the introductions and background, in particular that of reminding readers of popular papers from the late 1980s and early 1990s. The idea of the proposal is straight forwar", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 1, "RECOMMENDATION": 1, "APPROPRIATENESS": 1, "ID": "687", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": 1, "SUBSTANCE": 1, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors analyze trained neural networks by quantifying the selectivity of individual neurons in the network for a variety of specific features, including color and category. Pros: * The paper is c", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 1, "RECOMMENDATION": 1, "APPROPRIATENESS": 1, "ID": "717", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper formulates a number of rules for designing convolutional neural network architectures for image processing and computer vision problems. Essentially, it reads like a review paper about moder", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "749", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 2, "SUBSTANCE": 1, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The authors explore the idea of deep-learning a static analyzer. They do it with a toy programming language and a very simplified analysis problem -- just checking if all variables are initalized. Whi", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 1, "APPROPRIATENESS": 1, "ID": "761", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The authors propose to sample from VAEs through a Markov chain [z_t ~ q(z|x=x_{t-1}), x_t ~ p(x|z=z_t)]. The paper uses confusing notation, oversells the novelty, ignoring some relevant previous resul", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "789", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "It feels that this paper is structured around a shortcoming of the original paragraph vectors paper, namely an alleged inability to infer representation for text outside of the training data. I am rea", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "732", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a new RL architecture that aims at learning policies from sketches i.e sequence of high-level operations to execute for solving a particular task. The model relies on a hierarchical", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": 3, "ID": "542", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 2, "SUBSTANCE": 2, "CLARITY": 5, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper implements the method of Jonschkowski & Brock to learn a low-dimensional state representation represented as the last layer of a neural network. The experiments apply the method for learnin", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 1, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "714", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 1, "SUBSTANCE": null, "CLARITY": 2, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "This paper introduces a pratical large-scale visual search system for a fashion site. It uses RNN to recognize multi-label attributes and uses state-of-art faster RCNN to extract features inside those", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "574", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 2, "SUBSTANCE": 2, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose to measure feature importance, or specifically, which pixels contribute most to a networks classification of an image. A simple (albeit not particularly effective) heuristic for me", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "747", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 2, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a simple method for constructing a visual hierarchy of ImageNet classes based on a CNN trained on discriminate between the classes. It investigates two metrics for measuring inter-c", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "561", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": 1, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper's aim is - as argued in the paper and the responses to other reviewers comments - that SPN and MPN can be interpreted as encoders and decoders of RL. Well - this is an interesting perspectiv", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 4, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "658", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "Previous literature uses data-derived adjacency matrix A to obtain neighbors to use as foundation of graph convolution. They propose extending the set of neighbors by additionally including nodes reac", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "609", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 1, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The authors propose a time-series model with discrete states for robotics applications. I think the proposed method is too simplistic to be useful in the presented form, eg. 1) the state space (dimens", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 1, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "551", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The method overall seems to be a very interesting structural approach to variational autoencoders, however it seems to lack motivation as well as the application areas sufficient to prove its effectiv", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "605", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The proposed approach consists in a greedy layer wise initialization strategy for a deep MLP model, which is followed by global gradient-descent with dropout for fine-tuning. The initialization strate", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "700", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 2, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper describes a method that estimates the similarity between a set of images by alternatively attend each image with a recurrent manner. The idea of the paper is interesting, which mimic the hu", "SOUNDNESS_CORRECTNESS": 1, "ORIGINALITY": 4, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "569", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 1, "CLARITY": 1, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this work, the authors propose to use a (perhaps deterministic) retrieval function to replace uniform sampling over the train data in training the discriminator of a GAN. Although I like the basic ", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 4, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "616", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": 5, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper investigates the use of eligibility traces with recurrent DQN agents. As in other recent work on deep RL, the forward view of Sutton and Barto is used to make eligibility traces practical t", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "554", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 2, "SUBSTANCE": 2, "CLARITY": 2, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The paper proposes two methods for what is called wild variational inference. The goal is to obtain samples from the variational approximate distribution q without requiring to evaluate the density q(", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "641", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "Inspired by the analysis on the effect of the co-label similarity (Hinton et al., 2015), this paper proposes a soft-target regularization that iteratively trains the network using weighted average of ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "792", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": 1, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper proposes a new kind of expert model where a sparse subset of most reliable experts is chosen instead of the usual logarithmic opinion pool of a PoE. I find the paper very unclear. I tried t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "781", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Game of tic-tac-toe is considered. 1029 tic-tac-toe board combinations are chosen so that a single move will result into victory of either the black or the white player. There are 18 possible moves - ", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "741", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "*** Paper Summary *** The paper proposes to learn a predictive model (aka predict the next video frames given an input image) and uses the prediction from this model to improve a supervised classifier", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "513", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a theoretical and empirical approach to the problem of understanding the expressivity of deep networks. Random networks (deep networks with random Gaussian weights, hard tanh or Re", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "742", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper is beyond my expertise. I cannot give any solid review comments regarding the techniques that are better than an educated guess. However, it seems to me that the topic is not very relevant t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 1, "ID": "739", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": 2, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper tries to leverage an external lexicon / knowledge base to improve corpus-based word representations by determining (in a fuzzy way) which potential paraphrase is the most appropriate in a p", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "771", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 4, "SUBSTANCE": 2, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work proposes to use basic probability assignment to improve deep transfer learning. A particular re-weighting scheme inspired by Dempster-Shaffer and exploiting the confusion matrix of the sourc", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 4, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "655", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduces a lightweight network for semantic segmentation that combines several acceleration ideas. As indicated in my preliminary question, the authors do not make the case about why any o", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "716", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 1, "SUBSTANCE": 1, "CLARITY": 5, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper presents experimental results from an EdgeBoxes + Fast R-CNN detector on the task of localizing pedestrians. It uses an AlexNet (CaffeNet) backbone architecture modified to include batch no", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "766", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I have problems understanding the motivation of this paper. The authors claimed to have captured a latent representation of text and image during training and can translate better without images at te", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "627", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "This paper proposes to use previous error signal of the output layer as an additional input to recurrent update function in order to enhance the modelling power of a dynamic system such as RNNs. -This", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "793", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The authors did not bother responding or fixing any of the pre-review comments. Hence I repeat here: Please do not make incredibly unscientific statements like this one: \"The working procedure of this", "SOUNDNESS_CORRECTNESS": 1, "ORIGINALITY": null, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "692", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": 2, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper develops a theoretical guarantee for the convergence of the training error. The result is quite general that covers the training of a wide range of neural network models. The key idea of th", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 4, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "526", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper has no machine learning algorithmic contribution: it just uses the the same combination of LSTM and bivariate mixture density network as Graves, and the detailed explanation in the appendix", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 1, "APPROPRIATENESS": 1, "ID": "581", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "First up, I want to point out that this paper is really long. Like 17 pages long -- without any supplementary material. While ICLR does not have an official page limit, it would be nice if authors put", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "675", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduces a new pruning method for neural networks based on the second-order Taylor expansion and compares the results against a first-order method and brute-force pruning. It performs expe", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "687", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 5, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "this work investigates a joint learning setup where tasks are stacked based on their complexity. to this end, experimental evaluation is done on pos tagging, chunking, dependency parsing, semantic rel", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "584", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "Approximating solutions to PDEs with NN approximators is very hard. In particular the HJB and HJI eqs have in general discontinuous and non-differentiable solutions making them particularly tricky (un", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 1, "APPROPRIATENESS": 1, "ID": "511", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 5, "SUBSTANCE": 4, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors have grouped recent work in convolutional neural network design (specifically with respect to image classification) to identify core design principles guiding the field at large. The 14 pr", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "749", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The authors are trying to understand whether static analysis can be learned. As I hinted in my question, I think that all of the interesting complexity of static analysis has been removed in the toy l", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "761", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper attempts to learn a Markov chain to estimate a probability distribution over latent variables Z, such that P(X | Z) can be eased to generate samples from a data distribution. The paper in i", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "789", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work investigates the performance of transfer learning from resource-rich setup (BookTest, CNN/Daily Mail corpora) to low-resource (bAbI, SQuAD benchmarks) settings. Experiments show poor improve", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "678", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 5, "SUBSTANCE": 2, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a hierarchical DRL algorithm that solves sequences of navigate-and-act tasks in a 2D maze domain. During training and evaluation, a list of sub-goals represented by text is given to", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "625", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper is relatively difficult to parse. Much of the exposition of the proposed algorithm could be better presented using pseudo-code describing the compute flow, or a diagram describing exactly h", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "617", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 2, "SUBSTANCE": 2, "CLARITY": 2, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "This paper proposed to use unsupervised learning to learn features in a reinforcement learning setting. It is unclear what \"unsupervised\" means here since the \"causality prior\" uses reward signals for", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "714", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 2, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "Some of the key details in this paper are very poorly explained or not even explained at all. The model sounds interesting and there may be something good here, but it should not be published in it's ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "508", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The proposed method of modeling multimodal datasets is a VAE with an inference network for every combination of missing and present modalities. The method is evaluated on modeling MNIST and CelebA dat", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "672", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 2, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a variational autoencoder for a specific form of tree-generating model. The generative model for trees seems reasonable but is not fully motivated. If no previous references sugges", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "605", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 2, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a pedestrian detection method using Fast RCNN framework with batch normalization, where EdgeBoxes is used to collect pedestrian proposals instead of selective search as used in the", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "766", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper shows a different approach to a ternary quantization of weights. Strengths: 1. The paper shows performance improvements over existing solutions 2. The idea of learning the quantization inste", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": 1, "APPROPRIATENESS": 1, "ID": "369", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "The authors attempt to extract analytical equations governing physical systems from observations - an important task. Being able to capture succinct and interpretable rules which a physical system fol", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "546", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work describes 1: a two stage encoding of stories in bAbI like setups, where a GRU is used to encode a sentence, word by word, conditioned on a sentence level GRU, and the sentence level GRU keep", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "646", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 2, "SUBSTANCE": 1, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces an additional reward-predicting head to an existing NN architecture for video frame prediction. In Atari game playing scenarios, the authors show that this model can successfully", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "765", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I like this paper in that it is a creative application of computer vision to Biology. Or, at least, that would be a good narrative but I'm not confident biologists would actually care about the \"Tree ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "561", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an approach to unsupervised learning based on a modification to sparse coding that allows for explicit modeling of transformations (such as shift, rotation, etc.), as opposed to si", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "721", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper addresses an important and timely topic in a creative way. I consider it to have three flaws (and one good idea). 1) insufficient context of what is known and had been studied before (in sh", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "751", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper propose a new evaluation metric for dialogue systems, and show it has a higher correlation with human annotation. I agree the MT based metrics like BLEU are too simple to capture enough sem", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "502", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 1, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The paper considers Grassmannian SGD to optimize the skip gram negative sampling (SGNS) objective for learning better word embeddings. It is not clear why the proposed optimization approach has any ad", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 1, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "697", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: -------- The authors propose a histogram based state representation with differentiable motion models and observation updates for state tracking from observations. Linear model with Gaussian ", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "551", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper proposes Generative Adversarial Parallelization (GAP), one schedule to train N Generative Adversarial Networks (GANs) in parallel. GAP proceeds by shuffling the assignments between the N ge", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "562", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a novel extension of the variational autoencoder to arbitrary tree-structured outputs. Experiments are conducted on a synthetic arithmetic expression dataset and a first-order lo", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "605", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors pointed out some limitations of existing deep architectures, in particular hard to optimize on small or mid size datasets, and proposed to stack marginal fisher analysis (MFA) to build dee", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "700", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 2, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The paper proposes an approach to sequence transduction for the case when a monotonic alignment between the input and the output is plausible. It is assumed that the alignment can be provided as a par", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "659", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose amortized SVGD, an amortized form of prior work on SVGD, which is a particle variational method that maximally decreases the KL divergence at each update. \"amortized SVGD\" is done ", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "518", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The findings of applying sparsity in the backward gradients for training LSTMs is interesting. But the paper seems incomplete without the proper experimental justification. Only the validation loss is", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "738", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Unfortunately, even after reading the authors' response to my pre-review question, I feel this paper in its current form lacks sufficient novelty to be accepted to ICLR. Fundamentally, the paper sugge", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 2, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "647", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an approach to modeling videos based on a decomposition into a background + 2d sprites with a latent hidden state. The exposition is OK, and I think the approach is sensible, but t", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": 2, "ID": "531", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 1, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "I have not read the revised version in detail yet. SUMMARY This paper studies the preimages of outputs of a feedforward neural network with ReLUs. PROS The paper presents a neat idea for changes of co", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "626", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a system approach to combine multiple modalities to perform classification in a practical scenario (e-commerce). In general, I find the proposed approach in the paper sound and sol", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "663", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This manuscript tries to tackle neural network regularization by blending the target distribution with predictions of the model itself. In this sense it is similar in spirit to scheduled sampling (Ben", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "792", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper provides two RNN-based architectures for extractive document summarization. The first, \"Classify\", reads in the whole document and traverses the sentences a second time to decide whether to", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "702", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed to use GAN for encrypted communications. In section 2, the authors proposed a 3 part neural network trained to encode and decode data. This model does not have any practical value ", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "790", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": 2, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This submission introduces a formulation of Generative Adversarial Networks (GANs) under the lens of density ratio estimation, when using Bregman divergences. Even thought GANs already perform density", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "563", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 5, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "ResNet and other architectures that use shortcuts have shown empirical success in several domains and therefore, studying the optimization for such architectures is very valuable. This paper is an att", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "755", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents extensions to previous work using embeddings for modeling Knowledge Bases and performing Q&A on them, centered around the use of multivariate gaussian likelihood instead of inner p", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "632", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "Summary: The paper presents an approach Neural Answer Construction Model for the task of answering non-factoid questions, in particular, love-advice questions. The two main features of the proposed mo", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "570", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": 4, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The authors of this work propose a learnable approach to reducing the dimensionality of learned filters in deep neural networks. This is an interesting approach, but the presented work looks a bit raw", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "666", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper evaluates recent development in competitive ILSVRC CNN architectures from the perspective of resource utilization. It is clear that a lot of work has been put into the evaluations. The findi", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "690", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The authors proposes an interesting idea of connecting the energy-based model (descriptor) and the generator network to help each other. The samples from the generator are used as the initialization o", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "633", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "The basic idea of this contribution is very nice and worth pursuing: how to use the powerful divide and conquer algorithm design strategy to learn better programs for tasks such as sorting or planar c", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "746", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this paper, the author analyzes the convergence dynamics of a single layer non-linear network under Gaussian iid input assumptions. The first half of the paper, dealing with a single hidden node, w", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "522", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper proposes a multiview learning approach to finding dependent subspaces optimized for maximizing cross-view similarity between neighborhoods of data samples. The motivation comes from informa", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "567", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "I find this paper not very compelling. The basic idea seems to be that we can put a fast neighbor searcher into a memory augmented net to make the memory lookups scalable. However, this was precisely ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "673", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 5, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a novel method for accelerating optimization near saddle points. The basic idea is to repel the current parameter vector from a running average of recent parameter values. This met", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "548", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The paper presents a framework to formulate data-structures in a learnable way. It is an interesting and novel approach that could generalize well to interesting datastructures and algorithms. In its ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "606", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 3, "SUBSTANCE": 5, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper addresses automated argumentation mining using pointer network. Although the task and the discussion is interesting, the contribution and the novelty is marginal because this is a single-ta", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "604", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a method to investigate the predictiveness of intermediate layer activations. To do so, they propose training linear classifiers and evaluate the error on the test set. The paper i", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "577", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a \"hierarchical\" attention model for video captioning. They introduce a model composed of three parts: the temporal modeler (TEM) that takes as input the video sequence and outputs", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "607", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors of the paper explore the idea of incorporating skip connections *over time* for RNNs. Even though the basic idea is not particularly innovative, a few proposals on how to merge that inform", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "564", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": 4, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "A layer wise optimization for CNNs with ReLU activations and max-pooling is proposed and shown to correspond to a series of latent structured SVM problems. Using CCCP style optimization a monotonic de", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "412", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper summary: this work presents ENet, a new convnet architecture for semantic labeling which obtains comparable performance to the previously existing SegNet while being ~10x faster and using ~10x l", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "716", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper proposes a character-aware attention residual network for sentence embedding. Several text classification tasks are used to evaluate the effectiveness of the proposed model. On two of the t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "568", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper propose a parallel mechanism for stochastic gradient descent method (SGD) in case of gradient can be computed via linear operations (including least square linear regression and polynomial ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "745", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a setting to learn models that will seek information (e.g., by asking question) in order to solve a given task. They introduce a set of tasks that were designed for that goal. They", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "573", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes an approach to the task of multimodal machine translation, namely to the case when an image is available that corresponds to both source and target sentences. The idea seems to be t", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "627", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper summary: This work proposes a new algorithm to generate k-adversarial images by modifying a small fraction of the image pixels and without requiring access to the classification network weight. ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "708", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "This paper presents a simple method of adding gradient noise to improve the training of deep neural networks. This paper first appeared on arXiv over a year ago and while there have been many innovati", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 1, "APPROPRIATENESS": 1, "ID": "619", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper describes an end-to-end system for speech recognition that uses a linear conditional random field framework. A convnet estimates node potentials, while transition scores are provided by tra", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "598", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper proposes to reduce model size and evaluation time of deep CNN models on mobile devices by converting multiple layers into single layer and then retraining the converted model. The paper sho", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "587", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "Overview: This work seems very promising, but I believe it should be compared with more baselines, and more precisely described and explained, from a signal processing point of view. Pros: New descrip", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "681", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This paper introduces a variant of the neural Turing machine (NTM, Graves et al. 2014) where key and values are stored. They try both continuous and discrete mechanisms to control the memory. The mode", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "662", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper presents a hierarchical attention-based method for document classification. The main idea is to first run a bidirectional LSTM to get global context vector, and then run another attention-b", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "692", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The author proposes the use of low-rank matrix in feedfoward and RNNs. In particular, they try their approach in a GRU and a feedforward highway network. Author also presents as a contribution the pas", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "594", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "Update: I thank the authors for their comments. I still think that the method needs more experimental evaluation: for now, it's restricted to the settings in which one can use pre-trained ImageNet mod", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "736", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": 1, "CLARITY": 5, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "* Brief Summary: This paper explores an extension of multiplicative RNNs to the LSTM type of models. The resulting proposal is very similar to [1]. Authors show experimental results on character-level", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "527", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "- Proven again that end to end training with deep networks gives large gains over traditional hybrid systems with hand crafted features. The results are very nice for the small vocabulary grammar task", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "694", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper aims to characterize the perceptual ability of a neural network under different input conditions. This is done by manipulating the input image x in various ways (e.g. downsamplig, foveating", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "762", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": 5, "COMMENTS": "The authors take on the task of figuring out a set of design patterns for current deep architectures - namely themes that are recurring in the literature. If one may say so, a distributed representati", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "749", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 5, "COMMENTS": "1) Summary This paper proposes an end-to-end hybrid architecture to predict the local linear trends of time series. A temporal convnet on raw data extracts short-term features. In parallel, long term ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "579", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes to provide a theoretical explanation for why deep convolutional neural networks are invertible (at-least, when going back from certain intermediate layers to the image itself). It d", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 4, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "674", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 4, "SUBSTANCE": 2, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper takes a first step towards learning to statically analyze source code. It develops a simple toy programming language that includes loops and branching. The aim is to determine whether all v", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "761", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper is dedicated to better understanding the optimization landscape in deep learning, in particular when explored with different optimization algorithms, and thus it also characterizes the behav", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "556", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a study of transfer learning in the context of QA from stories. A system is presented with a a short story and has to answer a question about it. This paper studies how a system tr", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "678", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The paper presents an approach to learning shared neural representations of temporal abstractions in hierarchical RL, based on actor-critic methods. The approach is illustrated in two tasks: gridworld", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "542", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Description: This paper presents a reinforcement learning architecture where, based on \"natural-language\" input, a meta-controller chooses subtasks and communicates them to a subtask controller that c", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "625", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper addresses an important problem - namely on how to improve diversity in responses. It is applaudable that the authors show results on several tasks showing the applicability across different ", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "644", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "A method for click prediction is presented. Inputs are a categorical variables and output is the click-through-rate. The categorical input data is embedded into a feature vector using a discriminative", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "720", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 1, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a repurposing of rectified factor networks proposed earlier by the same authors to biclustering. The method seems potentially quite interesting but the paper has serious problems in", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "773", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This manuscript proposes an approach for modeling correlated timeseries through a combination of loss functions which depend on neural networks. The loss functions correspond to: data fit term, autore", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "763", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors show how the hidden states of an LSTM can be normalised in order to preserve means and variances. The methods gradient behaviour is analysed. Experimental results seem to indicate that the", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "519", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "The work introduced a new form of regularization for denoising autoencoders, which explicitly enforces robustness in the encoding phrase w.r.t. input perturbation. The author motivates the regularizat", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "550", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper investigates the modeling of graph sequences . Authors propose Graph Convolutional Recurrent Networks (GRCN) that extends convLSTM (Shi et al. 2015) for data having an unregular graph struc", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "589", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": 3, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This paper presented an unsupervised approach for the automatic segmentation of bioacoustic data. The authors applied an existing approach (Hierarchical Dirichlet Process Hidden Markov Models) to thei", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "710", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "The paper starts by pointing out the need for methods that perform both state and temporal representation learning for RL and which allow gaining insight into what is being learned (perhaps in order t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "728", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 2, "SUBSTANCE": 1, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper discusses recurrent networks with an update rule of the form h_{t+1} = R_x R h_{t}, where R_x is an embedding of the input x into the space of orthogonal or unitary matrices, and R is a sha", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "552", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 1, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The paper proposes a new second-order method L-SR1 to train deep neural networks. It is claimed that the method addresses two important optimization problems in this setting: poor conditioning of the ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "615", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper proposes a model-based reinforcement learning approach focusing on predicting future rewards given a current state and future actions. This is achieved with a \"residual recurrent neural net", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 3, "APPROPRIATENESS": 3, "ID": "684", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors extend their method of causal discovery (Chalupka et al 2016) to include assumptions about sparsity via regularization. They apply this extension to an interesting private dataset from Sut", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "613", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 4, "SUBSTANCE": 2, "CLARITY": 5, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The topic of the paper, model-based RL with a learned model, is important and timely. The paper is well written. I feel that the presented results are too incremental. Augmenting the frame prediction ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "765", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "The paper introduces supervised deep learning with layer-wise reconstruction loss (in addition to the supervised loss) and class-conditional semantic additive noise for better representation learning.", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "777", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 2, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a hierarchical clustering method using learned CNN features to build 'the tree of life'. The assumption is that the feature similarity indicates the distance in the tree. The aut", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "561", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 5, "COMMENTS": "Summary: This paper presents a differentiable histogram filter for state estimation/tracking. The proposed histogram filter is a particular Bayesian filter that represents the discretized states using", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "551", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes to address the mode collapsing problem of GANs by training a large set of generators and discriminators, pairing them each up with different ones at different times throughout trai", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "562", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes to initialize the weights of a deep neural network layer-wise with a marginal Fisher analysis model, making use of potentially the similarity metric. Pros: There are a lot of exper", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "700", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces an attention-based recurrent network that learns to compare images by attending iteratively back and forth between a pair of images. Experiments show state-of-the-art results on ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "569", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper considers the energy-based model interpretation of GAN, where the discriminator is an unnormalized model for the likelihood of a generative model p(x|theta) and the generator is a directed ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "518", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "CONTRIBUTIONS When training LSTMs, many of the intermediate gradients are close to zero due to the flat shape of the tanh and sigmoid nonlinearities far from the origin. This paper shows that rounding", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "738", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "In this submission, an interesting approach to character-based language modeling is pursued that retains word-level representations both in the context, and optionally also in the output. However, the", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "685", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a method of augmenting pre-trained networks for one task with an additional inference path specific to an additional task, as a replacement for the standard fine-tuning approach. P", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "701", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper proposes a generative model of videos composed of a background and a set of 2D objects (sprites). Optimization is performed under a VAE framework. The authors' proposal of an outer product ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "531", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: This paper looks at the structure of the preimage of a particular activity at a hidden layer of a network. It proves that any particular activity has a preimage of a piecewise linear set of s", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "626", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduced a regularization scheme through soft-target that are produced by mixing between the true hard label and the current model prediction. Very similar method was proposed in Section 6", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "792", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents two RNN architectures for extractive document summarization. The first one, Classifier, takes into account the order in which sentences appear in the original document, whereas the", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "702", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents the semantic embedding model for multi-label prediction. In my questions, I pointed that the proposed approach assumes the number of labels to predict is known, and the authors said", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "787", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "This paper presents a meta-learning algorithm which learns to learn generative models from a small set of examples. Its similar in structure to the matching networks of Vinyals et al. (2016), and is t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "693", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Studying the Hessian in deep learning, the experiments in this paper suggest that the eigenvalue distribution is concentrated around zero and the non zero eigenvalues are related to the complexity of ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "623", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I think the write-up can be improved. The results of the paper also might be somewhat misleading. The behavior for when weights are 0 is not revealing of how the model works in general. I think the wo", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "755", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper describes an extension of the HasheNets work, with several novel twists. Instead of using a single hash function, the proposed HFH approach uses multiple hash function to associate each \"vir", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "686", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a neural architecture for answering non-factoid questions. The author's model improves over previous neural models for answer sentence selection. Experiments are conducted on a Jap", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "570", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a regularization technique for k-shot learning based on orthogonal grouping of units in a neural network. The units within a group are forced to be maximally similar, at the same t", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "666", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes an alternative to conditional max. log likelihood for training discriminative classifiers. The argument is that the conditional log. likelihood is an upper bound of the Bayes error ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "493", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors did solid work in collecting all the reported data. However, most findings don't seem to be too surprising to me: - Finding #1 mainly shows that all architectures and batch sizes manage to", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "690", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors proposed an way to measure the generation of out-of-distribution novelty. Their methods implied, if a model trained on MNIST digits could generate some samples are more like letters judged", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "583", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a new reinforcement learning environment called The Retro Learning Environment, that interfaces with the open-source LibRetro API to offer access to various emulators and associa", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "691", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper aims to mine explicit rules from KB embedding space, and casts it into a sparse reconstruction problem. Experiments demonstrate its ability of extracting reasonable rules on a few link pred", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "637", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper is an extension of Lenc&Vedaldi15 paper, showing CNN representations at FC7 layer are to certain extent equivariant to various classes of transformations and that training with a certain gr", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "578", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors develop a way learn subspaces of multiple views such that data point neighborhoods are similar in all of the views. This similarity is measured between distributions of neighbors in pairs ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "567", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper addresses video captioning with a TEM-HAM architecture, where a HAM module attends over attended outputs of the TEM module when generating the description. This gives a kind of 2-level atte", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "607", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a generative model for binary images. Images are composed by placing a set of binary features at locations in the image. These features are OR'd together to produce an image. In a ", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "760", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This paper studies the problem of source code completion using neural network models. A variety of models are presented, all of which are simple variations on LSTMs, adapted to the peculiarities of th", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "603", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed to use the BPA criterion for classifier ensembles. My major concern with the paper is that it attempts to mix quite a few concepts together, and as a result, some of the simple not", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "655", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors apply the image captioning architecture of Xu et al. 2015 to video captioning. The model is extended to have attention over multiple layers of the ConvNet instead of just a single layer. E", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "535", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I reviewed the manuscript as of December 6th. The authors perform a systematic investigation of various retraining methods for making a classification network robust to adversarial examples. The autho", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "610", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a new neural network model for sentence representation. This new model is inspired by the success of residual network in Computer Vision and some observation of word morphology in ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "568", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Overall, the idea in this paper is interesting and the paper is well-written and well-motivated. However, I think it is not ready to publish in ICLR for the following reasons: - This paper is not rela", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": 2, "ID": "745", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this paper, the authors present several strategies to select a small subset of target vocabulary to work with per source sentence, which results in significant speedup. The results are convincing a", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": 2, "ID": "779", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a method to generate adversarial examples w/o relying on knowledge of the network architecture or network gradients. The idea has some merit, however, as mentioned by one of the re", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "708", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": 4, "CLARITY": 4, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The authors consider a simple optimization technique consisting of adding gradient noise with a specific schedule. They test their method on a number of recently proposed neural networks for simulatin", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "619", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: This paper proposes to use surprisal-driven feedback for training recurrent neural networks where they feedback the next-step prediction error of the network as an input to the network. Autho", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "793", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper discusses multi-sense embedddings and proposes learning those by using aligned text across languages. Further, the paper suggests that adding more languages helps improve word sense disambi", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "640", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "One of the main idea of this paper is to replace pooling layers with convolutions of stride 2 and retraining the model. Authors merge this into a new layer and brand it as a new type of layer. This is", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "587", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper attempts to combine Variational Auto-Encoders with the Stick-Breaking process. The motivation is to tackle the component collapsing and have a representation with stochastic dimensionality. ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "470", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an extension of the multiplicative RNN [1] where the authors apply the same reparametrization trick to the weight matrices of the LSTM. The paper proposes some interesting tricks, ", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "527", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper analyzes dependency trees vs standard window contexts for word vector learning. While that's a good goal I believe the paper falls short of a thorough analysis of the subject matter. It doe", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "649", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper develops Submodular Sum Product Networks (SSPNs) and an efficient inference algorithm for approximately computing the most probable labeling of variables in the model. The main application ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "628", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I do not feel very qualified to review this paper. I studied digital logic back in university, that was it. I think the work deserves a reviewer with far more sophisticated background in this area. It", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "703", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "For more than a decade, near data processing has been a key requirement for large scale linear learning platforms, as the time to load the data exceeds the learning time, and this has justified the in", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": 2, "ID": "553", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "UPDATE: I have read the authors' responses. I did not read the social media comments about this paper prior to reviewing it. I appreciate the authors' updates in response to the reviewer comments. Ove", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "694", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The responses to the pre-review questions are not strong; especially w.r.t. the question about dataset density and why the dataset had to be subsampled, the authors responded that subsampling is commo", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "611", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: In this paper, the authors explore the advantages/disadvantages of using a sin activation function. They first demonstrate that even with simple tasks, using sin activations can result in com", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "608", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Because the authors did not respond to reviewer feedback, I am maintaining my original review score. ----- This paper proposes to model relational (i.e., correlated) time series using a deep learning-", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "763", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 1, "SUBSTANCE": 2, "CLARITY": 2, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The authors address the problem of modeling temporally-changing signal on a graph, where the signal at one node changes as a function of the inputs and the hidden states of its neighborhood, the size ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "589", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The paper proposes the group sparse autoencoder that enforces sparsity of the hidden representation group-wise, where the group is formed based on labels (i.e., supervision). The p-th group hidden rep", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "600", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "My main objection with this work is that it operates under a hypothesis (that is becoming more and more popular in the literature) that all we need is to have gradients flow in order to solve long ter", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "552", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper proposes a new approach to model based reinforcement learning and evaluates it on 3 ATARI games. The approach involves training a model that predicts a sequence of rewards and probabilities", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "684", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an \"interactive\" version of the bAbI dataset by adding supporting questions/answers to the dataset in cases where there is not enough information to answer the question. Interactiv", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "646", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": 4, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper extends a recently proposed video frame prediction method with reward prediction in order to learn the unknown system dynamics and reward structure of an environment. The method is tested on", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "765", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Final review: The writers were very responsive and I agree the reviewer2 that their experimental setup is not wrong after all and increased the score by one. But I still think there is lack of experim", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "532", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "A new sparse coding model is introduced that learns features jointly with their transformations. It is found that inference over per-image transformation variables is hard, so the authors suggest tyin", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "721", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "- The topic of keeping around highly rewarding or dangerous states is important and has been studied extensively in the RL literature. After the pre-review comments, authors do mention that they compa", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "751", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a generative model for mixtures of basic local structures where the dependency between local structures is a tensor. They use tensor decomposition and the result of their earlier p", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "689", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The authors mention that they are not aiming to have SOTA results. However, that an ensemble of resnets has lower performance than some of single network results, indicates that further experimentatio", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "683", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes two pruning methods to reduce the computation of deep neural network. In particular, whole feature maps and the kernel connections can be removed with not much decrease of classifi", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "715", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The proposed regularizer seems to be a particular combination of existing methods. Though the implied connection between nonlinearities and stochastic regularizers is intriguing, in my opinion the emp", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "651", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an extension of the GAN framework known as GAP whereby multiple generators and discriminators are trained in parallel. The generator/discriminator pairing is shuffled according to ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "562", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The topic is very interesting, but the paper is not convincing. Specifically, the experiment part is weak. The study should include datasets that are familiar to the community as well as the ones \"tha", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "555", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an amortized version of the Stein variational gradient descent (SVGD) method in which \"a neural network is trained to mimic the SVGD dynamics\". It applies the method to generative ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "518", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper presents a generative model of video sequence data where the frames are assumed to be generated by a static background with a 2d sprite composited onto it at each timestep. The sprite itsel", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "531", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I really appreciate the directions the authors are taken and I think something quite interesting can come out of it. I hope the authors continue on this path and are able to come up with something qui", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "626", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This paper proposes the Neural Graph Machine that adds in graph regularization on neural network hidden representations to improve network learning and take the graph structure into account. The propo", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "661", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a semantic embedding based approach to multilabel classification. Conversely to previous proposals, SEM considers the underlying parameters determining the observed labels are low-r", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "787", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper analyzes the properties of the Hessian of the training objective for various neural networks and data distributions. The authors study in particular, the eigenspectrum of the Hessian, which ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "623", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "SUMMARY. The paper propose a new scoring function for knowledge base embedding. The scoring function called TransGaussian is an novel take on (or a generalization of) the well-known TransE scoring fun", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "632", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper extends mostly on top of the work of QA-biLSTM and QA-biLSTM with attentions, as proposed in Tan et al. 2015 and Tan et al. 2016, in the following 2 ways: 1. It trains a topic-specific word", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "570", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a k-shot learning framework that can be used on existing pre-trained networks by grouping filters that produce similar activations. The grouped filters are learned together to addr", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "666", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an approach to non-linear kernel dimensionality reduction with a trace norm regularizer in the feature space. The authors proposed an iterative minimization approach in order to ob", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "735", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The paper tries to present a first step towards solving the difficult problem of \"learning from limited number of demonstrations\". The paper tries to present 3 contributions towards this effort: 1. un", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "504", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a nice idea of directly finding rules such as brother(father) => uncle in knowledge bases, by directly searching in embedding space. The idea is to interpret the successive applicat", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "637", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I was holding off on this review hoping to get the missing details from the code at", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "746", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This paper uses an LSTM model to predict what it calls \"open bigrams\" (bigrams of characters that may or may not have letters inbetween) from handwriting data. These open bigrams are subsequently used", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "723", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a convergence analysis of some two-layer NNs with ReLUs. It is not the first such analysis, but maybe it is novel on the assumptions used in the analysis, and the focus on ReLU nonl", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "522", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper empirically studies the invariance, equivariance and equivalence properties of representations learned by convolutional networks under various kinds of data augmentation. Additional loss te", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "578", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": 2, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a piecewise constant parameterisation for neural variational models so that it could explore the multi-modality of the latent variables and develop more powerful neural models. The", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "706", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper presents an multi-view learning algorithm which projects the inputs of different views (linearly) such that the neighborhood relationship (transition probabilities) agree across views. This", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "567", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Authors propose a competitive learning architecture that learn different RNN predictors independently, akin to a committee of experts which are chosen with a hard switch at run-time. This work is appl", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "785", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The research direction taken by this paper is of great interest. However, the empirical results are not great enough to pay for the weaknesses of the proposed approach (see Section 6). \"Throughout thi", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "548", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "A method for training neural networks to mimic abstract data structures is presented. The idea of training a network to satisfy an abstract interface is very interesting and promising, but empirical s", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "606", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose \"information dropout\", a variation of dropout with an information theoretic interpretation. A dropout layer limits the amount of information that can be passed through it, and the ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "726", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper basically applies A3C to 3D spatial navigation tasks. - This is not the first time A3C has been applied to 3D navigation. In fact the original paper reported these experiments. Although the", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "355", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes to use a linear classifier as the probe for the informativeness of the hidden activations from different neural network layers. The training of the linear classifier does not affec", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "577", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes an attention-based approach for video description. The approach uses three LSTMs and two attention mechanisms to sequentially predict words from a sequence of frames. In the LSTM-en", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "607", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a model for video captioning with both soft and hard attention, using a C3D network for the encoder and a RNN for the decoder. Experiments are presented on YouTube2Text, M-VAD, and", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "535", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a new model for sentence classification. Pros: - Some interesting architecture choices in the network. Cons: - No evaluation of the architecture choices. An ablation study is criti", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "568", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a new kind of generative model based on an annealing process, where the transition probabilities are learned directly to maximize a variational lower bound on the log-likelihood. O", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "654", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed to use Generalized Advantage Estimation (GAE) to optimize DNNs for information seeking tasks. The task is posed as a reinforcement learning problem and the proposed method explicit", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "573", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a method for generating adversarial input images for a convolutional neural network given only black box access (ability to obtain outputs for chosen inputs, but no access to the ne", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "708", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "this work aims to address representation of multi-sense words by exploiting multilingual context. Experiments on word sense induction and word similarity in context show that the proposed solution imp", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "640", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper looks at the idea of fusing multiple layers (typically a convolution and a LRN or pooling layer) into a single convolution via retraining of just that layer, and shows that simpler, faster ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "587", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I find the general direction of the work is promising but, in my opinion, the paper has three main drawback. While the motivation and overall idea seem very reasonable, the derivation is not convincin", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "681", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper explores a new quantization method for both the weights and the activations that does not need re-training. In VGG-16 the method reaches compression ratios of 20x and experiences a speed-up", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "778", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "After a second look of the paper, I am still confused what the authors are trying to achieve. The CCA objective is not differentiable in the sense that the sum of singular values (trace norm) of T is ", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "575", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "TDLR: The authors present a regularization method wherein they add noise to some representation space. The paper mainly applies the technique w/ sequence autoencoders (Dai et al., 2015) without the us", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "524", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper investigates the issue of whether and how to use syntactic dependencies in unsupervised word representation learning models like CBOW or Skip-Gram, with a focus one the issue of bound (word", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": 2, "ID": "649", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper is about submodular sum product networks applied to scene understanding. SPNs have shown great success in deep linear models since the work of Poon 2011. The authors propose an extension to", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "628", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 2, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed a hardware accelerator for DNN. It utilized the fact that DNN are very tolerant to low precision inference and outperforms a state-of-the-art bit-parallel accelerator by 1.90x with", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": 2, "ID": "703", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I reviewed the manuscript as of December 6th. Summary: The authors build upon generative adversarial networks for the purpose of steganalysis -- i.e. detecting hidden messages in a payload. The author", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "664", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "TLDR: The authors present Variable Computation in Recurrent Neural Networks (VCRNN). VCRNN is similar in nature to Adaptive Computation Time (Graves et al., 2016). Imagine a vanilla RNN, at each times", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "441", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper fits models to spike trains of retinal ganglion cells that are driven by natural images. I think the title should thus include the word activity at the end for otherwise it is actually form", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "328", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I appreciate the work but I do not think the paper is clear enough. Moreover, the authors say \"local minimia\" ~70 times but do not show (except for Figure 11?) that the solutions found are not necessa", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "556", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "While this paper has some decent accuracy numbers, it is hard to argue for acceptance given the following: 1) motivation based on the incorrect assumption that the Paragraph Vector wouldn't work on un", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "732", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The paper proposes using an actor-critic RL algorithm for training learning rate controllers for supervised learning. The proposed method outperforms standard optimizers like SGD, ADAM and RMSprop in ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "767", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work presents a novel 3D CNN architecture for climate event detection that combines an unsupervised auto-encoder reconstruction loss with YOLO like bounding box prediction. The approach is traine", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "588", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Authors propose using periodic activation functions (sin) instead of tanh for gradient descent training of neural networks. This change goes against common sense and there would need to be strong evid", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "608", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "In this paper, the author proposed an approach for feature combination of two embeddings v1 and v2. This is done by first computing the pairwise combinations of the elements of v1 and v2 (with complic", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "720", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": 4, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors advocate use of chirplets as a basis for modeling audio signals. They introduce a fast chiplet transform for efficient computation. Also introduced is the idea of initializing (pre-trainin", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "521", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper introduces a new way of extending the count based exploration approach to domains where counts are not readily available. The way in which the authors do it is through hash functions. Exper", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "558", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The paper presents a large-scale visual search system for finding product images given a fashion item. The exploration is interesting and the paper does a nice job of discussing the challenges of oper", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "574", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In absence of authors' response, the rating is maintained. --- This paper introduces a nonlinear dynamical model for multiple related multivariate time series. It models a linear observation model con", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "763", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a modified DAE objective where it is the mapped representation of the corrupted input that is pushed closer to the representation of the uncorrupted input. This thus borrows from bo", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "550", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 2, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes to combine graph convolution with RNNs to solve problems in which inputs are graphs. The two key ideas are: (i) a graph convolutional layer is used to extract features which are the", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "589", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The framework of semi-Markov decision processes (SDMPs) has been long used to model skill learning and temporal abstraction in reinforcement learning. This paper proposes a variant of such a model cal", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "728", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a modification of the ELU activation function for neural networks, by parameterizing it with 2 trainable parameters per layer. This parameter is proposed to more effectively counte", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "713", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 2, "MEANINGFUL_COMPARISON": null, "COMMENTS": "While it is interesting that this can be done, and it will be useful for some, it does seem like the audience is not really the mainstream ICLR audience, who will not be afraid to use a conventional M", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": 2, "ID": "543", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "L-SR1 seems to have O(mn) time complexity. I miss this information in your paper. Your experimental results suggest that L-SR1 does not outperform Adadelta (I suppose the same for Adam). Given the tim", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "615", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I sincerely apologize for the late review! The first part has a strong emphasis on the technical part. It could benefit from some high level arguments on what the method aims to achieve, what limitati", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "618", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper discusses a range of modelling choices for designing differentiable programming languages. Authors propose 4 recommendations that are then tested on a set of 13 algorithmic tasks for lists, ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "528", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper replaces the Gaussian prior often used in a VAE with a group sparse prior. They modify the approximate posterior function so that it also generates group sparse samples. The development of ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "592", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper combines DRQN with eligibility traces, and also experiment with the Adam optimizer for optimizing the q-network. This direction is worth exploring, and the experiments demonstrate the benef", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "554", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a nonlinear regularizer for solving ill-posed inverse problems. The latent variables (or causal factors) corresponding to the observed data are assumed to lie near a low dimensional", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "735", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "*** Paper Summary *** This paper simplify matching network by considering only a single prototype per class which is obtained as the average of the embedding of the training class samples. Empirical c", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "559", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors introduce some new prior and approximate posterior families for variational autoencoders, which are compatible with the reparameterization trick, as well as being capable of expressing mul", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "706", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper aims at designing a real-time semantic segmentation network. The proposed approach has an encoder-decoder architecture with many pre-existing techniques to improvement the performance and s", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "716", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors present a method for training probabilistic models by maximizing a stochastic variational-lower-bound-type objective. Training involves sampling and then learning a transition-based infere", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "654", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "UPDATE: I looked at the arxiv version of the paper. It is much longer and appears more rigorous. Fig 3 there is indeed more insightful. However, I am reviewing the submission and my overall assessment", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "740", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper shows that when a larger mini-batch is used (in the serial setting), the number of samples needed to be processed for the same convergence guarantee is larger. A similar behavior is discuss", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "653", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "SYNOPSIS: The paper proposes a new neural network-based model for reading comprehension (reading a passage of text and answering questions based on the passage). It is similar in spirit to several oth", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "590", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "An interesting study of using Sine as activation function showing successful training of models using Sine. However the scope of tasks this is applied to is a bit too limited to be convincing. Maybe s", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "608", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The paper introduces Gated Multimodal Units GMUs, which use multiplicative weights to select the degree to which a hidden unit will consider different modalities in determining its activation. The pap", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "503", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a method for visualization and analysis of policies from observed trajectories that the policies produce. The method infers higher level skills and clusters states. The result is a ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "728", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": 5, "COMMENTS": "The paper presents a deep RL with eligibility traces. The authors combine DRQN with eligibility traces for improved training. The new algorithm is evaluated on a two problems, with a single set of hyp", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "554", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper compares several strategies for guessing a short list of vocabulary for the target language in neural machine translation. The primary findings are that word alignment dictionaries work bet", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "779", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors contribute an algorithm for building sum-product networks (SPNs) from data, assuming a Gaussian distribution for all dimensions of the observed data. Due to the restricted structure of the", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "525", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This work proposes to iteratively improve a sentence that has been generated from another MT system (in this case, a phrase-based system). The authors use a neural net that takes in the source sentenc", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "776", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors investigate the neural GPU model introduced by Kaiser and Sutskever. In section 3 they claim its performance is due to the O(n^2) number of steps it can perform for each example. In the su", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "586", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "# Summary This paper proposes an algorithm to learn the structure of continuous SPNs in a single pass through the data, basically by \"growing\" the SPN when two variables are correlated. ## NOTE I am n", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "525", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work proposes to use visualization of gradients to further understand the importance of features (i.e. pixels) for visual classification. Overall, this presented visualizations are interesting, h", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "747", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces pointer-network neural networks, which are applied to referring expressions in three small-scale language modeling tasks: dialogue modeling, recipe modeling and news article mode", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "707", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a neural approach to learning an image compression-decompression scheme as an auto-encoder. While the idea is certainly interesting and well-motivated, in practice, it turns out to ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "392", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper proposes a model to learn across different views of objects. The key insight is to use a triplet loss that encourages two different views of the same object to be closer than an image of a ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "332", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The paper presents an interesting modification to PoWER algorithm that is well motivated. The main limitation of this paper is the lack of comparison with other methods and on richer problems. The exp", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "688", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents an alternative way of supervising the training of neural network without explicitly using labels when only link/not-link information is available between pairs of examples. A pair o", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "719", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I would definitely love to have this and use it for my research. A great tool. However, the paper lacks detail. In particular, I feel that it is impossible for someone to reimplement the research-most", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": 2, "ID": "544", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a training strategy for deep networks. First, the network is trained in a standard fashion. Second, small magnitude weights are clamped to 0; the rest of the weights continue to be", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "370", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper proposes a simple randomized algorithm for selecting which weights in a ConvNet to prune in order to reduce theoretical FLOPs when evaluating a deep neural network. The paper provides a nic", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "715", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper is interesting, it relates findings from neurscience and biology to a method for sparse coding that is adaptive and able to automatically generate (or even delete) codes as new data is comin", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "643", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The method proposed essential trains neural networks without a traditional nonlinearity, using multiplicative gating by the CDF of a Gaussian evaluated at the preactivation; this is motivated as a rel", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "651", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Based on previous work such as the stepped sigmoid units and ReLU hidden units for discriminatively trained supervised models, a Leaky-ReLU model is proposed for generative learning. Pro: what is inte", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "682", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper presents an attention based recurrent approach to one-shot learning. It reports quite strong experimental results (surpassing human performance/HBPL) on the Omniglot dataset, which is somew", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "569", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper studies the error surface of deep rectifier networks, giving specific examples for which the error surface has local minima. Several experimental results show that learning can be trapped a", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "624", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a model that generates a latent representation of input image(s) and optimizes a reconstruction loss with an adversarial loss (Eq (1)) over nearest neighbors from a bank of images ", "SOUNDNESS_CORRECTNESS": 1, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "616", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This paper studies the graph embedding problem by using the encoder-decoder method. The experimental study on real network data sets show the features extracted by the proposed model is good for class", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "677", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposed a nice framework leveraging Tucker and Tensor train low-rank tensor factorization to induce parameter sharing for multi-task learning. The framework is nice and appealing. However, ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "459", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper takes a standard auto-regressive model of source code and augments it with a fixed attention policy that tracks the use of certain token types, like identifiers. Additionally they release a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "754", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a variety of techniques for visualizing learned generative models, focussing specifically on VAE and GAN models. This paper is somewhat challenging to assess since it doesn't propo", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": 2, "ID": "774", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes SEM, a simple large-size multilabel learning algorithm which models the probability of each label as softmax(sigmoid(W^T X) + b), so a one-layer hidden network. This in and of itse", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "787", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an interesting idea for rapidly adapting generative models in the low data regime. The idea is to use similar techniques that are used in one-shot learning, specifically ideas from", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "693", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper uses a combination of likelihood and reward based learning to learn sequence models for music. The ability to combine likelihood and reward based learning has been long known, as a result o", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "529", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an approach to character language modeling (CLMs) based on developing a domain specific language to represent CLMs. The experiments show mixed performance versus neural CLM approac", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 2, "ID": "343", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 2, "MEANINGFUL_COMPARISON": null, "COMMENTS": "After the rebuttal: The paper contains an interesting set of results (mainly produced after the initial submission), but novelty is limited, and presentation is suboptimal. For me now the biggest prob", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "572", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposed a very complex compression and reconstruction method (with additional parameters) for reducing the memory footprint of deep networks. The authors show that this complex proposal is ", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "686", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a new method for learning graphical models. Combined with a neural network architecture, some sparse edge structure is estimated via sampling methods. In introduction, the authors ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "517", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a small trick to improve the model quality of variational autoencoders (further optimizing the ELBO while initializing it from the predictions of the q network, instead of just usi", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "595", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a simple extension to a neural network language model by adding a cache component. The model stores", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "339", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper introduces a variant of the semi-supervised variational auto-encoder (VAE) framework. The authors present a way of introducing structure (observed variables) inside the recognition network.", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "593", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper introduces a new dataset to evaluate word representations. The task considered in the paper, called outlier detection (also known as word intrusion), is to identify which word does not belo", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 3, "APPROPRIATENESS": 2, "ID": "507", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed a quantitative metric for evaluating out-of-class novelty of samples from generative models. The authors evaluated the proposed metric on over 1000 models with different hyperparam", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "583", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": 4, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a new environment, called Retro Learning Environment (RLE), for reinforcement learning. The authors focus on Super Nintendo but claim that the interface supports many others (includ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "691", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The idea of universality that is independent of input distribution and dimension, depending only on the algorithm is an appealing one. However, as an empirical study, this paper comes up somewhat shor", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "743", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a new architecture that does not explicitly use residuals but constructs an architecture that is composed of networks with fractal structure by using expand and join operations. Us", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "449", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary === This paper trains models to predict whether block towers will fall down or not. It shows that an additional model of how blocks fall down (predicting a sequence of frames via unsupervised ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "513", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper explores the use of Open Bigrams as a target representation of words, for application to handwriting image recognition. Pros: - The use of OBs is novel and interesting. - Clearly written an", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "723", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work proposes a joint classification of images and audio captions for the task of word like discovery of acoustic units that correlate to semantically visual objects. The general this is a very i", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "705", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work presents an empirical study of the influence of different types of data augmentation on the performance of CNNs. It also proposes to incorporate additional loss functions to encourage approx", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "578", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "After rebuttal: Thanks for reporting the AlexNet results. The fact that they are not great is not so bad by itself, and as the authors mention, it would be interesting to understand why this happens. ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "648", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work address the problem of supervised learning from strongly labeled data with label noise. This is a very practical and relevant problem in applied machine learning. The authors note that using", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "463", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper discusses a method to learn interpretable hierarchical template representations from given data. The authors illustrate their approach on binary images. The paper presents a novel technique ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "760", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper considers the code completion problem: given partially written source code produce a distribution over the next token or sequence of tokens. This is an interesting and important problem wit", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "603", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This paper performs a series of experiments to systematically evaluate the robustness of several defense methods, including RAD, AEC and its improved version etc.. It provides interesting observations", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "610", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents three improvements to the standard LSTM architecture used in many neural NLP models: Monte Carlo averaging, embed average pooling, and residual connections. Each of the modificatio", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "730", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I very much like the underlying idea for this paper. I wasn't convinced by the execution in its current state. My primary concern is the one I expressed in my pre-review question below, which I don't ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "654", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this paper, the authors propose a Bayesian variant of the skipgram model to learn word embeddings. There are two important variant compared to the original model. First, aligned sentences from mult", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "640", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper considers the case where multiple views of data are learned through a probabilistic deep neural network formulation. This makes the model non-linear (unlike e.g. CCA) but makes inference di", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "734", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: This paper proposes a read-again attention-based representation of the document with the copy mechanism for the summarization task. The model reads each sentence in the input document twice a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "630", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The submitted paper proposes a new way of learning sequence predictors. In the lines of incremental learning and curriculum learning, easier samples are presented first and the complexity is increased", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "675", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": 3, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper discusses sub modular sum-product networks as a tractable extension for classical sum-product networks. The proposed approach is evaluated on semantic segmentation tasks and some early promi", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "628", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Update: Because no revision of the paper has been provided by the authors, I am reducing my rating to \"marginally below acceptance\". ---------- This paper addresses the problem of training stochastic ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "725", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper addresses the problem of the influence of mini-batch size on the SGD convergence in a general non-convex setting. The results are then translated to analyze the influence of the number of l", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "653", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The work combines variational recurrent neural networks, and adversarial neural networks to handle domain adaptation for time series data. The proposed method, along with several competing algorithms ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "342", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an interesting application of the GAN framework in steganography domain. In addition to the normal GAN discriminator, there is a steganalyser discriminator that receives the negati", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 3, "ID": "664", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "While the idea of moving the processing for machine learning into silicon contained within the (SSD) data storage devices is intriguing and offers the potential for low-power efficient computation, it", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": 2, "ID": "553", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduce a way to train joint models for many NLP tasks. Traditionally, we treat these tasks as pipeline the later tasks will depending on the output of the previous tasks. Here, the author", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "584", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I have no familiarity with the HJI PDE (I've only dealt with parabolic PDE's such as diffusion in the past). So the details of transforming this problem into a supervised loss escape me. Therefore, as", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": 3, "ID": "511", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Pros : - New and clear formalism for invariance on signals with known structure - Good numerical results Cons : - The structure must be specified. - The set structure dataset is too simple - There is ", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "514", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The goal of this paper is to learn vector representation of boolean and polynomial expressions, such that equivalent expressions have similar representations. The model proposed in the paper is based ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "538", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The authors proposed to learn embeddings of users and items by using deep neural network for a recommendation task. The resulting method has only minor differences from the previous CDL, in which neur", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "611", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduces a variation to the CNN-based texture synthesis procedure of Gatys et al. that matches correlations between spatially shifted feature responses in addition to the correlations betw", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "387", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduces an efficient variant of sparse coding and uses it as a building block in CNNs for image classification. The coding method incorporates both the input signal reconstruction objecti", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "549", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Overall the paper has the feel of a status update by some of the best researchers in the field. The paper is very clear, the observations are interesting, but the remarks are scattered and don't add u", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "586", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper builds upon the method of Jonschkowski & Brock to learn state representations for multiple tasks, rather than a single task. The research direction of learning representations for multiple ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "670", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 5, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper claim that, when supported by a number of backup workers, synchronized-SGD actually works better than async-SGD. The paper first analyze the problem of staled updates in async-SGDs, and prop", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "783", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "strengths: A method is proposed in this paper to initialize the encoder and decoder of the seq2seq model using the trained weights of language models with no parallel data. After such pretraining, all", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "709", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 3, "SUBSTANCE": 2, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The approximation capabilities of neural networks have been studied before for approximating different classes of functions. The goal of this paper is to provide an analog of the approximation theorem", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "536", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "the paper proposed a method mainly for graph classification. The proposal is to decompose graphs objects into hierarchies of small graphs followed by generating vector embeddings and aggregation using", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "508", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an improved formulation of CNN, aiming to separate geometric transformation from inherent features. The network can estimate the transformation of filters given the input images. T", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "618", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an alternative to Conditional Variational Auto-Encoders and Conditional MultiModal Auto-Encoders to perform inference of missing modalities in dataset with multiple modalities. The", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "672", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents an application of a tensor factorization to linear models, which allows to consider higher-order interactions between variables in classification (and regression) problems, and that", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "515", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "1. the QA model is not novel, very similar to the existing model. 2. The IQA model is very confusing. If it needs human interactive in the training process, how could it be practical to ask human to j", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "646", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a new learning model \"Compositional Kernel Machines (CKMs)\" that extends the classic kernel machines by constructing compositional kernel functions using sum-product networks. This", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "545", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper addresses the problem of decoding barcode-like markers depicted in an image. The main insight is to train a CNN from generated data produced from a GAN. The GAN is trained using unlabeled i", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "537", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper trains a generative model of image patches, where dictionary elements undergo gated linear transformations before being combined. The transformations are motivated in terms of Lie group ope", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "721", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a heuristic for avoiding large negative rewards which have already been experienced by distilling such events into a \"danger model\". The paper is well written including some rather", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "751", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes to use a last-layer feature penalty as regularization on the last layer of a neural net. Although the equations suggest a weighting per example, dropping this weight (alpha_i) works", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "750", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper provides a first study of customized precision hardware for large convolutional networks, namely alexnet, vgg and googlenet. It shows that it is possible to achieve larger speed-ups using fl", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "642", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "Approaches like adaptive dropout also have the binary mask as a function of input to a neuron very similar to the proposed approach. It is not clear, even from the new draft, how the proposed approach", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "651", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an intriguing study of how one can pose architecture search as a meta learning problem. By collecting features from networks trained on various datasets and training a ranking clas", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "555", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a sequence transduction model that first uses a traditional statistical alignment methods to provide alignments for an encoder-decoder type model. The paper provides experiments on", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "659", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper addresses the problem of allowing networks to change the number of units that are used during training. This is done in a simple but elegant and well-motivated way. Units with zero input or", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "322", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper tackles the problem of multi-modal classification of text and images. Pros: - Interesting dataset and application. Cons: - The results are rather lacklustre, showing a very mild improvement", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "663", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Authors show that a contrastive loss for a Siamese architecture can be used for learning representations for planar curves. With the proposed framework, authors are able to learn a representation whic", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "478", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper proposes new initialization for particular architectures and a correction trick to batch normalization to correct variance introduced by dropout. While authors state interesting observation", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "636", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The submission proposes to modify the typical GAN architecture slightly to include \"encrypt\" (Alice) and \"decrypt\" (Bob) modules as well as a module trying to decrypt the signal without a key (Eve). T", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "790", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper considers different methods of producing adversarial examples for generative models such as VAE and VAEGAN. Specifically, three methods are considered: classification-based adversaries whic", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "572", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The contribution of this paper can be summarized as: 1, A TransGaussian model (in a similar idea of TransE) which models the subject / object embeddings in a parameterization of Gaussian distribution.", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "632", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposed to analyze several recently developed machine readers and found that some machine readers could potentially take advantages of the entity marker (given that the same marker points o", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "696", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper is an extension of the matching networks by Vinyals et al. in NIPS2016. Instead of using all the examples in the support set during test, the method represents each class by the mean of its ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "559", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper Summary This paper evaluates the ability of two unsupervised learning models to learn a generalizable physical intuition governing the stability of a tower of blocks. The two models are (1) A mo", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "513", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "CONTRIBUTIONS This paper introduces a method for learning semantic \"word-like\" units jointly from audio and visual data. The authors use a multimodal neural network architecture which accepts both ima", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "705", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary of the paper: Authors study in this paper quantities related to the expressivity of neural networks.The analysis is done for a random network. authors define the trajectory length of a one dim", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "742", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a recurrent neural network approach for constructing a stochastic volatility model for financial time series. They introduce an inference network based on a recurrent neural networ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "712", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a method for estimating the context sensitivity of paraphrases and uses that to inform a word embedding learning model. The main idea and model are presented convincingly and seem ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "771", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "1. The hierarchical memory is fixed, not learned, and there is no hierarchical in the experimental section, only one layer for softmax layer. 2. It shows the 10-mips > 100-mips > 1000-mips, does it me", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "673", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: This paper proposes a regularizer that is claimed to help escaping from the saddle points. The method is inspired from physics, such that thinking of the optimization process is moving a posi", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "548", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper addresses the problem of argument mining, which consists of finding argument types and predicting the relationships between the arguments. The authors proposed a pointer network structure t", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "604", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a method that attempts to \"understand\" what is happening within a neural network by using linear classifier probes which are inserted at various levels of the network. I think the ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "577", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a network called Gated Residual Networks layer design that adds gating to shortcut connections with a scalar to regulate the gate. The authors claim that this approach will improve", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "744", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "As you noted for Figure 5 Left, sometimes it seems sufficient to tune learning rates. I see your argument for Figure 6 Right, but 1) not for all good learning rates make Adam fail, I guess you selecte", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "660", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a novel layer-wise optimization approach for learning CNN with piecewise linear nonlinearities. The proposed approach trains piecewise linear CNNs layer by layer and reduces the su", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "412", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper describes a fast image semantic segmentation network. Many different techniques are combined to create a system much faster than the baseline SegNet approach, with accuracy comparable or so", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "716", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I agree with the other reviewer that the application areas are limited in the paper. I agree with the overall sentiment of the paper to evaluate effectiveness of some of the more recent techniques in ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "730", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "This paper introduces a novel hierarchical memory architecture for neural networks, based on a binary tree with leaves corresponding to memory cells. This allows for O(log n) memory access, and experi", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "782", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work proposes 3 improvements to scattering networks: (1) a non-linearity that allows Fourier-domain computation, (2) compact-supported (in the Fourier domain) representations, and (3) computing a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "681", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I do need to see the results in a clear table. Original results and results when compression is applied for all the tasks. In any case, i would like to see the results when the compression is applied ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "778", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I reviewed the manuscript on December 5th. Summary: The authors investigate the phenomenon of adversarial perturbations and ask whether one may build a system to independently detect an adversarial da", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "462", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "UPDATE: I have read the replies on this thread. My opinion has not changed. The authors propose deep VCCA, a deep version of the probabilistic CCA model by using likelihoods parameterized by nonlinear", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "734", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a low-rank version of pass-through networks to better control capacity, which can be useful in some cases, as shown in the experiments. That said, I found the results not very convi", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "594", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a method for future frame prediction based on transformation of previous frame rather than direct pixel prediction. Many previous works have proposed similar methods. The authors in", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "612", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work explores the neural models for sentence summarisation by using a read-again attention model and a copy mechanism which grants the ability of direct copying word representations from the sour", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "630", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Strengths - interesting to explore the connection between ReLU DNN and simplified SFNN - small task (MNIST) is used to demonstrate the usefulness of the proposed training methods experimentally - the ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "725", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an approach to do (structured) program induction based on program sketches in Forth (a simple stack based language). They turn the overall too open problem of program induction int", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "509", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes and tests two ideas. (1) a method of pruning networks by identifying highly correlated neuron pairs, pruning one of the pair, and then modifying downstream weights to compensate fo", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "695", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 2, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper proposes an unsupervised training objective based on patch contrasting for visual representation learning using deep neural networks. In particular, the feature representations of the patch", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "791", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an anomaly-based host intrusion detection method. LSTM RNN is used to model the system-call sequences and the averaged sequence likelihood is then used to determine anomaly, which ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "733", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors present a method for adaptively setting the step size for SGD by treating the learning rate as an action in an MDP whose reward is the change in loss function. The method is presented agai", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "767", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presented an extension to the current visual attention model that learns a deformable sampling lattice. Comparing to the fixed sampling lattice from previous works, the proposed method shows", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "334", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a linear pipeline All-reduce approach for parallel neural networks on multiple GPU. The paper provides both theoretical analysis and experiments. Overall, the results presented in ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "780", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Vanishing and exploding gradients makes the optimization of RNNs very challenging. The issue becomes worse on tasks with long term dependencies that requires longer RNNs. One of the suggested approach", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "560", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper can be seen as instantiating a famous paper by the founder of AI John McCarthy on learning to take advice (which was studied in depth by other later researchers, such as Jack Mostow in the ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "625", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a way to learn continuous features for input data which consists of multiple categorical data. The idea is to embed each category in a learnable low dimensional continuous space, ex", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 1, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "720", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper describe an implementation of delayed synchronize SGD method for multi-GPU deep ne training. Comments 1) The described manual implementation of delayed synchronization and state protection ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "617", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 2, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper applies RFN for biclustering to overcome the drawbacks in FABIA. The proposed method performs best among 14 biclustering methods, However, my first concern is that from the methodological p", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "773", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes to add an additional term to the denoising-autoencoder objective. The new term is well motivated, it introduces an asymmetry between the encoder and decoder, forcing the encoder to ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "550", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper is a novel application for the sticky HDP-HMM, focused on correctly identifying the number of components in bird and whale song across a variety of datasets. It's nice to see the model appli", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "710", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": 4, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper contributes to recent work investigating how neural networks can be used on graph-structured data. As far as I can tell, the proposed approach is the following: 1. Construct a hierarchical s", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "508", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "It is an interesting idea to go after saddle points in the optimization with an SR1 update and a good start in experiments, but missing important comparisons to recent 2nd order optimizations such as ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "615", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduces the joint multimodal variational autoencoder, a directed graphical model for modeling multimodal data with latent variable. the model is rather straightforward extension of standa", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "672", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes to use a causality score to weight a sparsity regularizer. In that way, selected variables trade off between being causal and discriminative. The framework is primarily evaluated o", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "613", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 2, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a new learning framework called \"compositional kernel machines\" (CKM). It combines two ideas: kernel methods and sum-product network (SPN). CKM first defines leaf kernels on elemen", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "545", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 2, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper explores 3 language modeling applications with an explicit modeling of reference expressions: dialog, receipt generation and coreferences. While these are important tasks for NLP and the au", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "707", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a set of recommendations for the design of differentiable programming languages, based on what made gradient descent more successful in experiments. I must say im no expert in progr", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "528", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper explores a new technique for classless association, a milder unsupervised learning where we do not know the class labels exactly, but we have a prior about the examples that belong to the sa", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "719", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I do like the demonstration that including learning of auxiliary tasks does not interfere with the RL tasks but even helps. This is also not so surprising with deep networks. The deep structure of the", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "438", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "A differentiable physics engine is indeed a wonderful thing to have. The key selling point of the proposed software is its speed, however there is no comparison to other physics engines. Besides descr", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "544", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Dear authors, The authors' response clarified some of my confusion. But I still have the following question: -- The response said a first contribution is a different formulation: you divide the word e", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "697", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "I'd like to thank the authors for their detailed response and clarifications. This work proposes new training scheme for online sparse dictionary learning. The model assumes a non-stationary flow of t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "643", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper describes a recurrent transducer that uses hard monotonic alignments: at each step a discrete decision is taken either to emit the next symbol or to consume the next input token. The model i", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "659", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors proposed to use leaky rectified linear units replacing binary units in Gaussian RBM. A sampling method was presented to train the leaky-ReLU RBM. In the experimental section, AIS estimated", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "682", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a version of a variational autoencoder that uses a discrete latent variable that masks the activation of the latent code, making only a subset (an \"epitome\") of the latent variables", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "592", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The main merit of this paper is to draw again attention to how crucial initialization of deep network *can* be; and to counter the popular impression that modern architectures and improved gradient de", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "624", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a method to synthesize string manipulation programs based on a set of input output pairs. The paper focuses on a restricted class of programs based on a simple context free grammar ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "356", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents the observation that it is possible to utilize sparse operations in the training of LSTM networks without loss of accuracy. This observation is novel (although not too surprising) ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "738", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed a set of different things under the name of \"sampling generative models\", focusing on analyzing the learned latent space and synthesizing desirable output images with certain prope", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "774", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes the RIMs that unrolls variational inference procedure. The author claims that the novelty lies in the separation of the model and inference procedure, making the MAP inference as a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "647", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 5, "SUBSTANCE": 2, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a large-scale multi-model product classification system. The model consists of three modules, Image CNN (VGG 16 architecture), text CNN (Kim 2014) and decision-level fusion polic", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "663", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a modification to ConvNet training so that the feature activations before the linear classifier are divided into groups such that all pairs of features across all pairs of groups a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "768", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper investigates a hybrid network consisting of a scattering network followed by a convolutional network. By using scattering layers, the number of parameters is reduced, and the first layers ar", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "656", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper studies the optimization issue of linear ResNet, and shows mathematically that for 2-shortcuts and zero initialization, the Hessian has condition number independent of depth. I skimmed thro", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "755", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a hierarchical infomax method. My comments are as follows: (1) First of all, this paper is 21 pages without appendix, and too long as a conference proceeding. Therefore, it is not ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "335", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "A few issues with this paper: 1- I find finding #2 trivial and unworthy of mention, but the author don't seem to agree with me that it is. See discussions. 2- Finding #1 relies on Fig #4, which appear", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "690", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents an action-conditional recurrent network that can predict frames in video games hundreds of steps in the future. The paper claims three main contributions: 1. modification to model a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "405", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper looks at how to train if there are significant label noise present. This is a good paper where two main methods are proposed, the first one is a latent variable model and training would req", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "463", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The paper proposes an algorithm for training memory networks which have very large memories. Training such models in traditional ways, by using soft-attention mechanism over all the memory slots is no", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "673", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a model for the task of argumentation mining (labeling the set of relationships between statements expressed as sentence-sized spans in a short text). The model combines a pointer ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": 2, "ID": "604", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes to learn a single scalar gating parameter instead of a full gating tensor in highway networks. The claim is that such gating is easier to learn and allows a network to flexibly uti", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "744", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a method to combine arbitrary content into recommender systems, such as images, text, etc. These various features have been previously used to improve recommender systems, though wh", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "582", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "This paper presents an approach to learn object representations by composing a set of templates which are leaned from binary images. In particular, a hierarchical model is learned by combining AND, OR", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "760", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper describes an approach to learning the non-linear activation function in deep neural nets. This is achieved by representing the activation function in a basis of non-linear functions and lea", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "512", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduced an extension of Adam optimizer that automatically adjust learning rate by comparing the subsequent values of the cost function during training. The authors empirically demonstrate", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "660", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Pros: using neural network on a new domain. Cons: It is not clear how it is guaranteed that the network generates syntactically correct code. Questions, comments: How is the NT2N+NTN2T top 5 accuracy ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "603", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper compares several defense mechanisms against adversarial attacks: retraining, two kinds of autoencoders and distillation with the conclusion that the retraining methodology proposed by Li et ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "610", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper proposes a cascade of paired (left/right, up/down) 1D RNNs as a module in CNNs in order to quickly add global context information to features without the need for stacking many convolutiona", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "631", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper conducts a comprehensive series of experiments on vocabulary selection strategies to reduce the computational cost of neural machine translation. A range of techniques are investigated, ran", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "779", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes and analyses three methods applied to traditional LSTMs: Monte Carlo test-time model averaging, average pooling, and residual connections. It shows that those methods help to enhanc", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "730", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Strengths -- An interesting proposal for a smaller CNN architecture designed for embedded CNN applications. -- Balanced exploration of CNN macroarchitecture and microarchitecture with fire modules. --", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "737", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: In this paper, the authors look at the ability of neural networks to represent low dimensional manifolds efficiently e.g. embed them into a lower dimensional Euclidian space. They define a cl", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "485", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents an architecture to parallelize the optimization of nested functions based on the method of auxiliary coordinates (MAC) (Carreira-Perpinan and Wang, 2012). This method decomposes the", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "740", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors introduce a new memory model which allows memory access in O(log n) time. Pros: * The paper is well written and everything is clear. * It's a new model and I'm not aware of a similar model", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "782", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a method to represent text documents and paragraphs as short binary codes to allow fast similarity search and retrieval by using hashing techniques. The real-valued paragraph vecto", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": 2, "ID": "731", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes two approaches to boosting generative models, both based on likelihood ratio estimates. The approaches are evaluated on synthetic data, as well as on MNIST dataset for the tasks of ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "571", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a method for iteratively improving the output of an existing machine translation by identifying potential mistakes and proposing a substitution, in this case using an attention-bas", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "776", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "Overall I think this is an interesting paper which shows empirical performance improvement over baselines. However, my main concern with the paper is regarding its technical depth, as the gist of the ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": 2, "ID": "736", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents an interesting incremental approach for exploring new convolutional network hierarchies in an incremental manner after a baseline network has reached a good recognition performance.", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "540", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 5, "COMMENTS": "Update after reading the authors' responses & the paper revision dated Dec 21: I have removed the comment \"insufficient comparison to past work\" in the title & update the score from 3 -> 5. The main r", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "680", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: In this paper, the authors introduce NoiseOut, a way to reduce parameters by pruning neurons from a network. They do this by identifying pairs of neurons produce the most correlated outputs, ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "695", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper discusses ways to enforce invariance in neural networks using weight sharing. The authors formalize a way for feature functions to be invariant to a collection of relations and the main inv", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "514", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper is motivated by the ability that human's visual system can recognize contents of environment by from critical features, and tried to investigate whether neural networks can also have this k", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "762", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose using an LSTM on a sequence of system calls to perform network intrusion detection (NIDS). The idea of using neural networks (in general) for NIDS is old [1]. The idea of using som", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 2, "ID": "733", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "Revision of the review: The authors did a commendable job of including additional references and baseline experiments. --- This paper presents a hybrid architecture for time series prediction, focusin", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "579", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary of the paper The paper studies the invertiblity of convolutional neural network in the random model. A reconstruction algorithm similar to IHT is proposed for layer-wise inversion of the netwo", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "674", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper Summary: Authors investigate identity re-parametrization in the linear and the non linear case. Detailed comments: Linear Residual Network: The paper shows that for a linear residual network any", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "466", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposed an end-to-end machine learning model called dynamic reader for the machine reading comprehension task. Compared to earlier systems, the proposed model is able to extract and rank a ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "590", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper provides a minor improvement paper of DeepRS. The major improvement comes from the coupling of user-item factors in prediction. While the motivation is clear, the improvement of the model a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "611", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I reviewed the manuscript as of December 7th. Summary: The authors investigate the transferability of adversarial examples in deep networks. The authors confirm that transferability exists even in lar", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "465", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper analyzes the ring-based AllReduce approach for multi-GPU data parallel training of deep net. Comments 1) The name linear pipeline is somewhat confusing to the readers, as the technique is u", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "780", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes sparse coding problem with cosine-loss and integrated it as a feed-forward layer in a neural network as an energy based learning approach. The bi-directional extension makes the pr", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "549", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper is well-motivated, and is part of a line of recent work investigating the use of orthogonal weight matrices within recurrent neural networks. While using orthogonal weights addresses the iss", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "560", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed a novel adversarial framework to train a model from demonstrations in a third-person perspective, to perform the task in the first-person view. Here the adversarial training is use", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "341", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper studies the problem of abstract hierarchical multiagent RL with policy sketches, high level descriptions of abstract actions. The work is related to much previous work in hierarchical RL, a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "542", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper investigates on better training strategies for the Neural GPU models as well as studies the limitations of the model. Pros: * Well written. * Many investigations. * Available source code. Co", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "586", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an extension of PixelCNN method that can be conditioned on text and spatially-structured constraints (segmentation / keypoints). It is similar to Reed 2016a except the extension is", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": 4, "APPROPRIATENESS": 4, "ID": "520", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Clarity: The novel contribution of the paper --- Section 2.2 --- was very difficult to understand. The notation seemed inconsistent (particularly the use of l, p, and m), and I am still not confident ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "773", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a few tricks to compress a wide and shallow text classification model based on n-gram features. These tricks include (1) using (optimized) product quantization to compress embedding", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "657", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper applies HDP-HMM to challenging bioacoustics segmentation problems including humpback whole sound and bird sound segmentation. Although the technique itself is not novel, the application of ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "710", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose transfer learning variants for neural-net-based models, applied to a bunch of NLP tagging tasks. The field of multi-tasking is huge, and the approaches proposed here do not seem to", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "373", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduces GA3C, a GPU-based implementation of the A3C algorithm, which was originally designed for multi-core CPUs. The main innovation is the introduction of a system of queues. The queues", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "437", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "SUMMARY This paper presents a study of the number of hidden units and training examples needed to learn functions from a particular class. This class is defined as those Boolean functions with an uppe", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "536", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed the group sparse auto-encoder for feature extraction. The author then stack the group sparse auto-encoders on top of CNNs to extract better question sentence representation for QA ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "600", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is a nice proposal, and could lead to more efficient training of recurrent nets. I would really love to see a bit more experimental evidence. I asked a few questions already but didn't get any an", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "552", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Specifically, this paper suggests regularizing the estimator of a probability distribution to prefer high-entropy distributions. This avoids overfitting. I generally like this idea. Regularizing the b", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "668", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper addresses the issue of how to evaluate automatic dialogue responses. This is an important issue because current practice to automatically evaluate (e.g. BLEU, based on N-gram overlap, etc.)", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "502", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper provides an interesting use of generative models to address the classification with missing data problem. The tensorial mixture models proposed take into account the general problem of depen", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "689", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed a way to deal with supervised multivariate time series tasks involving missing values. The high level idea is still using the recurrent neural network (specifically, GRU in this pa", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "599", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this paper, the authors extend the f-GAN by using Bregman divergences for density ratio matching. The argument against f-GAN (which is a generalization of the regular GAN) is that the actual object", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "563", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a solution for the task of synthesizing melodies. The authors claim that the \"language-model\"-type approaches with LSTMs generate melodies with certain shortcomings. They tend to l", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "529", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces three tricks for training deep latent variable models on sparse discrete data: 1) tf-idf weighting 2) Iteratively optimizing variational parameters after initializing them with a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "595", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors explore whether the halting time distributions for various algorithms in various settings exhibit \"universality\", i.e. after rescaling to zero mean and unit variance, the distribution does", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "743", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Thank you for an interesting read. I found the application of VRNN type generative model to financial data very promising. But since I don't have enough background knowledge to judge whether the perfo", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 2, "APPROPRIATENESS": 2, "ID": "712", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper evaluates several strategies to reduce output vocabulary size in order to speed up NMT decoding and training. It could be quite useful to practitioners, although the main contributions of t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 2, "ID": "779", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a new software package for probabilistic programming, taking advantage of recent successful tools used in the deep learning community. The software looks very promising and has the", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "395", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose two approaches to combine multiple weak generative models into a stronger one using principles from boosting. The approach is simple and elegant and basically creates an unnormaliz", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "571", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a thorough analysis of different methods to do curriculum learning. The major issue I have with it is that the dataset used seems very specific and does not necessarily justified, ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "675", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors present TARTAN, a derivative of the previously published DNN accelerator architecture: DaDianNao. The key difference is that TARTANs compute units are bit-serial and unroll MAC operation o", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "703", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Pros: Interesting training criterion. Cons: Missing proper ASR technique based baselines. Comments: The dataset is quite small. ROC curves for detection, and more measurements, e.g. EER would probably", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "408", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper deals with a very important issue of vanishing gradients and the quest for a perfect activation function. Proposed is an approach of learning the activation functions during the training pro", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "713", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a method to efficiently augment an SVM variant with many virtual instances, and show promising preliminary results. The paper was an interesting read, with thoughtful methodology, ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "545", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 2, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors talk about design choice recommendations for performing program induction via gradient descent, basically advocating reasonable programming language practice (immutable data, higher-order ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "528", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a simple idea. They penalize confident predictions by using the entropy of the predictive distribution as a regularizer. The authors consider two variations on this idea. In one, t", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "668", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper explores the performance-area-energy-model accuracy tradeoff encountered in designing custom number representations for deep learning inference. Common image-based benchmarks: VGG, Googlene", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "642", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "SUMMARY: This paper describes a set of experiments evaluating techniques for training a dialogue agent via reinforcement learning. A standard memory network architecture is trained on both bAbI and a ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 1, "RECOMMENDATION": null, "APPROPRIATENESS": 1, "ID": "445", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper tackles the task of music generation. They use an orderless NADE model for the task of \"fill in the notes\". Given a roll of T timesteps of pitches, they randomly mask out some pitches, and t", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": 1, "APPROPRIATENESS": 2, "ID": "621", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper proposes a deep extension of generalized CCA. The main contribution of the paper is deriving the gradient update for the GCCA objective. I disagree with the claim that this is the first Mul", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "645", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: The paper describes how the DaDianNao (DaDN) DNN accelerator can be improved by employing bit serial arithmetic. They replace the bit-parallel multipliers in DaDN with multipliers that accept", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "703", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Overall, this is a nice paper. Developing a unifying framework for these newer neural models is a worthwhile endeavor. However, it's unclear if the DRAGNN framework (in its current form) is a signific", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "671", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a model for iteratively refining translation hypotheses. This has several benefits, including enabling the translation model to condition not only on left context, but also on righ", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "776", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an architecture for answer extraction task and evaluates on the SQUAD dataset. The proposed model builds fixed length representations of all spans in the answer document based on r", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "711", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The present submission discusses a \"causal regularizer\", which promotes the use of causal dependencies (X -> Y, where X is a feature of the learning problem, and Y is the target variable) in predictiv", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "613", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Thank you for an interesting read. The ideas presented have a good basis of being true, but the experiments are rather too simple. It would be interesting to see more empirical evidence. Pros - The ap", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "545", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a sparsely connected network and an efficient hardware architecture that can save up to 90% of memory compared to the conventional implementations of fully connected neural networks", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "487", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes an approach to generating synthetic training data for deep networks, based on rendering 3D models and learning additional transformations with adversarial training. The approach is ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "537", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents small but important modifications which can be made to differentiable programs to improve learning on them. Overall these modifications seem to substantially improve convergence of", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "528", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: The authors propose a multi-hop \"gated attention\" model, which models the interactions between query and document representations, for answering cloze-style questions. The document representa", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "602", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work proposes to augment normal gradient descent algorithms with a \"Data Filter\", that acts as a curriculum teacher by selecting which examples the trained target network should see to learn opti", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "532", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose and evaluate using SPN's to generate embeddings of input and output variables, and using MPN to decode output embeddings to output variables. The advantage of predicting label embe", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "658", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper seeks to predict user events (interactions with items at a particular point in time). Roughly speaking the contributions are as follows: (a) the paper models the co-evolutionary process of u", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "614", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes analysis of regularization, weight Froebius-norm and feature L2 norm, showing that it is equivalent to another proposed regularization, gradient magnitude loss. They then argue tha", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "750", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Update: I thank the authors for their comments! After reading them, I decided to increase the rating. This paper proposes a variant of the convolution operation suitable for a broad class of graph str", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "609", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes an evolution upon traditional Recurrent Language Models to give the capability to deal with unknown words. It is done by pairing the traditional RNNLM with a module operating on a K", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "770", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Thie paper proposed an iterative memory updating model for cloze-style question-answering task. The approach is interesting, and result is good. For the paper, I have some comments: 1. Actually the mo", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "479", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose NVI for LDA variants. The authors compare NVI-LDA to standard inference schemes such as CGS and online SVI. The authors also evaluate NVI on a different model ProdLDA (not sure thi", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "366", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "An interesting architecture that accumulates and continuously corrects mistakes as you see more and more of a video sequence. Clarity: The video you generated seems very helpful towards understanding ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "350", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors provide a well engineered solution to exploiting sparsity in convolutional layers of a deep network by recasting it as sparse matrix-vector multiplication. This leads to very nice speedups", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "469", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Updated review: 18 Jan. 2017 Thanks to the authors for including a comparison to the previously published sparsity method of Yu et al., 2012. The comparison is plausible, though it would be clearer if", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "391", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper extends preceding works to create a mapping between the word embedding space of two languages. The word embeddings had been independently trained on monolingual data only, and various forms", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "426", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces the Quasi-Recurrent Neural Network (QRNN) that dramatically limits the computational burden of the temporal transitions in sequence data. Briefly (and slightly inaccurately) mode", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "404", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "This paper presents a new technique for adapting a neural network to a new task for which there is not a lot of training data. The most widely used current technique is that of fine-tuning. The idea i", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "701", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a framework for creating document representations. The main idea is to represent a document as an average of its word embeddings with a data-dependent regularization that favors in", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "330", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The starting point of this work is the understanding that by having decorrelated neurons (e.g. neurons that only fire on background, or only on foreground regions) one provides independent pieces of i", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "768", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents an approach for compensating the input/activation variance introduced by dropout in a network. Additionally, a practical inference trick of re-estimating the batch normalization par", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "636", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a relatively novel way to visualize the features / hidden units of a neural network and generate adversarial examples. The idea is to do gradient descent in the pixel space, from a", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "634", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents an interesting framework for image generation, which stitches the foreground and background to form an image. This is obviously a reasonable approach there is clearly a foreground o", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "396", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper addresses the problem of data sparsity in the healthcare domain by leveraging hierarchies of medical concepts organized in ontologies. The paper focuses on sequential prediction given a pat", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": 3, "ID": "667", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this paper, the authors propose a new method to learn hierarchical representations of sentences, based on reinforcement learning. They propose to learn a neural shift-reduce parser, such that the i", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "464", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a method for joint motion prediction and activity classification from sequences with two different applications: motion of fruit flies and online handwriting recognition. The method", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "480", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper considers the problem of transferring skills between robots with different morphologies, in the context of agents that have to perform several tasks. A core component of the proposed approac", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "331", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper aims to consolidate some recent literature in simple types of \"reading comprehension\" tasks involving matching questions to answers to be found in a passage, and then to explore the types of", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 2, "ID": "696", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Update: thank you for running more experiments, and add more explanations in the manuscript. They addressed most of my concerns, so I updated the score accordingly. The work aims at learning a generat", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "340", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper shows the relation between stochastically perturbing the parameter of a model at training time, and considering a mollified objective function for optimization. Aside from Eqs. 4-7 where I f", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "424", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Apologies for the late submission of this review, and thank you for the authors responses to earlier questions. This submission proposes an improved implementation of the PixelCNN generative model. Mo", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "336", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "SUMMARY This paper studies the expressive power of deep neural networks under various related measures of expressivity. It discusses how these measures relate to the `trajectory length', which is show", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "742", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper addresses a question that is often overlooked in reinforcement learning or locomotion experiment. My biggest point of critique is that it's difficult to draw conclusions or reason beyond th", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "775", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work brings multiple discriminators into GAN. From the result, multiple discriminators is useful for stabilizing. The main problem of stabilizing seems is from gradient signal from discriminator,", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "423", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces the concept of fuzzy paraphrases to aid in the learning of distributed word representations from a corpus augmented by a lexicon or ontology. Sometimes polysemy is context-depend", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "771", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "An interesting connection is made between dropout, Tishby et al's \"information bottleneck\" and VAEs. Specifically, classification of 'y' from 'x' is split in two faces: an inference model z ~ q(z|x), ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "726", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper describes approaches taken to train learning agents for the 3D game Doom. The authors propose a number of performance enhancements (curriculum learning, attention (zoomed-in centered) frames", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "355", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a layer architecture where a single parameter is used to gate the output response of layer to amplify or suppress it. It is shown that such an architecture can ease optimization of ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "744", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper propose to find an optimal decoder for binary data using a min-max decoder on the binary hypercube given a linear constraint on the correlation between the encoder and the data. The paper gi", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "367", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 2, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper address the problem of detecting if an example is misclassified or out-of-distribution. This is an very important topic and the study provides a good baseline. Although it misses strong nove", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "410", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper compares the performance, in terms of sensitivity to perturbations, of multilayer neural networks to human vision. In many of the tasks tested, multilayer neural networks exhibit similar se", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "629", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes the neural noisy channel model, P(x|y), where (x, y) is a input-to-out sequence pair, based on the authors' previous work on segment to segment neural transduction (SSNT) model. Fo", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "443", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper demonstrates a semi-automatic learning rate schedule for the Adam optimizer, called Eve. Originality is somehow limited but the method appears to have a positive effect on neural network tra", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "660", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a method for link prediction on Knowledge Bases. The method contains 2 main innovations: (1) an iterative inference process that allows the model to refine its predictions and (2) ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "596", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a reinforcement learning framework for designing a neural network architecture. For each time-step, the agent picks a new layer type with corresponding layer parameters (e.g., #f", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "383", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an extension of the MAC method in which subproblems are trained on a distributed cluster arranged in a circular configuration. The basic idea of MAC is to decouple the optimization", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "740", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper reports a very clear and easy to understand result that a convolutional network can be used instead of the recurrent encoder for neural machine translation. Apart from the known architectura", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": 2, "ID": "748", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper addresses to reduce test-time computational load of DNNs. Another factorization approach is proposed and shows good results. The comparison to the other methods is not comprehensive, the pa", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "778", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work proposes a model that can learn short binary codes via paragraph vectors to allow fast retrieval of documents. The experiments show that this is superior to semantic hashing. The approach is", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "731", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper describes the creation of a corpus of freely-licensed classical music recordings along with corresponding MIDI-scores aligned to the audio. It also describes experiments in polyphonic trans", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "409", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 5, "SUBSTANCE": 3, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents an application of deep learning to genomic SNP data with a comparison of possible approaches for dealing with the very high data dimensionality. The approach looks very interesting ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "351", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper extends boosting to the task of learning generative models of data. The strong learner is obtained as a geometric average of weak learners, which can themselves be normalized (e.g. VAE) or ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "571", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes to investigate attention transfers between a teacher and a student network. Attention transfer is performed by minimising the l2 distance between the teacher/student attention maps", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "319", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper evaluates how different context types affect the quality of word embeddings on a plethora of benchmarks. I am ambivalent about this paper. On one hand, it continues an important line of wor", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "649", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper is a well written paper. This paper can be divided into 2 parts: 1.Adversary training on ImageNet 2.Empirical study of label leak, single/multiple step attack, transferability and importanc", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "481", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "* Summary: This paper proposes a neural machine translation model that translates the source and the target texts in an end to end manner from characters to characters. The model can learn morphology ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "680", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This seems like a reasonable study, though it's not my area of expertise. I found no fault with the work or presentation, but did not follow the details or know the comparable literature. There seem t", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 3, "ID": "703", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an approach to learning word vector representations for character sequences and acoustic spans jointly. The paper is clearly written and both the approach and experiments seem reas", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "408", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes to use the very standard SVGB in a sequential setting like several previous works did. However, they proposes to have a clear state space constraints similar to Linear Gaussian Mode", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "422", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper develops a differentiable interpreter for the Forth programming language. This enables writing a program \"sketch\" (a program with parts left out), with a hole to be filled in based upon lea", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "509", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work offers a theoretical justification for reusing the input word embedding in the output projection layer. It does by proposing an additional loss that is designed to minimize the distance betw", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "473", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper investigates the identity parametrization also known as shortcuts where the output of each layer has the form h(x)+x instead of h(x). This has been shown to perform well in practice (eg. Re", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "466", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: The paper Deep Variational Information Bottleneck explores the optimization of neural networks for variational approximations of the information bottleneck (IB; Tishby et al., 1999). On the e", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "442", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors of this work propose an interesting approach to visualizing the predictions made by a deep neural network. The manuscript is well written is provides good insight into the problem. I also ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "427", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: The paper proposes a novel machine comprehension dataset called NEWSQA. The dataset consists of over 100,000 question answer pairs based on over 10,000 news articles from CNN. The paper analy", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "601", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: The paper proposes a large-scale dataset for reading comprehension, with the final goal of releasing 1 million questions and answers. The authors have currently released 100,000 queries and t", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "665", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a succinct argument that the principle of optimizing receptive field location and size in a simulated eye that can make saccades with respect to a classification error of images of", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "334", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The primary point made by this paper is that given certain architectural characteristics of multi-GPU systems, namely the use of bi-directional PCI-E for communication and the integration of two indep", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "780", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper applies convnet-based object detection techniques to detection of weather events from 3D climate data, additionally exploring the effect of using an unsupervised autoencoder-style objective", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "588", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The work introduces a new regularization for learning domain-invariant representations with neural networks. The regularization aims at matching the higher order central moments of the hidden activati", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "456", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "The authors present a novel approach to surprise-based intrinsic motivation in deep reinforcement learning. The authors clearly explain the difference from other recent approaches to intrinsic motivat", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "533", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "\"First, it allows us to assess whether auto-regressive models are able to match the GAN results of Reed et al. (2016a).\" Does it, though? Because the resolution is so bad. And resolution limitations a", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "520", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Pros: - Introduction of a nice filter banks and its implementation - Good numerical results - Refinement of the representation via back propagation, and a demonstration that it speeds up learning Cons", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "521", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a new exploration scheme for reinforcement learning using locality-sensitive hashing states to build a table of visit counts which are then used to encourage exploration in the styl", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "558", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "The paper proposes a series of tricks for compressing fast (linear) text classification models. The paper is clearly written, and the results are quite strong. The main compression is achieved via pro", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "657", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "I just noticed I submitted my review as a pre-review question - sorry about this. Here it is again, with a few more thoughts added... The authors present a great and - as far as I can tell - accurate ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "534", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper motivates the combination of autoregressive models with Variational Auto-Encoders and how to control the amount the amount of information stored in the latent code. The authors provide stat", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "397", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper propose to classify questions by leveraging corresponding answers. The proposed method uses group sparse autoencoders to model question groups. The proposed method offers improved accuracy ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "600", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a technique to combine deep learning style input-output training with search techniques to match the input of a program to the provided output. Orders of magnitude speedup over non-", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "439", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors proposed RASOR to address the problem of finding the best answer span according to a given question. The focus of the paper is mainly on how to model the relationship between question and ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "711", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper describes a new approach to meta learning by interpreting the SGD update rule as gated recurrent model with trainable parameters. The idea is original and important for research related to ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "306", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a new type of language model that treats entity references as latent variables. The paper is structured as three specialized models for three applications: dialog generation with r", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "707", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I think learning a deep feature representation that is supervised to group dissimilar views of the same object is interesting. The paper isn't technically especially novel but that doesn't bother me a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "332", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper looks correct but still i am not convinced about the experimentation performed. Perhaps another experiment with more challenging data would be welcome. Honestly i don't find a clear motivati", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "719", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper creates a physics simulator using theano, and uses it to learn a neural network policy by back propagating gradients through the simulation. The approach is novel, and is motivated by being", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "544", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper tries to solve the problem of interpretable representations with focus on Sum Product Networks. The authors argue that SPNs are a powerful linear models that are able to learn parts and the", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "658", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduces a time dependent recommender system based on point processes parametrized by time dependent user and item latent representations. The later are modeled as coupled autoregressive p", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "614", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes to incorporate knowledge base facts into language modeling, thus at each time step, a word is either generated from the full vocabulary or relevant KB entities. The authors demonst", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "770", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a principled optimization method for SGNS (word2vec). While the proposed method is elegant from a theoretical perspective, I am not sure what the tangible benefits of this approach", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "697", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a novel energy-function for RBMs, using the leaky relu max(cx, x) activation function for the hidden-units. Analogous to ReLU units in feed-forward networks, these leaky relu RBMs ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "682", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper tackles the problem of compressing trained convnets with the goal of reducing memory overhead and speeding up the forward pass. As I understand it, the main contribution of this work is to ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "469", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In PALEO the authors propose a simple model of execution of deep neural networks. It turns out that even this simple model allows to quite accurately predict the computation time for image recognition", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "431", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a method for predicting video sequences in the lines of Mathieu et al. The contribution is the separation of the predictor into two different networks, picking up motion and content", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "357", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper describes a network architecture for inverse problems in computer vision. Example inverse problems considered are image inpainting, computing intrinsic image decomposition and foreground/bac", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "616", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: The authors present a simple RNN with linear dynamics for language modeling. The linear dynamics greatly enhance the interpretability of the model, as well as provide the potential to improve", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "580", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper propose DRNN as a neural decoder for tree structures. I like the model architecture since it has two clear improvements over traditional approaches (1) the information flows in two direction", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "400", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper uses a pointer network over a sparse window of identifiers to improve code suggestion for dynamically-typed languages. Code suggestion seems an area where attention and/or pointers truly sh", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "754", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work proposes to a spatiotemporal saliency network that is able to mimic human fixation patterns, thus helping to prune irrelevant information from the video and improve action recognition. The w", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "483", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a RNN-method for time-series classification with missing values, that can make use of potential information in missing values. It is based on a simple linear imputation of missing ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "599", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed an integration of memory network with reinforcement learning. The experimental data is simple, but the model is very interesting and relatively novel. There are some questions abou", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "349", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a model that blends ideas from generative topic models with those from recurrent neural network language models. The authors evaluate the proposed approach on a document level cl", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "419", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes to learn groups of orthogonal features in a convnet by penalizing correlation among features in each group. The technique is applied in the setting of image classification with pri", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "768", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes the Layerwise Origin Target Synthesis (LOTS) method, which entails computing a difference in representation at a given layer in a neural network and then projecting that difference", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 4, "APPROPRIATENESS": 2, "ID": "634", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper suggests combining LSTMs, trained on a large midi corpus, with a handcrafted reward function that helps to fine-tune the model in a musically meaningful way. The idea to use hand-crafted re", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "529", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "The goal of this paper is to learn a collection of experts that are individually meaningful and that have disjoint responsibilities. Unlike a standard mixture model, they use a different mixture for e", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "781", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes to use RNN and reinforcement learning for solving combinatorial optimization problems. The use of pointer network is interesting as it enables generalization to arbitrary input siz", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "597", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "SUMMARY. This paper presents a method for enriching medical concepts with their parent nodes in an ontology. The method employs an attention mechanism over the parent nodes of a medical concept to cre", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "667", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper investigates deep generative models with multiple stochastic nodes and gives them meaning by semi-supervision. From a methodological point of view, there is nothing fundamentally novel (it ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "593", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper addresses the question of which functions are well suited to deep networks, as opposed to shallow networks. The basic intuition is convincing and fairly straightforward. Pooling operations ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "484", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": 4, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a new approach for estimating maximum entropy distributions subject to expectation constraints. Their approach is based on using normalizing flow networks to non-linearly transform", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "416", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a design principle for computation blocks in convolutional networks based on repeated application of expand and join operations resulting in a fractal-like structure. This paper is", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "449", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "The authors propose to apply virtual adversarial training to semi-supervised classification. It is quite hard to assess the novelty on the algorithmic side at this stage: there is a huge available lit", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "488", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a method to improve the efficiency of CNNs that encode sequential inputs in a slow fashion such that there is only a small change between the representation of adjacent steps in the", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "413", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces an actor-critic deep RL approach with experience replay, which combines truncated importance sampling and trust region policy optimization. The paper also proposes a new method c", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "460", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper studies deep reinforcement learning paradigm for controlling high dimensional characters. Experiments compare the effect different control parameterizations (torques, muscle-activations, PD cont", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": 2, "ID": "775", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a method to incorporate super-resolution and inpainting in the GAN framework for semi-supervised learning using the GAN discriminative features on larger images. The core idea of t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "648", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes to perform active learning using pool selection of deep learning mini-batches using an approximation of the bayesian posterior. Several terms are in turn approximated. The Maximum L", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "566", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper summary This paper develops a generalization of dropout using information theoretic principles. The basic idea is that when learning a representation z of input x with the aim of predicting y, w", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": 5, "ID": "726", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors present results on a number of different tasks where the goal is to determine whether a given test example is out-of-domain or likely to be mis-classified. This is accomplished by examinin", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "410", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The author works to compare DNNs to human visual perception, both quantitatively and qualitatively. Their first result involves performing a psychophysical experiment both on humans and on a model and", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "629", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: The paper introduces a parametric class for non linearities used in neural networks. The paper suggests two stage optimization to learn the weights of the network, and the non linearity weigh", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "512", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "[Summary] This paper proposes a new way for knowledge base completion which highlights: 1) adopting an implicit shared memory, which makes no assumption about its structure and is completely learned d", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "596", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a method of integrating recurrent layers within larger, potentially pre-trained, convolutional networks. The objective is to combine the feature extraction abilities of CNNs with th", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "631", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a novel way of using Bayesian NNs for policy search in stochastic dynamical systems. Specifically, the authors minimize alpha-divergence with alpha=0.5 as opposed to standard VB. T", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "440", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper looks solid and the idea is natural. Results seem promising as well. I am mostly concerned about the computational cost of the method. 8-10 days on 10 GPUs for relatively tiny datasets is qu", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "383", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Pros: * The general idea behind the paper seems pretty novel and potentially quite cool. * The specific technical implementation seems pretty reasonable and well-thought through. * The general types o", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "573", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a novel approach ParMAC, a parallel and distributed framework of MAC (the Method of Auxiliary Coordinates) to learn nested and non-convex models which is based on the composition o", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "740", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "There have been numerous works on learning from raw waveforms and training letter-based CTC networks for speech recognition, however, there are very few works on combining both of them with purely Con", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "598", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work builds on top of STOKE (Schkufza et al., 2013), which is a superoptimization engine for program binaries. It works by starting with an existing program, and proposing modifications to it acc", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 2, "APPROPRIATENESS": 2, "ID": "411", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "The authors propose a method that extends the non-linear two-view representation learning methods, and the linear multiview techniques, and combines information from multiple sources into a new non-li", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "645", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this paper authors propose a novel data augmentation scheme where instead of augmenting the input data, they augment intermediate feature representations. Sequence auto-encoder based features are c", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "524", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a simple method for pruning filters in two types of architecture to decrease the time for execution. Pros: - Impressively retains accuracy on popular models on ImageNet and Cifar10", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "324", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presented a modified knowledge distillation framework that minimizes the difference of the sum of statistics across the a feature map between the teacher and the student network. The authors", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "319", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a simple domain adaptation technique in which batch normalization is performed separately in each domain. Pros: The method is very simple and easy to understand and apply. The expe", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "736", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "After the discussion below, I looked at previous work by the authors (MUS-ROVER) on which this paper was based. On one hand, this was very helpful for me to better understand the current paper. On the", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 2, "ID": "474", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Update: I thank the authors for their comments! After reading them, I still think the paper is not novel enough so I'm leaving the rating untouched. This paper proposes a domain adaptation technique f", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "342", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I found this paper very original and thought-provoking, but also a bit difficult to understand. It is very exciting to see a practical use case for image-generating GANs, with potentially meaningful b", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "664", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is mainly a (well-written) toy application paper. It explains SGVB can be applied to state-space models. The main idea is to cast a state-space model as a deterministic temporal transformation, w", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "422", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper shows promising results but it is difficult to read and follow. It presents different things closely related and it is difficult to asses the performance of each one. Diversity, sparsity, re", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "365", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a transfer learning approach applied to a number of NLP tasks; the set of tasks appear to have an order in terms of complexity (from easy syntactic tasks to somewhat harder semanti", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "584", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I like the idea the paper is exploring. Nevertheless I see some issues with the analysis: - To get a better understanding of the quality of the results, I think at least some state-of-the-art comparis", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "762", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Updated review: the authors did an admirable job of responding to and incorporating reviewer feedback. In particular, they put a lot of effort into additional experiments, even incorporating a new and", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "579", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "SUMMARY. The paper propose a reading-comprehension question answering system for the recent QA task where answers of a question can be either single tokens or spans in the given text passage. The mode", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "590", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper provides an extensive analysis of the error loss function for different optimization methods. The presentation is well done and informative. The experimental procedure is clarified sufficie", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "556", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "It would seem that the shelf life of a dataset has decreased rapidly in recent literature. SQuAD dataset has been heavily pursued as soon as it hit online couple months ago, the best performance on th", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "601", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "First I would like to apologize for the delay in reviewing. summary : This work explores several experiments to transfer training a specific model of reading comprehension ( AS Reader), in an artifici", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "678", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is a dataset paper that brings unique values over existing reading comprehension challenges. Unlike others, MS MARCO is derived from query logs, thus represents real questions that people ask, ra", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "665", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents an interesting and very detailed study of targeted and non-targeted adversarial examples in CNNs. Im on the fence about this paper but am leaning towards acceptance. Such detailed e", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "465", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "[EDIT: The thoughtful author responses addressed my major concerns. The github links for data and code will be really helpful for reproducing results (I haven't looked carefully, but this is great). T", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "588", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "First, I'd like to thank the authors for their answers and clarifications. I find, the presentation of the multi-stage version of the model much clearer now. Pros: + The paper states a sparse coding p", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "549", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a new memory module for large scale life-long and one-shot learning. The module is general enough that the authors apply the module to several neural network architectures and show", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "372", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper extends the imitation learning paradigm to the case where the demonstrator and learner have different points of view. This is an important contribution, with several good applications. The m", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "341", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper explores the topic of intrinsic motivation in the context of deep RL. It proposes a couple of variants derived from an auxiliary model-learning process (prediction error, surprise and learn", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "533", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The paper presents a method to learn a low-dimensional state representations from raw obervation for multi-task setting. In contrast to classic multi-task learning setting where a joint representation", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "670", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "[ Summary ] This paper presents a new modified beam search algorithm that promotes diverse beam candidates. It is a well known problem with both RNNs and also non-neural language models that beam sear", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "644", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "While I understand the difficulty of collecting audio data from animals, I think this type of feature engineering does not go in the right direction. I would rather see a model than learns the feature", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "521", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper describes how to approximate the FastText approach such that its memory footprint is reduced by several orders of magnitude, while preserving its classification accuracy. The original FastT", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 1, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "657", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "SUMMARY. This paper proposes a new neural network architectures for solving the task of reading comprehension question answering where the goal is answering a questions regarding a given text passage.", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "384", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed The Gated Multimodal Unit (GMU) model for information fusion. The GMU learns to decide how modalities influence the activation of the unit using multiplicative gates. The paper col", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "503", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I think this build upon previous works, in the attempt of doing something similar to batch norm specific for RNNs. To me the experiments are not yet very convincing, I think is not clear this works be", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": 2, "ID": "519", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Authors present a parameterized variant of ELU and show that the proposed function helps to deal with vanishing gradients in deep networks in a way better than existing non-linearities. They present b", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "713", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Validity: The presented work seems technically valid. Code for matrix library sushi2 and DL library sukiyaki2 are on github, including live demos that run in your browser.", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "543", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is a good paper, well written, that presents a simple but effective approach to predict code properties from input output pairs. The experiments show superiority to the baseline, with speedup fac", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "439", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "The paper describes how to use a tensor factorization method called Tensor Train for modeling the interactions between features for supervised classification tasks. Tensor Train approximates tensors o", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "515", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "From my original comments: The results looks good but the baselines proposed are quite bad. For instance in the table 2 \"Misclassification rate for a 784-1024-1024-1024-10 \" the result for the FC with", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "487", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The submission proposes an interesting way to match synthetic data to real data in a GAN type architecture. The main novelty are parametric modules that emulate different transformations and artefact ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "537", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper experimentally investigates a slightly modified version of label smoothing technique for neural network training, and reports results on various tasks. Such smoothing idea is not new, but wa", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "668", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper conducts a detailed evaluation of different CNN architectures applied to image retrieval. The authors focus on testing various architectural choices, but do not propose or compare to end-to-", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "772", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an interesting idea for iteratively re-weighting the word representations in a document (hence the GRU-coded doc representation as well) with a simple multiplication operation. As ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "602", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper is about using denoising autoencoders to improve performance in GANs. In particular, the features as determined by the discriminator, of images generated by the generator, are fed into a de", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 5, "ID": "329", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a method to model time changing dynamics in collaborative filtering. Comments: 1) The main idea of the paper is build upon similar to a previous work by the same group of author (W", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "614", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary === This paper extends and analyzes the gradient regularizer of Hariharan and Girshick 2016. In that paper a regularizer was proposed which penalizes gradient magnitudes and it was shown to ai", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "750", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper addresses the practical problem of generating rare or unseen words in the context of language modeling. Since language follows a Zipfs law, most approaches limit the vocabulary (because of ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "770", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper studies the impact of using customized number representations on accuracy, speed, and energy consumption of neural network inference. Several standard computer vision architectures including", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "642", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors introduce a variant of the variational autoencoder (VAE) that models dataset-level latent variables. The idea is clearly motivated and well described. In my mind the greatest contribution ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "358", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is an interesting paper on a VAE framework for topic models. The main idea is to train a recognition model for the inference phase which, because of so called amortized inference can be much fast", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "366", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper is technically sound. It highlights well the strengths and weaknesses of the proposed simplified model. In terms of impact, its novelty is limited, in the sense that the authors did seeming", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "431", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Authors take the skip-graph architecture (Kiros 2015) and apply it to classifying labeled graphs (molecular graphs). They do it by creating many sentences by walking the graph randomly, and asking the", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "677", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors present a character language model that gains some interpretability without large losses in predictivity. CONTRIBUTION: I'd characterize the paper as some experimental investigation of a c", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "580", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a variant of a recurrent neural network that has two orthogonal temporal dimensions that can be used as a decoder to generate tree structures (including the topology) in an encoder", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "400", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "The paper proposes a method for pruning weights in neural networks during training to obtain sparse solutions. The approach is applied to an RNN-based system which is trained and evaluated on a speech", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "391", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an improved neural language models designed for selected long-term dependency, i.e., to predict more accurately the next identifier for the dynamic programming language such as Pyt", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "754", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a new method for estimating visual attention in videos. The input clip is first processed by a convnet (in particular, C3D) to extract visual features. The visual features are then", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "483", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this paper the authors propose a method to explicitly regularize sparse coding to encode neighbouring datapoints with similar sets of atoms from the dictionary by clustering training examples with ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "472", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed to perform finetuning in an augmentation fashion by freezing the original network and adding a new model aside it. The idea itself is interesting and complements existing training ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "701", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a new memory access scheme based on Lie group actions for NTMs. Pros: * Well written * Novel addressing scheme as an extension to NTM. * Seems to work slightly better than normal NT", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "403", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I'm torn on this one. Seeing the MPEG-7 dataset and references to curvature scale space brought to mind the old saying that \"if it's not worth doing, it's not worth doing well.\" There is no question t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "478", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents two models for extractive document summarization: the classifier architecture and the selector architecture. These two models basically use either classification or ranking in a se", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "702", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper deals with an interesting application of adversarial training to encryption. It considers the standard scenario of Alice, Eve and Bob, where A and B aim to exchange messages conditioned on a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "790", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes b-GAN, which trains a discriminator by estimating density ratio that minimizes Bregman divergence. The authors also discuss how b-GANs relate to f-GAN and the original GAN work, pr", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "563", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a new exciting layerwise origin-target synthesis method both for generating a large number of diverse adversarials as well as for understanding the robustness of various layers. The", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "634", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Use of ML in ITP is an interesting direction of research. Authors consider the problem of predicting whether a given statement would be useful in a proof of a conjecture or not. This is posed as a bin", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "494", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a method to reduce the memory footprint of a neural network at some increase in the computation cost. This paper is a generalization of HashedNets by Chen et al. (ICML'15) where par", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "686", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper is methodologically very interesting, and just based on the methodological contribution I would vote for acceptance. However, the paper's sweeping claims of clearly beating existing baselin", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "597", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a model for image generation where the back-ground is generated first and then the foreground is pasted in by generating first a foregound mask and corresponding appearance, curving", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "396", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I sincerely apologize for the late-arriving review. This paper proposes to frame the problem of structure estimation as a supervised classification problem. The input is an empirical covariance matrix", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "517", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes new bounds on the misclassification error. The bounds lead to training classifiers with an adaptive loss function, and the algorithm operates in successive steps: the parameters are", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "493", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I read the authors' response and maintain my rating. --- This paper introduces an approach for integrating a direct acyclic graph structure of the data into word / code embeddings, in order to leverag", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "667", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed a new joint training scheme for two probabilistic models of signals (e.g. images) which are both deep neural network based and are termed generator and descriptor networks. In the ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "633", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed a variant of the semi-supervised VAE model which leads to a unified objective for supervised and unsupervised VAE. This variant gives software implementation of these VAE models mo", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "593", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "First, let me praise the authors for generating and releasing an NLP data set: a socially useful task. The authors use an algorithm to generate a 500-cluster-per-language data set in semantic similari", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 2, "ID": "507", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "First, the bad: This paper is frustratingly written. The grammar is fine, but: - The first four pages are completely theoretical and difficult to follow without any concrete examples. These sections w", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "583", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper explores transfer in reinforcement learning between agents that may be morphologically distinct. The key idea is for the source and target agent to have learned a shared skill, and then to ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "331", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper provides a new perspective to understanding the ResNet and Highway net. The new perspective assumes that the blocks inside the networks with residual or skip-connection are groups of succes", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "338", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper aims to provide an insightful and analytic survey over the recent literature on reading comprehension with the distinct goal of investigating whether logical structure (or predication, as t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "696", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is a well-conducted and well-written study on the prediction of medication from diagnostic codes. The authors compared GRUs, LSTMs, feed-forward networks and random forests (making a case for why", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 3, "ID": "482", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an improved version of matching networks, with better scalability properties with respect to the support set of a few-shot classifier. Instead of considering each support point ind", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "559", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper first discusses a general framework for improving optimization of a complicated function using a series of approximations. If the series of approximations are well-behaved compared to the o", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "424", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a strategy for building deep neural networks via rules for expansion and merging of sub-networks. pros: - the idea is novel - the approach is described clearly cons: - the experime", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "449", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper is a follow-up on the NIPS 2016 paper \"Unsupervised learning of spoken language with visual context\", and does exactly what that paper proposes in its future work section: \"to perform acous", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "705", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 5, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I think that the paper is quite interesting and useful. It might benefit from additional investigations, e.g., by adding some rescaled Gaussian noise to gradients during the LB regime one can get adva", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "315", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a recurrent variational neural network approach to modelling volatility in financial time series. This model consists of an application of Chung et al.s (2015) VRNN model to volati", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "712", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper looks at several innovations for deep RL, and evaluates their effect on solving games in the Atari domain. The paper reads a bit like a laundry list of the researchers latest tricks. It is w", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "460", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper is straightforward, easy to read, and has clear results. Since all these parameterisations end up outputting torques, it seems like there shouldn't be much difference between them. There is ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "775", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a semi-supervised algorithm for regularizing deep convolutional neural networks. They propose an adversarial approach for image inpainting where the discriminator learns to identif", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "648", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 5, "COMMENTS": "- summary The paper proposes a differntiable Neural Physics Engine (NPE). The NPE consists of an encoder and a decoder function. The NPE takes as input the state of pairs of objects (within a neighbou", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "371", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a mechanism for active learning with convolutional neural networks (CNNs). I would not go as far as the authors in calling these \"deep\", seeing that they seem to have only 2 hidd", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "566", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose the use of statistics of softmax outputs to estimate the probability of error and probability of a test sample being out-of-domain. They contrast the performance of the proposed me", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "410", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I think the backbone of the paper is interesting and could lead to something potentially quite useful. I like the idea of connecting signal processing with recurrent network and then using tools from ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "564", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this paper, the authors proposed an implicit ResoNet model for knowledge base completion. The proposed model performs inference implicitly by a search controller and shared memory. The proposed app", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "596", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "*** Paper Summary *** The paper proposes to a new neural network architecture. The layer weights of a classical network are computed as a function of a latent representation associated with the layer.", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "499", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This paper proposes a new approaches for optimizing the objective of CNNs. The proposed method uses a lay-wise optimization, i.e. at each step, it optimizes the parameters in one layer of CNN while fi", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "412", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Authors learn deep architectures on a few small vision problems using Q-learning and obtain solid results, SOTA results when limiting to certain types of layers and competitive against everything else", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "383", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In supervised learning, a significant advance occurred when the framework of semi-supervised learning was adopted, which used the weaker approach of unsupervised learning to infer some property, such ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "360", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper describes a correction technique to combine updates from multiple SGD to make it statistically equivalent to sequential technique. Comments 1) The proposed method is novel and interesting t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "745", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed COCONET, which is a neural autoregressive model with convolution, to do music composition task. This paper also proposed to use blocked Gibbs sampling instead of the ancestral samp", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "621", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper is the first (I believe) to establish a simple yet important result that Convnets for NMT encoders can be competitive to RNNs. The authors present a convincing set of results over many tran", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": 3, "ID": "748", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a new neural architecture, called DRAGNN, for the transition-based framework. A DRAGNN uses TBRUs which are neural units to compute hidden activations for the current state of a tra", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "671", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed a compare-aggregate model for the NLP tasks that require semantically comparing the text sequences, such as question answering and textual entailment. The basic framework of this m", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "363", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper Strengths: -- Elegant use of MoE for expanding model capacity and enabling training large models necessary for exploiting very large datasets in a computationally feasible manner -- The effectiv", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "399", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduces a new dataset called MusicNet (presumably analogous to ImageNet), featuring dense ground truth labels for 30+ hours of classical music, which is provided as raw audio. Such a data", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 5, "ID": "409", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors study the use of low-rank approximation to the matrix-multiply in RNNs. This reduces the number of parameters by a large factor, and with a diagonal addition (called low-rank plus diagonal", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "594", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper Summary This paper makes two contributions - (1) A model for next step prediction, where the inputs and outputs are in the space of affine transforms between adjacent frames. (2) An evaluation m", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "612", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed two incremental ideas to extend the current state-of-the-art summarization work based on seq2seq models with attention and copy/pointer mechanisms. 1. This paper introduces 2-pass ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "630", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a new way of transferring knowledge. I like the idea of transferring attention maps instead of activations. However, the experiments dont show a big improvement compared with knowle", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "319", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Pros: * Clearly written. * New model mLSTM which seems to be useful according to the results. * Some interesting experiments on big data. Cons: * Number of parameters in comparisons of different model", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "527", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an interesting framework (as a follow-up work of the author's previous paper) to learn compositional rules used to compose better music. The system consists of two components, a ge", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "474", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper builds connections between DNN, simplified stochastic neural network (SFNN) and SFNN and proposes to use DNN as the initialization model for simplified SFNN. The authors evaluated their mod", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "725", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper investigate the phenomenon of the adversarial examples and the adversarial training on the dataset of ImageNet. While the final conclusions are still vague, this paper raises several notewo", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "481", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper theoretically justified a faster convergence (in terms of average gradient norm attained after processing a fixed number of samples) of using small mini-batches for SGD or ASGD with smaller", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "653", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "this proposes a multi-view learning approach for learning representations for acoustic sequences. they investigate the use of bidirectional LSTM with contrastive losses. experiments show improvement o", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "408", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper combines variational RNN (VRNN) and domain adversarial networks (DANN) for domain adaptation in the sequence modelling domain. The VRNN is used to learn representations for sequential data,", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "342", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Combining storage and processing capabilities is an interesting research topic because data transfer is a major issue for many machine learning tasks. The paper itself is well-written, but unfortunate", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 2, "ID": "553", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work introduces a number of techniques to compress fully-connected neural networks while maintaining similar performance, including a density-diversity penalty and associated training algorithm. ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "365", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "SYNOPSIS: The authors introduce an efficient approximation to the softmax function that speeds up the empirical calculation of the softmax on GPUs. They leverage the unbalanced distribution of words a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "523", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors present a well thought out and constructed system for performing lipreading. The primary novelty is the end-to-end nature of the system for lipreading, with the sentence-level prediction a", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "694", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The proposed self supervised loss is formulated using a Siamese architecture and encourages patches from the same image to lie closer in feature space than a contrasting patch taken from a different, ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "791", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I think the problem here is well motivated, the approach is insightful and intuitive, and the results are convincing of the approach (although lacking in variety of applications). I like the fact that", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "374", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work proposes to compute embeddings of symbolic expressions (e.g., boolean expressions, or polynomials) such that semantically equivalent expressions are near each other in the embedded space. Th", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "538", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Thank you for an interesting read. I personally like the information bottleneck principle and am very happy to see its application to deep neural networks. To my knowledge, this is the first paper tha", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "442", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a theoretically well motivated for visualizing what parts of the input feature map are responsible for the output decision. The key insight is that features that maximally change th", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "427", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper Summary: This paper presents a new comprehension dataset called NewsQA dataset, containing 100,000 question-answer pairs from over 10,000 news articles from CNN. The dataset is collected through", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "601", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper Summary: This paper presents a new large scale machine reading comprehension dataset called MS MARCO. It is different from existing datasets in that the questions are real user queries, the cont", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "665", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This papers adds to the literature on learning optimizers/algorithms that has gained popularity recently. The authors choose to use the framework of guided policy search at the meta-level to train the", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "362", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This paper proposed a neural attention model which has a learnable and differentiable sampling lattice. The work is well motivated as few previous work focus on learning the sampling lattice but with ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "334", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper provides a surprise-based intrinsic reward method for reinforcement learning, along with two practical algorithms for estimating those rewards. The ideas are similar to previous work in int", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "533", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper is about learning unsupervised state representations using multi-task reinforcement learning. The authors propose a novel approach combining gated neural networks with multitask learning wi", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "670", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper considers the problem of decoding diverge solutions from neural sequence models. It basically adds an additional term to the log-likelihood of standard neural sequence models, and this addi", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "644", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper looks at the problem of locating the answer to a question in a text (For this task the answer is always part of the input text). For this the paper proposes to combine two existing works: Ma", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "384", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes an extension of weight normalization / normalization propagation to recurrent neural networks. Simple experiments suggest it works well. The contribution is potentially useful to a ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "519", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed a synchronous parallel SGD by employing several backup machines. The parameter server does not have to wait for the return from all machines to perform the update on the model, whi", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "783", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a weakly supervised, end-to-end neural network model for solving a challenging natural language understanding task. As an extension of the Neural Programmer, this work aims at over", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "436", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "Authors propose the use of layer-wise language model-like pretraining for encoder-decoder models. This allows to leverage separate source and target corpora (in unsupervised manner) without necessity ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 1, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "709", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "Summary: This paper introduces a heuristic approach for training a deep directed generative model, where similar to the transition operator of a Markov chain each layer samples from the same condition", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "325", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a polynomial linear model for supervised classification tasks. The model is based on a combination of the Tensor Train (TT) tensor decomposition method and a form of stochastic R", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "515", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "Authors propose a neural pruning technique starting from trained models using an approximation of change in the cost function and outperform other criteria. Authors obtain solid speedups while maintai", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "381", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: There are many different pruning techniques to reduce memory footprint of CNN models, and those techniques have different granularities (layer, maps, kernel or intra kernel), pruning ratio an", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "715", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this paper the authors propose various techniques to sample visualizations from generative models with high dimensional latent spaces like VAEs and GANs. For example, the authors highlight the well", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": 2, "ID": "774", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper builds on the work of Weston (2016), using End-to-end memory network models for a limited form of dialogue with teacher feedback. As the authors state in the comments, it is closely related", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "445", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Comments: \"This contrasts to adversarial attacks on classifiers, where any inspection of the inputs will reveal the original bytes the adversary supplied, which often have telltale noise\" Is this real", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "572", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper extends neural conversational models into the batch reinforcement learning setting. The idea is that you can collect human scoring data for some responses from a dialogue model, however suc", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "471", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper applies the pointer network architecturewherein an attention mechanism is fashioned to point to elements of an input sequence, allowing a decoder to output said elementsin order to solve si", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "597", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a novel method to learn vision feature as intermediate rewards to guide the robot training in the real world. Since there are only a few sequences of human demonstrations, the pape", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "504", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper applies the idea of normalizing flows (NFs), which allows us to build complex densities with tractable likelihoods, to maximum entropy constrained optimization. The paper is clearly written", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "416", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Quality: The paper initiates a framework to incorporate active learning into the deep learning framework, mainly addressing challenges such as scalability that accompanies the training of a deep neura", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "566", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Thank you for an interesting read. To my knowledge, very few papers have looked at transfer learning with **no** target domain data (the authors called this task as \"extrapolation\"). This paper clearl", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "546", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a way to model the distribution of four-part Bach chorales using Convolutional Neural Networks. Furthermore it addresses the task of artificial music generation by sampling from the", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "621", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents an analysis of the ability of deep networks with ReLU functions to represent particular types of low-dimensional manifolds. Specifically, the paper focuses on what the authors call ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "485", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors proposed a dynamic neural Turing machine (D-NTM) model that overcomes the rigid location-based memory access used in the original NTM model. The paper has two main contributions: 1) introd", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "662", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors present an online learning method for learning the structure of sum-product networks. The algorithm assumes Gaussian coordinate-wise marginal distributions, and learns both parameters and ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "525", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a theoretical treatment of transformation groups applied to convnets, and presents some empirical results showing more efficient usage of network parameters. The basic idea of stee", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "348", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper describes a method to evaluate generative models such as VAE, GAN and GMMN. This is very much needed in our community where we still eyeball generated images to judge the quality of a model.", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "368", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper studies knowledge transfer problem from small capacity network to bigger one. This is a follow-up work of Net2Net (ICLR 2015) and NetMorph(ICML 2016). Comments - 1) This paper studies macro", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": 4, "ID": "540", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper was easy to read, the main idea was presented very clearly. The main points of the paper (and my concerns are below) can be summarized as follows: 1. synchronous algoriths suffer from some ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "783", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work finds a connection between Bourgain's junta problem, the existing results in circuit complexity, and the approximation of a boolean function using two-layer neural net. I think that finding ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "536", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduces a novel memory mechanism for NTMs based on differentiable Lie groups. This allows to place memory elements as points on a manifold, while still allowing training with backpropagat", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "403", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a modified gated RNN caled GRU-D that deals with time series which display a lot of missing values in their input. They work on two fronts. The first deals with the missing inputs ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "599", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper claims improved inference for density estimation of sparse data (here text documents) using deep generative Gaussian models (variational auto-encoders), and a method for deriving word embedd", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "595", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper explores a simple approach to learning reward functions for reinforcement learning from visual observations of expert trajectories for cases were only little training data is available. To o", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "504", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper combines a hierarchical Variational Autoencoder with PixelCNNs to model the distribution of natural images. They report good (although not state of the art) likelihoods on natural images and", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "353", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The method in this paper introduces a binary encoding level in the PV-DBOW and PV-DM document embedding methods (from Le & Mikolov'14). The binary encoding consists in a sigmoid with trained parameter", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "731", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "The paper presents an interesting new problem setup for imitation learning: an agent tries to imitate a trajectory demonstrated by an expert but said trajectory is demonstrated in a different state or", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "341", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a weakly supervised, end-to-end neural network model to learn a natural language interface for tables. The neural programmer is applied to the WikiTableQuestions, a natural languag", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "436", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper addresses the question of how to utilize physical interactions to answer questions about physical outcomes. This question falls into a popular stream in ML community -- understanding physic", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "377", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper looks at the problem of transferring a policy learned in a simulator to a target real-world system. The proposed approach considers using an ensemble of simulated source domains, along with ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "406", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes to use the tensor train (TT) decomposition to represent the full polynomial linear model. The TT form can reduce the computation complexity in both of inference and model training.", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "515", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work proposes a pattern extraction method to both understand what a trained LSTM has learnt and to allow implementation of a hand-coded algorithm that performs similarly to the LSTM. Good results", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "444", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper shows how policy gradient and Q-Learning may be combined together, improving learning as demonstrated in particular in the Atari Learning Environment. The core idea is to note that entropy-", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "432", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper shows that a deep RL approach augmented with auxiliary tasks improves performance on navigation in complex environments. Specifically, A3C is used for the RL problem, and the agent is simul", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "438", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper is well written, and well presented. This method is using denoise autoencoder to learn an implicit probability distribution helps reduce training difficulty, which is neat. In my view, join", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "329", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper uses Tensors to build generative models. The main idea is to divide the input into regions represented with mixture models, and represent the joint distribution of the mixture components wi", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "689", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper studies the energy landscape of the loss function in neural networks. It is generally clearly written and nicely provides intuitions for the results. One main contribution is to show that t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "451", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a novel and interesting way to tackle the difficulties of performing inference atop HSMM. The idea of using an embedded bi-RNN to approximate the posterior is a reasonable and clev", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "421", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces an analytical performance model to estimate the training and evaluation time of a given network for different software, hardware and communication strategies. The paper is very c", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "431", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "1) Summary This paper investigates the usefulness of decoupling appearance and motion information for the problem of future frame prediction in natural videos. The method introduces a novel two-stream", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "357", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper sets out to tackle the program synthesis problem: given a set of input/output pairs discover the program that generated them. The authors propose a bipartite model, with one component that ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "356", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes augmenting RNN-based language models with a pointer network in order to deal better with rare words. The pointer network can point to words in the recent context, and hence the pre", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "490", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 5, "COMMENTS": "This paper presents a model for semi-supervised learning by encouraging feature invariance to stochastic perturbations of the network and/or inputs. Two models are described: One where an invariance t", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "461", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "SUMMARY This paper addresses important questions about the difficulties in training generative adversarial networks. It discusses consequences of using an asymmetric divergence function and sources of", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "308", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "The authors formulate a recurrent deep neural network to predict human fixation locations in videos as a mixture of Gaussians. They train the model using maximum likelihood with actual fixation data. ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "483", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The work proposes to use the geometry of data (that is considered to be known a priori) in order to have more consistent sparse coding. Namely, two data samples that are similar or neighbours, should ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "472", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a nonparametric neural network model, which automatically learns the size of the model during the training process. The key idea is to randomly add zero units and use sparse regula", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "322", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents an amortised MAP estimation method for SR problems. By learning a neural network which learns to project to an affine subspace of SR solutions which are consistent with the LR metho", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "317", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a nice dataset/data generator that creates bAbI like tasks, except where the questioning answering agent is required to clarify the values of some variables in order to succeed. ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "349", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes to use an empirical Bayesian approach to learn the parameters of a neural network, and their priors. A mixture model prior over the weights leads to a clustering effect in the weig", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "345", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper examines the so called \"Sample Importance\" of each sample of a training data set, and its effect to the overall learning process. The paper shows empirical results that shows different trai", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "591", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this paper, the authors explicitly design geometrical structure into a CNN by combining it with a Scattering network. This aids stability and limited-data performance. The paper is well written, th", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "656", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a conceptually simple method for regularisation of recurrent neural networks. The idea is related to dropout, but instead of zeroing out units, they are instead set to their respec", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "394", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is an 18 page paper plus appendix which presents a mathematical derivation for infomax for an actual neural population with noise. The original Bell & Sejnowski infomax framework only considered ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "335", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "*Edited the score 6->7. The paper presents a method for hierarchical RL using stochastic neural networks. The paper has introduced using information-theoretic measure of option identifiability as an a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "321", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Thank you for an interesting angle on highway and residual networks. This paper shows a new angle to how and what kind of representations are learnt at each layer in the aforementioned models. Due to ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "338", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a simple way to reweight the word embedding in the simple composition function for sentence representation. This paper also shows the connection between this new weighting scheme a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "375", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces an energy-based Generative Adversarial Network (GAN) and provides theoretical and empirical results modeling a number of image datasets (including large-scale versions of categor", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "455", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper studies the off-policy learning of actor-critic with experience replay. This is an important and challenging problem in order to improve the sample efficiency of the reinforcement learning ", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "460", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "UPDATE: The authors addressed all my concerns in the new version of the paper, so I raised my score and now recommend acceptance. -------------- This paper combines the recent progress in variational ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "353", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Thank you for an interesting read. Pros - This paper tackles a very crucial problem of understanding communications between 2 agents. As more and more applications of reinforcement learning are being ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "310", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper provides a principled framework for nonparametrically learning activation functions in deep neural networks. A theoretical justification for authors' choice of nonparametric activation func", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "512", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Encouraging orthogonality in weight features has been reported useful for deep networks in many previous works. The authors present a explicit regularization cost to achieve de-correlation among weigh", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "415", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "1) Summary This paper proposes a video captioning model based on a 3D (space+time) convnet (C3D) encoder and a LSTM decoder. The authors investigate the benefits of using attention mechanisms operatin", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "535", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 5, "COMMENTS": "The paper develops a simple and reasonable algorithm for graph node prediction/classification. The formulations are very intuitive and lead to a simple CNN based training and can easily leverage exist", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "486", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons. Paper summary: this work proposes to use RNNs inside a convoluti", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "631", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "After reading the rebuttal, I decided to increase my score. I think ALI somehow stabilizes the GAN training as demonstrated in Fig. 8 and learns a reasonable inference network. --------------- Initial", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "446", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a relation network (RN) to model relations between input entities such as objects. The relation network is built in two stages. First a lower-level structure analyzes a pair of inp", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "530", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The main contribution of this paper is a construction to eps-approximate a piecewise smooth function with a multilayer neural network that uses O(log(1/eps)) layers and O(poly log(1/eps)) hidden units", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "495", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents an investigation of various neural language models designed to query context information from their recent history using an attention mechanism. The authors propose to separate the ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "420", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: The paper presents a smaller CNN architecture called SqueezeNet for embedded deployment. The paper explores CNN macroarchitecture and microarchitecture to develop SqueezeNet, which is compose", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "737", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper discusses Hyperband, an extension of successive halving by Jamieson & Talwalkar (AISTATS 2016). Successive halving is a very nice algorithm that starts evaluating many configurations and re", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "402", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a compare-aggregate framework that performs word-level matching followed by aggregation with convolutional neural networks. It compares six different comparison functions and evalu", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "363", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper proposes a method for significantly increasing the number of parameters in a single layer while keeping computation in par with (or even less than) current SOTA models. The idea is based on", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "399", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a new idea to help defending adversarial examples by training a complementary classifier to detect them. The results of the paper show that adversarial examples in fact can be easi", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "462", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "It is interesting to derive such a bound and show it satisfies a regret bound along with empirical evidence on the CIFAR-10 for cross entropy loss and auto encoder for MSE loss. At least empirically, ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "526", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The concept of data augmentation in the embedding space is very interesting. The method is well presented and also justified on different tasks such as spoken digits and image recognition etc. One com", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "524", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper prunes entire groups of filters in CNN so that they reduce computational cost and at the same time do not result in sparse connectivity. This result is important to speed up and compress ne", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "324", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a parameterization of CNNs that guarantees equivariance wrt a large family of geometric transformations. The mathematical analysis is rigorous and the material is very interesting ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "348", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this paper, the authors use a separate introspection neural network to predict the future value of the weights directly from their past history. The introspection network is trained on the paramete", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "401", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents works on neural network / CNN architecture morphing. Results are not reported on ImageNet larger ResNet and new network architecture such as Xception and DenseNet - which are maybe", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "540", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduces a new regularization term which encourages the optimizer to search for a flat local minimum of reasonably low loss instead of seeking a sharp region of a low loss. This is motivat", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "458", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is a parallel work with ALI. The idea is using auto encoder to provide extra information for discriminator. This approach seems is promising from reported result. For feature learning part of BiG", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "467", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents new way for compressing CNN weights. In particular this paper uses a new neural network quantization method that compresses network weights to ternary values. The group has recentl", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "369", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a novel way to do unsupervised pretraining in a deep convolutional network setting (though likely applicable to fully-connected nets as well). The method is that of spatial constra", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "791", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 2, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper attempts to understand and visualize what deep nets are representing as one ascends from low levels to high levels of the network. As has been shown previously, lower levels are more local ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 1, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "717", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "1) Summary This paper proposes to tackle visual servoing (specifically target following) using spatial feature maps from convolutional networks pre-trained on general image classification tasks. The a", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 4, "ID": "320", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "SUMMARY. The paper proposes a gating mechanism to combine word embeddings with character-level word representations. The gating mechanism uses features associated to a word to decided which word repre", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "374", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper describes a way to speed up convergence through sudden increases of otherwise monotonically decreasing learning rates. Several techniques are presented in a clear way and parameterized meth", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "435", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper present an experimental study of the robustness of state-of-the-art CNNs to different types of \"attacks\" in the context of image classication. Specifically, an attack aims to fool the class", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "465", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The current version of the paper is improved w.r.t. the original arXiv version from June. While the results are exactly the same, the text does not oversell them as much as before. You may also consid", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "362", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper shows that BN, which does not work out of the box for RNNs, can be used with LSTM when the operator is applied to the hidden-to-hidden and the input-to-hidden contribution separately. Experi", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "434", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper investigates the impact of orthogonal weight matrices on learning dynamics in RNNs. The paper proposes a variety of interesting optimization formulations that enforce orthogonality in the r", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "560", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: The paper presents a deep neural network for the task of machine comprehension on the SQuAD dataset. The proposed model is based on two previous works -- match-LSTM and Pointer Net. Match-LST", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "384", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduce a variant of A3C model where while agents run on multiple cores on CPU the model computations which is the computationally intensive part is passed to the GPU. And they perform va", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "437", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a new non-linear function for CNN and deep neural networks. The new non-linearity reports some gains on most datasets of interest, and can be used in production networks with minim", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "713", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a JavaScript framework including WebCL components for training and deploying deep neural networks. The authors show that it is possible to reach competitive speeds with this techno", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "543", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed a proximal (quasi-) Newtons method to learn binary DNN. The main contribution is to combine pre-conditioning with binarization in a proximal framework. It is interesting to have a ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "453", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper addresses systematic discrepancies between simulated and real-world policy control domains. Proposed method contains two ideas: 1) training on an ensemble of models in an adversarial fashion to ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "406", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a novel method for extracting rule-based classifiers from trained LSTM models. The proposed method is applied to a factoid question-answering task, where it is demonstrated that th", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "444", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "Experimental results look reasonable, validated on 3 tasks. References could be improved, for example I would rather see Rumelhart's paper cited for back-propagation than the Deep Learning book.", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "487", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": 5, "COMMENTS": "This paper presents design decisions of TerpreT [1] and experiments about learning simple loop programs and list manipulation tasks. The TerpreT line of work (is one of those which) bridges the gap be", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "528", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "SUMMARY. The paper proposes a machine reading approach for cloze-style question answering. The proposed system first encodes the query and the document using a bidirectional gru. These two representat", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "602", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper is easy to follow, Idea is pretty clear and makes sense. Experimental results are hard to judge, it would be nice to have other baselines. For faster training convergence, the question is how we", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "532", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors present a way to complement the Gerative Adversarial Network traning procedure with an additional term based on denoising autoencoders. The use of denoising autoencoders is motivated by th", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "329", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "First I would like to apologize for the delay in reviewing. Summary : this work introduces a novel memory based artificial neural network for reading comprehension. Experiments show improvement on sta", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "479", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I don't have much to add to my pre-review questions. The main thing I'd like to see that would strengthen my review further is a larger scale evaluation, more discussion of the hyperparameters, etc. W", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "354", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a novel model for unsupervised segmentation and classification of time series data. A recurrent hidden semi-markov model is proposed. This extends regular hidden semi-markov models", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "421", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a simple modification of online dictionary learning: inspired by neurogenesis, they propose to add steps of atom addition, or atom deletion, in order to extent the online dictionar", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "643", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a method to learn graph embeddings in a unsupervised way using random walks. It is well written and the execution appears quite accurate. The area of learning whole graph representa", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "677", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposed a tensor factorization approach for MTL to learn cross task structures for better generalization. The presentation is clean and clear and experimental justification is convincing. A", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "459", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This submission proposes to learn the word decomposition, or word to sub-word sequence mapping jointly with the attention based sequence-to-sequence model. A particular feature of this approach is tha", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "430", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper discusses aligning word vectors across language when those embeddings have been learned independently in monolingual settings. There are reasonable scenarios in which such a strategy could ", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "426", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a novel RNN architecture named QRNN. QNNs are similar to gated RNN , however their gate and state update functions depend only on the recent input values, it does not depend on t", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "404", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I'd like to thank the authors for their detailed response to my questions. The paper proposes a support regularized version of sparse coding that takes into account the underlying manifold structure o", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "472", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a method to learn both a model and inference procedure at the same time with recurrent neural networks in the context of inverse problems. The proposed method is interesting and re", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "647", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The Neural Turing Machine and related external memory models have demonstrated an ability to learn algorithmic solutions by utilizing differentiable analogues of conventional memory structures. In par", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "403", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes learning document embeddings as a sum of the constituent word embeddings, which are jointly learned and randomly dropped out ('corrupted') during training. While none of the pieces", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "330", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I would like first to apologize for the delay. Summary: A framework for two-samples statistical test using binary classification is proposed. It allows multi-dimensional sample testing and an interpre", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "450", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors describe a dataset of proof steps in higher order logic derived from a set of proven theorems. The success of methods like AlphaGo suggests that for hard combinatorial style problems, havi", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "494", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Thanks a lot for your detailed response and clarifications. The paper proposes to use a scattering transform as the lower layers of a deep network. This fixed representation enjoys good geometric prop", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "656", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a new algorithm based on REINFORCE which aims at exploring under-appreciate action sequences. The idea is to compare the probability of a sequence of actions under the current polic", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "378", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a method that generates naturally looking images by first generating the background and then conditioned on the previous layer one or multiple foreground objects. Additionally they", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "396", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a novel algorithm to estimate graph structures by using a convolutional neural network to approximate the function that maps from empirical covariance matrix to the sparsity pattern", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "517", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors present a simple method to affix a cache to neural language models, which provides in effect a copying mechanism from recently used words. Unlike much related work in neural networks with ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 4, "APPROPRIATENESS": 2, "ID": "339", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a recurrent architecture for simultaneously predicting motion and action states of agents. The paper is well written, clear in its presentation and backed up by good experiments. T", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "480", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is a well written, organized, and presented paper that I enjoyed reading. I commend the authors on their attention to the narrative and the explanations. While it did not present any new methodol", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "482", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Update: After reading the rebuttal comments and the revised paper, I'm leaving the rating as it was before. This paper proposes an unsupervised algorithm for transferring samples from one domain to an", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "340", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors show that the idea of smoothing a highly non-convex loss function can make deep neural networks easier to train. The paper is well-written, the idea is carefully analyzed, and the experime", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "424", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This submission investigates the usability of cortical-inspired distant bigram representations for handwritten word recognition. Instead of generating neural network based posterior features for chara", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "723", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: This paper on autoregressive generative models explores various extensions of PixelCNNs. The proposed changes are to replace the softmax function with a logistic mixture model, to use dropout", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "336", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper addressed the erroneous label problem for supervised training. The problem is well formulated and the presented solution is novel. The experimental justification is limited. The effectivenes", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "463", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this interesting paper the authors explore the idea of using an ensemble of multiple discriminators in generative adversarial network training. This comes with a number of benefits, mainly being ab", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "423", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 5, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper proposes a neural physics engine (NPE). NPE provides a factorization of physical scene into composable object-based representations. NPE predicts a future state of the given object as a function", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "371", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper provides a simple method to handle action repetitions. They make the action a tuple (a,x), where a is the action chosen, and x the number of repetitions. Overall they report some improvemen", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "452", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a learning algorithm for micromanagement of battle scenarios in real-time strategy games. It focuses on a complex sub-problem of the full RTS problem. The assumptions and restrictio", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "344", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This is a solid paper that applies A3C to Doom, enhancing it with a collection of tricks so as to win one of the VizDoom competitions. I think it is fair to expect the competition aspect to overshadow", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "355", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The author attacks the problem of shallow binary autoencoders using a minmax game approach. The algorithm, though simple, appears to be very effective. The paper is well written and has sound analyses", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "367", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a new Bayesian neural network architecture for predicting the values of learning curves during the training of machine learning models. This is an exploratory paper, in that the ul", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "361", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "To train natural language systems by putting multiple agents within an interactive referential communication game is very nice. As the authors mention, there has been some (although seemingly not much", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "310", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The author proposed a simple but yet effective technique in order to regularized neural networks. The results obtained are quite good and the technique shows to be effective when it it applied even on", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "415", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduces a method for semi-supervised learning in graphs that exploits the spectral structure of the graph in a convolutional NN implementation. The proposed algorithm has a limited comple", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "486", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an interesting new method for training neural networks, i.e., a hypernetwork is used to generate the model parameters of the main network. The authors demonstrated that the total n", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "499", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: In this paper, the authors study ResNets through a theoretical formulation of a spin glass model. The conclusions are that ResNets behave as an ensemble of shallow networks at the start of tr", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "622", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work introduces a novel method for training GANs by displacing simultaneous SGD, and unrolling the inner optimization in the minmax game as a computational graph. The paper is very clearly writte", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "418", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Nice idea but not complete, model size is not reduced by the large factors found in one of your references (Song 2016), where they go to 5 bits, but this is ontop of pruning which gives overall 49X re", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "457", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is a parallel work with BiGAN. The idea is using auto encoder to provide extra information for discriminator. This approach seems is promising from reported result.", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "446", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper shows: 1. Easy, constructive proofs to derive e-error upper-bounds on neural networks with O(log 1/e) layers and O(log 1/e) ReLU units. 2. Extensions of the previous results to more general", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "495", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Thank you for an interesting perspective on the neural approaches to approximate physical phenomenon. This paper describes a method to extrapolate a given dataset and predict formulae with naturally o", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "546", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper focusses on attention for neural language modeling and has two major contributions: 1. Authors propose to use separate key, value, and predict vectors for attention mechanism instead of a s", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "420", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 5, "SUBSTANCE": 5, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The Squeezenet paper came out in Feb 2016, and I read it with interest. It has a series of completely reasonable engineering suggestions for how to save parameter memory for CNNs for object recognitio", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "737", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "SUMMARY This paper discusses how data from a special type of low dimensional structure (monotonic chain) can be efficiently represented in terms of neural networks with two hidden layers. PROS Interes", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "485", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work proposed a simple but strong baseline for parametric texture synthesis. In empirical experiments, samples generated by the baseline composed by multi-scale and random filters sometime rival ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "333", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "CONTRIBUTIONS Large-scale experiments are used to measure the capacity and trainability of different RNN architectures. Capacity experiments suggest that across all architectures, RNNs can store betwe", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "376", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces dropout as a latent variable model (LVM). Leveraging this formulation authors analyze the dropout inference gap which they define to be the gap between network output during trai", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "498", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper describes a method for greatly expanding network model size (in terms of number of stored parameters) in the context of a recurrent net, by applying a Mixture of Experts between recurrent n", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "399", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper addresses the important problem (d>>n) in deep learning. The proposed approach, based on lower-dimensional feature embeddings, is reasonable and makes applying deep learning methods to data ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "351", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper adopts Taylor approximations of neural nets for separating convex and non-convex components of the optimization. This enables them to bound the training error by the Taylor optimum and regr", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "526", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Disclosure: I am not an expert in machine translation algorithms. Summary: A human translator does not come up with the final translation right away. Instead, (s)he uses an iterative process, starting", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "776", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: This paper describes how to estimate log-likelihoods of currently popular decoder-based generative models using annealed importance sampling (AIS) and HMC. It validates the method using bidir", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "368", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper has two main contributions: (1) Applying adversarial training to imagenet, a larger dataset than previously considered (2) Comparing different adversarial training approaches, focusing impo", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": 5, "ID": "481", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "The paper proposes a methodology for morphing a trained network to different architecture without having to retrain from scratch. The manuscript reads well and the description is easy to follow. Howev", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "540", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents one of the first neural translation systems that operates purely at the character-level, another one being", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "680", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper provides an interesting idea, which extends GAN by taking into account bidirectional network. Totally, the paper is well-written, and easy to follow what is contribution of this paper. From", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "467", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "he authors provide an interesting, computational-complexity-driven approach for efficient softmax computation for language modeling based on GPUs. An adaptive softmax approach is proposed based on a h", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "523", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper describes a simple but clever method for allowing variable amounts of computation at each time step in RNNs. The new architecture seems to outperform vanilla RNNs on various sequence modell", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "441", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work presents a novel ternary weight quantization approach which quantizes weights to either 0 or one of two layer specific learned values. Unlike past work, these quantized values are separate a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "369", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper provides a theoretical framework for tying parameters between input word embeddings and output word representations in the softmax. Experiments on PTB shows significant improvement. The ide", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 1, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "473", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an algorithm for approximating the solution of certain time-evolution PDEs. The paper presents an interesting learning-based approach to solve such PDEs. The idea is to alternate b", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "511", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This review is only an informed guess - unfortunately I cannot assess the paper due to my lack of understanding of the paper. I have spent several hours trying to read this paper - but it has not been", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "514", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 5, "COMMENTS": "Deep RL (using deep neural networks for function approximators in RL algorithms) have had a number of successes solving RL in large state spaces. This empirically driven work builds on these approache", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "314", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a new gating mechanism to combine word and character representations. The proposed model sets a new state-of-the-art on the CBT dataset; the new gating mechanism also improves over", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "374", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a theoretical framework to analyze the recoverability of sparse activations in intermediate layers of deep networks, using theoretical tools from compressed sensing. They relate th", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "674", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a new model to learn symbolic expression representations. They do a reasonably extensive evaluation with similar approaches and motivate their approach well. As expressed in the pr", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "538", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a novel neural network compression technique. The goal is to compress maximally the network specification via parameter quantisation with a minimum impact on the expected loss. It ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "468", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Building on earlier work on a model called NICE, this paper presents an approach to constructing deep feed-forward generative models. The model is evaluated on several datasets. While it does not achi", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "433", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper investigates a simple extension of Gatys et al. CNN-based texture descriptors for image generation. Similar to Gatys et al., the method uses as texture descriptor the empirical intra-channel", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "387", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an approach to learning a custom optimizer for a given class optimization problems. I think in the case of training machine learning algorithms, a class would represent a model lik", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "362", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Contributions The paper presents an adaptation of batch normalization for RNNs in the case of LSTMs, along the horizontal depth. Contrary to previous work from (Laurent 2015; Amodei 2016), the work de", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "434", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work focuses on conditional image synthesis in the autoregressive framework. Based on PixelCNN, it trains models that condition on text as well as segmentation masks or keypoints. Experiments sho", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "520", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed to use a simple count-based exploration technique in high-dimensional RL application (e.g., Atari Games). The counting is based on state hash, which implicitly groups (quantizes) s", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "558", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a Variational Autoencoder model that can discard information found irrelevant, in order to learn interesting global representations of the data. This can be seen as a lossy compres", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "397", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper poses an interesting idea: removing chaotic behavior or RNNs. While many other papers on new RNN architecture usually focus too much on the performance improvement and leave the analysis pa", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "398", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Taking into account the loss in the binarization step through a proximal Newton algorithm is a nice idea. This is at least one approach to bringing in the missing loss in the binarization step, which ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "453", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This works applies steerable frames for various tasks where convolutional neural networks with location invariant operators are traditionally applied. Authors provide a detailed overview of steerable ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "618", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes RaSoR, a method to efficiently representing and scoring all possible spans in an extractive QA task. While the test set results on SQuAD have not been released, it looks likely tha", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "711", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "Authors describe implementation of TensorFlow Fold which allows one to run various computations without modifying computation graph. They achieve this by creating a generic scheduler as a TensorFlow c", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "379", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "EDIT: the revisions made to this paper are very thorough and address many of my concerns, and the paper is also easier to understand. i recommend the latest version of this paper for acceptance and ha", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "444", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an autoencoder approach to lossy image compression by minimizing the weighted sum of reconstruction error and code length. The architecture consists of a convolutional encoder and ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "392", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "Authors propose a strategy for pruning weights with the eventual goal of reducing GFLOP computations. The pruning strategy is well motivated using the taylor expansion of the neural network function w", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 2, "APPROPRIATENESS": null, "ID": "381", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Nice paper, exploring the connection between value-based methods and policy gradients, formalizing the relation between the softmax-like policy induced by the Q-values and a regularized form of PG. Pr", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "432", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "On one hand this paper is fairly standard in that it uses deep metric learning with a Siamese architecture. On the other, the connections to human perception involving persistence is quite interesting", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "332", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "The paper considers the problem of reinforcement learning where the number of policy updates is required to be low. The problem is well motivated and the author provides an interesting modification to", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": 3, "ID": "688", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Overall the paper address an important problem: how to evaluate more appropriately automatic dialogue responses given the fact that current practice to automatically evaluate (BLEU, METEOR, ...) is of", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "502", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This paper proposed an iterative query updating mechanism for cloze-style QA. The approach is novel and interesting and while it is only verified in the paper for two Cloze-style tasks (CBT and WDW), ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "479", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Putting the score for now, will post the full review tomorrow.", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "421", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduces a simulator and a set of synthetic question answering tasks where interaction with the \"teacher\" via asking questions is desired. The motivation is that an intelligent agent can i", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "447", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper details an implementation of sparse-full convolutions and a model to work out the potential speed-up of various sparsity levels for CNNs. The first contribution is more about engineering, bu", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "469", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces an approach for future frame prediction in videos by decoupling motion and content to be encoded separately, and additionally using multi-scale residual connections. Qualitative ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "357", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces an approach to reinforcement learning and control wherein, rather than training a single controller to perform a task, a metacontroller with access to a base-level controller and", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "390", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper discusses how to guarantee privacy for training data. In the proposed approach multiple models trained with disjoint datasets are used as ``teachers'' model, which will train a ``student'' ", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "316", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper points out that you can take an LSTM and make the gates only a function of the last few inputs - h_t = f(x_t, x_{t-1}, ...x_{t-T}) - instead of the standard - h_t = f(x_t, h_{t-1}) -, and t", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "404", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I agree with reviewer 2 on the interesting part of the paper. The idea of removing or adding units is definitely an interesting direction, that will make a model grow or shrink along the lines require", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "322", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper discusses a method for computing vector representations for documents by using a skip-gram style learning mechanism with an added regularizer in the form of a global context vector with var", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "330", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "## Paper summary The paper reconsiders the idea of using a binary classifier to do two-sample testing. The idea is to split the sample into two disjoint training and test sets, train a classifier on t", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "450", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "As discussed, the there are multiple concurrent contributions in different packages/submission by the authors that are in parts difficult to disentangle. Despite this fact, it is impressive to see a s", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "445", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "The paper explores a VAE architecture and training procedure that allows to generate new samples of a concept based on several exemplars that are shown to the model. The proposed architecture processe", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "693", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper investigates a set of tasks that augment the basic bAbI problems. In particular, some of the people and objects in the scenarios are replaced with unknown variables. Some of these variables", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "349", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This paper presents TopicRNN, a combination of LDA and RNN that augments traditional RNN with latent topics by having a switching variable that includes/excludes additive effects from latent topics wh", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "419", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a method to compress neural networks by retraining them while putting a mixture of Gaussians prior on the weights with learned means and variances which then can be used to compres", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "345", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 5, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The main observation made in the paper is that the use of dropout increases the variance of neurons. Correcting for this increase in variance, in the parameter initialization, and in the test-time sta", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "636", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The author propose to use a off-policy actor-critic algorithm in a batch-setting to improve chat-bots. The approach is well motivated and the paper is well written, except for some intuitions for why ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "471", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a novel exploration strategy that promotes exploration of under-appreciated reward regions. Proposed importance sampling based approach is a simple modification to REINFORCE and ex", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "378", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "First I would like to apologize for the delay in reviewing. Summary : In this paper a variational inference is adapted to deep generative models, showing improvement for non-negative sparse dataset. T", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "595", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I have not much to add to my pre-review comments. It's a very well written paper with an interesting idea. Lots of people currently want to combine RL with NLP. It is very en vogue. Nobody has gotten ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "464", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "While my above review title is too verbose, it would be a more accurate title for the paper than the current one (an overall better title would probably be somewhere in between). The overall approach ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "480", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Interesting work on hierarchical control, similar to the work of Heess et al. Experiments are strong and manage to complete benchmarks that previous work could not. Analysis of the experiments is a bi", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "321", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper provides a highly complex algebraic machinery to analyze the type of functions covered by convolutional network. As in most attempts in this direction in the literature, the ideal networks d", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "484", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a valuable new collection of video game benchmarks, in an extendable framework, and establishes initial baselines on a few of them. Reward structures: for how many of the possible ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 1, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "691", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents interesting experimental findings that state-of-the-art deep reinforcement learning methods enable agent learning of latent (physical) properties in its environment. The paper form", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "377", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an unsupervised image transformation method that maps a sample from source domain to target domain. The major contribution lies in that it does not require aligned training pairs f", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "340", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This is a good paper with an interesting probabilistic motivation for weighted bag of words models. The (hopefully soon) added comparison to Wang and Manning will make it stronger. Though it is sad th", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "375", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a novel extension of generative adversarial networks that replaces the traditional binary classifier discriminator with one that assigns a scalar energy to each point in the genera", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "455", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper applies the idea of the adversarial training and virtual adversarial training to the LSTM-based model in the text context. The paper is in general well written and easy to follow. Extending", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "488", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "# Review This paper proposes five modifications to improve PixelCNN, a generative model with tractable likelihood. The authors empirically showed the impact of each of their proposed modifications usi", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "336", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper extends the GAN framework to accommodate multiple discriminators. The authors motivate this from two points of view: (1) Having multiple discriminators tackle the task is equivalent to optim", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "423", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is a very interesting and timely paper, with multiple contributions. - it proposes a setup for dealing with combinatorial perception and action-spaces that generalizes to an arbitrary number of u", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "344", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper studies the problem of transferring solutions of existing tasks to tackle a novel task under the framework of reinforcement learning and identifies two important issues of avoiding negative", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "407", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a novel look at binary auto-encoders, formulating the objective function as a min-max reconstruction error over a training set given the observed intermediate representations. The a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "367", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper addresses the problem of predicting learning curves. The key difference from prior work is that (1) the authors learn a neural network that generalizes across hyperparameter settings and (2)", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "361", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this paper, a referential game is proposed between two agents. Both agents observe two images. The first agent, called the sender, receive a binary target variable (t) and must send a symbol (messa", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "310", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper reports several connections between the image representations in state-of-the are object recognition networks and findings from human visual psychophysics: 1) It shows that the mean L1 dista", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "629", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 5, "SUBSTANCE": 4, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Description. This paper describes experiments testing whether deep convolutional networks can be replaced with shallow networks with the same number of parameters without loss of accuracy. The experim", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "476", "RECOMMENDATION_ORIGINAL": 3.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes an online variant of segment to segment transducers, which allows to circumvent the necessity of observing whole sentence, before making target predictions. Authors mostly build on ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "443", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a new regulariser for CNNs that penalises positive correlations between feature weights, but does not affect negative correlations. An alternative version which penalises all correl", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "415", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes the graph convolutional networks, motivated from approximating graph convolutions. In one propagation step, what the model does can be simplified as, first linearly transform the n", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "486", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper extend the Spin Glass analysis of Choromanska et al. (2015a) to Res Nets which yield the novel dynamic ensemble results for Res Nets and the connection to Batch Normalization and the analys", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "622", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a modified RNN architecture with multiple layers, where higher layers are only passed lower layer states if a FLUSH operation is predicted, consisting of passing up the state and re", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "496", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces an approach for model-based control of stochastic dynamical systems with policy search, based on (1) learning the stochastic dynamics of the underlying system with a Bayesian dee", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "440", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents an approach for tackling the instability problem that is present in generative adversarial networks. The general idea is to allow the generator to \"peek ahead\" at how the discrimina", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "418", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The idea of this paper is reasonable - gradually go from original weights to compressed weights by compressing a part of them and fine-tuning the rest. Everything seems fine, results look good, and my", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "457", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "SUMMARY This paper contributes to the description and comparison of the representational power of deep vs shallow neural networks with ReLU and threshold units. The main contribution of the paper is t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "495", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper explores a variety of memory augmented architectures (key, key-value, key-predict-value) and additionally simpler near memory-less RNN architectures. Using an attention model that has acces", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "420", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose to add noise to the gradients computed while optimizing deep neural networks with stochastic gradient based methods. They show results multiple data sets which indicate that the me", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "619", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This submission proposes a letter-level decoder with a variation of the CTC approach they call ASG, where the blank symbol is dropped and replaced by letter repetition symbols, and where explicit norm", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "598", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents Hyperband, a method for hyperparameter optimization where the model is trained by gradient descent or some other iterative scheme. The paper builds on the successive halving + rand", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "402", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper extends the NTM by a trainable memory addressing scheme. The paper also investigates both continuous/differentiable as well as discrete/non-differentiable addressing mechanisms. Pros: * Exte", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "662", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper explores an important angle to adversarial examples: the detection of adversarial images and their utilization for trainig more robust networks. This takes the competition between adversari", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "462", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a way of adding unsupervised auxiliary tasks to a deep RL agent like A3C. Authors propose a bunch of auxiliary control tasks and auxiliary reward tasks and evaluate the agent in La", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "309", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "7 Summary: This paper describes the use of variational autoencoders for multi-view representation learning as an alternative to canonical correlation analysis (CCA), deep CCA (DCCA), and multi-view au", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "734", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Thank you for an interesting read. I found this paper very interesting. Since I don't think (deterministic) approximate inference is separated from the modelling procedure (cf. exact inference), it is", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "395", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a very simple idea (prune low-weight filters from ConvNets) in order to reduce FLOPs and memory consumption. The proposed method is experimented on with VGG-16 and ResNets on CIFAR", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "324", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "# Review This paper proposes a quantitative evaluation for decoder-based generative models that use Annealed Importance Sampling (AIS) to estimate log-likelihoods. Quantitative evaluations are indeed ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "368", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors extend GANs by an inference path from the data space to the latent space and a discriminator that operates on the joint latend/data space. They show that the theoretical properties of GANs", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "467", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The main contribution of this paper seems to be an introduction of a set of differential graph transformations which will allow you to learn graph->graph classification tasks using gradient descent. T", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "318", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a variational inference based method for learning nonlinear dynamical systems. Unlike the deep Kalman filter, the proposed method learns a state space model, which forces the laten", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "422", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors present a method for changing the objective of generative adversarial networks such that the discriminator accurately recovers density information about the underlying data distribution. I", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "380", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an approach to make a programming language (Forth) interpreter differentiable such that it can learn the implementation of high-level instruction from provided examples. The paper ", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "509", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper makes three main methodological contributions: - definition of Neural Feature (NF) as the pixel average of the top N images that highly activation a neuron - ranking of neurons based on col", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "717", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes a novel approach for learning visual servoing based on Q-iteration. The main contributions of the paper are: 1. Bilinear dynamics model for predicting next frame (features) based on", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "320", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper has two main contributions: 1) Shows that uniform quantization works well with variable length (Huffman) coding 2) Improves fixed-length quantization by proposing the Hessian-weighted k-mean", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "468", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a modification of the parametric texture synthesis model of Gatys et al. to take into account long-range correlations of textures. To this end the authors add the Gram matrices bet", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "387", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This an interesting investigation into learning rate schedules, bringing in the idea of restarts, often overlooked in deep learning. The paper does a thorough study on non-trivial datasets, and while ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "435", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "The paper proposes a new memory module to be used as an addition to existing neural network models. Pros: * Clearly written and original idea. * Useful memory module, shows nice improvements. * Tested", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "372", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed a new metric central moment discrepancy (CMD) for matching two distributions, with applications to domain adaptation. Compared to a more well-known variant, MMD, CMD has the benefi", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "456", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper proposes Gated Muiltimodal Unit, a building block for connectionist models capable of handling multiple modalities. (Figure 2) The bimodal case returns weighted activation by gains of gating uni", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "503", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Thank you for an interesting read. Given the huge interest in generative modelling nowadays, this paper is very timely and does provide very clear connections between methods that don't use maximum li", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "534", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces the notion of a \"variational lossy autoencoder\", where a powerful autoregressive conditional distribution on the inputs x given the latent code z is crippled in a way that forces", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 4, "RECOMMENDATION": 1, "APPROPRIATENESS": null, "ID": "397", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I think the authors provide an interesting direction for understanding and maybe constructing recurrent models that are easier to interpret. Is not clear where such direction will lead but I think it ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "398", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a second-order method for training a neural networks while ensuring at the same time that weights (and activations) are binary. Through binarization, the method aims to achieve mode", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "453", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an approach to learn to generate programs. Instead of directly trying to generate the program, the authors propose to train a neural net to estimate a fix set of attributes, which ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "439", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This relatively novel work proposes to augment current RL models by adding self-supervised tasks encouraging better internal representations. The proposed tasks are depth prediction and loop closure d", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "438", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes the use of neural variational inference method for topic models. The paper shows a nice trick to approximate Dirichlet prior using softmax basis with a Gaussian and then the model ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "366", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The goal of this paper is to analyze the behaviour of dialogue agents when they must answer factoid questions, but must query an oracle for additional information. This can be interpreted as a form of", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "447", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: The authors propose an input switched affine network to do character-level language modeling, a kind of RNN without pointwise nonlinearity, but with switching the transition matrix & bias bas", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "580", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Authors' response well answered my questions. Thanks. Evaluation not changed. ### This paper proposes a neural model for generating tree structure output from scratch. The model does 1) separate the r", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "400", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Interesting paper which proposes jointly learning automatic segmentation of words to sub words and their acoustic models. Although the training handles the word segmentation as hidden variable which d", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "430", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: The paper presents a technique to convert a dense to sparse network for RNNs. The algorithm will increasingly set more weights to zero during the RNN training phase. This provides a RNN model", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "391", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper revives a classic idea involving regularization for purposes of compression for modern CNN models on resource constrained devices. Model compression is hot and we're in the midst of lots of", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "345", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "SYNOPSIS: This paper introduces a new dataset for evaluating end-to-end goal-oriented dialog systems. All data is generated in the restaurant setting, where the goal is to find availability and eventu", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "307", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper examines computational creativity from a machine learning perspective. Creativity is defined as a model's ability to generate new types of objects unseen during training. The authors argue ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "583", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This paper presents an approach for skills transfer from one task to another in a control setting (trained by RL) by forcing the embeddings learned on two different tasks to be close (L2 penalty). The", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "331", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper investigates the fact why deep networks perform well in practice and how modifying the geometry of pooling can make the polynomially sized deep network to provide a function with exponentia", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "484", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "[UPDATE] After going through the response from the author and the revision, I increased my review score for two reasons. 1. I thank the reviewers for further investigating the difference between yours", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "405", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "*** Paper Summary *** This paper applies adversarial and virtual adversarial training to LSTM for text classification. Since text inputs are discrete adversarial perturbation are applied to the (norma", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "488", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "All in all this is a nice paper. I think the model is quite clever, attempting to get the best of latent variable models and auto-regressive models. The implementation and specific architecture choice", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "353", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper tackles important problems in multi-task reinforcement learning: avoid negative transfer and allow finer selective transfer. The method is based on soft attention mechanism, very general, an", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "407", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper is about using Bayesian neural networks to model learning curves (that arise from training ML algorithms). The application is hyper-parameter optimization: if we can model the learning curv", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "361", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper aims to investigate the question if shallow non-convolutional networks can be as affective as deep convolutional ones for image classification, given that both architectures use the same nu", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "476", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes to use an SSNT model of p(x|y) to allow for a noisy channel model of conditional generation that (still) allows for incremental generation of y. The authors also propose an approxi", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "443", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper considers the problem of model-based policy search. The authors consider the use of Bayesian Neural Networks to learn a model of the environment and advocate for the $\\alpha$-divergence min", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "440", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper formalizes the problem setting of having only a subset of available MDPs for which one has access to a reward. The authors name this setting \"semi-supervised reinforcement learning\" (SSRL),", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "360", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Two things I really liked about this paper: 1. The whole idea of having a data-dependent proposal distribution for MCMC. I wasn't familiar with this, although it apparently was previously published. I", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "411", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The system described works comparably to bi-directional LSTM baseline for NMT, and CNN's are naturally parallelizable. Key ideas include the use of two stacked CNN's (one for each of encoding and deco", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 2, "ID": "748", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The proposed method is simple and elegant; it builds upon the huge success of gradient based optimization for deep non-linear function approximators and combines it with established (linear) many-view", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "645", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The idea of \"pruning where it matters\" is great. The authors do a very good job of thinking it through, and taking to the next level by studying pruning across different layers too. Extra points for c", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "324", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors introduce an adaptive softmax approximation tailored for faster performance on GPUs. The key idea, which is very sensible, is to use a class-based hierarchical softmax, but where the clust", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "523", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is high novelty work, and an enjoyable read. My concerns about the paper more or less mirror my pre-review questions. I certainly agree that the learned variable computation mechanism is obviousl", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "441", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is a clearly written paper with a nice, if straightforward, result: RNNs can be good predictive models of neuron firing rates in the retina. On the one hand, the primary scientific contribution s", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "328", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Update: raised the score, because I think the arguments about adversarial examples are compelling. I think that the paper convincingly proves that this method acts as a decent regularizer, but I'm not", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "442", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a network quantization method for compressing the parameters of neural networks, therefore, compressing the amount of storage needed for the parameters. The authors assume that the", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 5, "APPROPRIATENESS": 5, "ID": "468", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This heuristic to improve gradient descent in image classification is simple and effective, but this looks to me more like a workshop track paper. Demonstration of the algorithm is limited to one task", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "435", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an architecture and corresponding algorithms for learning to act across multiple tasks, described in natural language. The proposed system is hierarchical and is closely related to", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "625", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Authors' response well answered my questions. Thanks! Evaluation not changed. ### This paper proposes a hierarchical framework of transfer learning for sequence tagging, which is expected to help the ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "373", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents an end-to-end neural network model for the problem of designing natural language interfaces for database queries. The proposed approach uses only weak supervision signals to learn t", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "436", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this paper, the authors propose to pretrain the encoder/decoder of seq2seq models on a large amount of unlabeled data using a LM objective. They obtain improvements using this technique on machine ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "709", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a method for training a generative model via an iterative denoising procedure. The denoising process is initialized with a random sample from a crude approximation to the data distr", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "325", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper investigates the question of gathering information (answering question) through direct interaction with the environment. In that sense, it is closely related to \"active learning\" in supervi", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "377", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this paper a well known soft mixture of experts model is adapted for, and applied to, a specific type of transfer learning problem in reinforcement learning (RL), namely transfer of action policies", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "407", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors present a general framework for defining a wide variety of recurrent neural network architectures, including seq2seq models, tree-structured models, attention, and a new family of dynamica", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": 5, "ID": "671", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper purports to investigate the ability of RL agents to perform physics experiments in an environment, to infer physical properties about the objects in that environment. The problem is very we", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "377", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Two things I'd like to see. 1) Specifics about the JPEG and JPEG2000 implementations used, and how they were configured. One major weakness I see in many papers is they do not include specific encoder", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "305", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a novel strategy to deal with dynamic computation graphs. They arise, when the computation is dynamically influenced by the input data, such as in LSTMs. The authors propose an `unr", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "379", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In light of the authors' responsiveness and the updates to the manuscript -- in particular to clarify the meta-learning task -- I am updating my score to an 8. ----- This manuscript proposes to tackle", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "306", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The work presented in this paper proposes a method to get an ensemble of neural networks at no extra training cost (i.e., at the cost of training a single network), by saving snapshots of the network ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "354", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Sorry for the late review -- I've been having technical problems with OpenReview which prevented me from posting. This paper presents a method for learning to predict things from sets of data points. ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "358", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a simulator and a set of synthetic tasks for evaluating a dialogue agent's ability to learn from user feedback. For solving these tasks, the paper uses memory networks (Sukhbaata", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "447", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: The paper proposes a novel deep neural network architecture for the task of question answering on the SQuAD dataset. The model consists of two main components -- coattention encoder and dynam", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "388", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Thank you for an interesting read on an approach to choose computational models based on kind of examples given. Pros - As an idea, using a meta controller to decide the computational model and the nu", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "390", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Pros : - New representation with nice properties that are derived and compared with a mathematical baseline and background - A simple algorithm to obtain the representation Cons : - The paper sounds l", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "478", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The submission considers the setting of 2-sample testing from the perspective of evaluating a classifier. For a classifier between two samples from the same distribution, the distribution of the class", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "450", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work combines a LDA-type topic model with a RNN and models this by having an additive effect on the predictive distribution via the topic parameters. A variational auto-encoder is used to infer t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "419", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors present a dataset extraction method, dataset and first interesting results for machine-learning supported higher order logic theorem proving. The experimental results are impressively good", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "494", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper proposes a novel Variational Encoder architecture that contains discrete variables. Model contains an undirected discrete component that captures distribution over disconnected manifolds and a d", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "475", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "overview: This work proposes to link trajectory log-probabilities and rewards by defining under-appreciated rewards. This suggests that there is a linear relationship between trajectory rewards and th", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "378", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper analyses the misclassification error of discriminators and highlights the fact that while uniform probability prior of the classes makes sense early in the optimization, the distribution dev", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": 5, "ID": "493", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper analyzes various unsupervised sentence embedding approaches by means of a set of auxiliary prediction tasks. By examining how well classifiers can predict word order, word content, and sent", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "489", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In light of the detailed author responses and further updates to the manuscript, I am raising my score to an 8 and reiterating my support for this paper. I think it will be among the strongest non-tra", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": 4, "APPROPRIATENESS": 5, "ID": "482", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 2, "COMMENTS": "The authors propose a recurrent neural network architecture that is able to output more accurate long-term predictions of several game environments than the current state-of-the-art. The original netw", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "405", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presented a method of improving the efficiency of deep networks acting on a sequence of correlated inputs, by only performing the computations required to capture changes between adjacent i", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "413", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Interesting paper, definitely provides value to the community by discussing why large batch gradient descent does not work too well", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 5, "ID": "315", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work introduces some StarCraft micro-management tasks (controlling individual units during a battle). These tasks are difficult for recent DeepRL methods due to high-dimensional, variable action ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "344", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper describes a careful experimental study on the CIFAR-10 task that uses data augmentation and Bayesian hyperparameter optimization to train a large number of high-quality, deep convolutional ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "476", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a new multiscale recurrent neural network, where each layer has different time scale, and the scale is not fixed but variable and determined by a neural network. The method is eleg", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "496", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "There is a great deal of ongoing interest in compressing neural network models. One line of work has focused on using low-precision representations of the model weights, even down to 1 or 2 bits. Howe", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "457", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper provides an interesting analysis of the conditions which enable generation of natural looking textures. The results is quite surprising, and analysis is quite thorough. I do think the evalu", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "333", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper performs a very important service: exploring in a clear and systematic way the performance and trainability characteristics of a set of neural network architectures -- in particular, the ba", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 1, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "376", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "summary The paper explains dropout with a latent variable model where the dropout variable (0 or 1 depending on which units should be dropped) is not observed and is accordingly marginalised. Maximum ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "498", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an approach which modifies the variational auto-encoder (VAE) framework so as to use stochastic latent dimensionality. This is achieved by using an inherently infinite prior, the s", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 5, "ID": "470", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper argues that being able to handle recursion is very important for neural programming architectures that handling recursion allows for strong generalization to out of domain test cases and le", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "304", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "The paper introduces Edward, a probabilistic programming language built over TensorFlow and Python, and supporting a broad range of most popular contemporary methods in probabilistic machine learning.", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "395", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: The paper presents an advanced self-learning model that extracts compositional rules from Bach's chorales, which extends their previous work in: 1) the rule hierarchy in both conceptual and i", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "474", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is a nice paper that demonstrates an end-to-end trained image compression and decompression system, which achieves better bit-rate vs quality trade-offs than established image compression algorit", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "305", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The submission explores several alternatives to provide the generator function in generative adversarial training with additional gradient information. The exposition starts by describing a general fo", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "380", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper explores the ability of nonlinear recurrent neural networks to account for neural response properties that have otherwise eluded the ability of other models. A multilayer rnn is trained to ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "328", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents an on-policy method to predict future intrinsic measurements. All the experiments are performed in the game of Doom (vizDoom to be exact), and instead of just predicting win/loss or", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "314", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "In this paper a novel approach for anomaly detection is considered for the task of intrusion detection based on system call sequence. The system call sequence is regarded as a language, and multiple l", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "733", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "A new memory module based on k-NN is presented. The paper is very well written and the results are convincing. Omniglot is a good sanity test and the performance is surprisingly good. The artificial t", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "372", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is a solid paper that proposes to endow attention mechanisms with structure (the attention posterior probabilities becoming structured latent variables). Experiments are shown with segmental aten", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "393", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a clear hierarchical taxonomy of transfer learning methods as applicable to sequence tagging problems. This contextualizes and unifies previous work on specific instances of this t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "373", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This paper trains a generative model which transforms noise into model samples by a gradual denoising process. It is similar to a generative model based on diffusion. Unlike the diffusion approach: - ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "325", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors of the paper set out to answer the question whether chaotic behaviour is a necessary ingredient for RNNs to perform well on some tasks. For that question's sake, they propose an architectu", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "398", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper describes a novel technique to improve the efficiency of computation graphs in deep learning frameworks. An impressive speedup can be observed in their implementation within TensorFlow. The ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "379", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work proposes a new approach for image compression using auto encoders. The results are impressive, besting the state of the art in this field. Pros: + Very clear paper. It should be possible to ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "392", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Training highly non-convex deep neural networks is a very important practical problem, and this paper provides a great exploration of an interesting new idea for more effective training. The empirical", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "370", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work contributes to understanding the landscape of deep networks in terms of its topology and geometry. The paper analyzes the former theoretically, and studies the latter empirically. Although t", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "451", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Learning about the physical structure and semantics of the world from video (without supervision) is a very hot area in computer vision and machine learning. In this paper, the authors investigate how", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "350", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a model that is able to infer a program from input/output example pairs, focusing on a restricted domain-specific language that captures a fairly wide variety of string transformat", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "356", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work is an extension of previous works on pointer models, that mixes its outputs with standard softmax outputs. The idea is appealing in general for context biasing and the specific approach appe", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "490", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a semi-supervised technique for self-ensembling where the model uses a consensus prediction (computed from previous epochs) as a target to regress to, in addition to the usual supe", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "461", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper Summary: The paper introduces a question answering model called Dynamic Coattention Network (DCN). It extracts co-dependent representations of the document and question, and then uses an iterati", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "388", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Pros: The authors are presenting an RNN-based alternative to wavenet, for generating audio a sample at a time. RNNs are a natural candidate for this task so this is an interesting alternative. Further", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "389", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a new framework to solve the SR problem - amortized MAP inference and adopts a pre-learned affine projection layer to ensure the output is consistent with LR. Also, it proposes thre", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "317", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Attempts to use chatbots for every form of human-computer interaction has been a major trend in 2016, with claims that they could solve many forms of dialogs beyond simple chit-chat. This paper repres", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "307", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a novel method for language modeling which is suitable for both modeling programming language as well as natural language. The approach uses a program synthesis algorithm to sear", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": 4, "APPROPRIATENESS": 3, "ID": "343", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Paper Summary This paper proposes a variant of dropout, applicable to RNNs, in which the state of a unit is randomly retained, as opposed to being set to zero. This provides noise which gives the regu", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "394", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper discuss a \"batch\" method for RL setup to improve chat-bots. The authors provide nice overview of the RL setup they are using and present an algorithm which is similar to previously published", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "471", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is an interesting paper on how to handle reparameterization in VAEs when you have discrete variables. The idea is to introduce a smoothing transformation that is shared between the generative mod", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "475", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an information theoretic framework for unsupervised learning. The framework relies on infomax principle, whose goal is to maximize the mutual information between input and output. ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "335", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "The paper proposes to use reinforcement learning to learn how to compose the words in a sentence, i.e. parse tree, that can be helpful for the downstream tasks. To do that, the shift-reduce framework ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "464", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I like the setting presented in this paper but I have several criticism/questions: (1) What are the failure model of this work? As richness of behaviors get complex, I expected this approach to have i", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "321", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper describes a new benchmark for word representations: spotting the odd one out. The authors build upon an idea recently presented at the RepEval workshop, but are able to collect a significan", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "507", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper describes an alternative view on hierarchical feature representations in deep neural networks. The viewpoint of refining representations is well motivated and is in agreement with the succes", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "338", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors present a methodology for analyzing sentence embedding techniques by checking how much the embeddings preserve information about sentence length, word content, and word order. They examine", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "489", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a new theoretically-principled method of representing sentences as vectors. The experiments show that vectors produced by this method perform well on similarity and entailment benc", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "375", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper is a parallel work to Improving Generative Adversarial Networks with Denoising Feature Matching. The main solution of both papers is introducing autoencoder into discriminator to improve th", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "455", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work analyzes the continuous-time dynamics of gradient descent when training two-layer ReLU networks (one input, one output, thus only one layer of ReLU units). The work is interesting in the sen", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "522", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a mathematical analysis of how information is propagated through deep feed-forward neural networks, with novel analysis addressing the problem of vanishing and exploding gradients ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "448", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes to study the problem of semi-supervised RL where one has to distinguish between labelled MDPs that provide rewards, and unlabelled MDPs that are not associated with any reward signa", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "360", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 5, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This was an interesting paper. The algorithm seems clear, the problem well-recognized, and the results are both strong and plausible. Approaches to hyperparameter optimization based on SMBO have strug", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "402", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper presents a general approach to modeling for natural language understanding problems with two distinct textual inputs (such as a question and a source text) that can be aligned in some way. I", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "363", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is a very interesting and fairly easy to read paper. The authors present a small, yet nifty approach to make Neural Programming Interpreters significantly more powerful. By allowing recursion, NP", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "304", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 5, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces MusicNet, a new dataset. Application of ML techniques to music have been limited due to scarcity of exactly the kind of data that is provided here: meticulously annotated, carefu", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "409", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This nicely written paper presents an end-to-end learning method for image compression. By optimizing for rate-distortion performance and a clever relaxation the method is able to learn an efficient i", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "305", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper addresses one of the major shortcomings of generative adversarial networks - their lack of mechanism for evaluating held-out data. While other work such as BiGANs/ALI address this by learni", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "380", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper provides some theoretical guarantees for the identity parameterization by showing that 1) arbitrarily deep linear residual networks have no spurious local optima; and 2) residual networks w", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "466", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is a very nice paper. The writing of the paper is clear. It starts from the traditional attention mechanism case. By interpreting the attention variable z as a distribution conditioned on the inp", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "393", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper introduces a 'GPU-friendly' variant of A3C which relaxes some synchronicity constraints in the original A3C algorithm to make it more friendly to a high-throughput GPU device. The analysis ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "437", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper explores ensemble optimisation in the context of policy-gradient training. Ensemble training has been a low-hanging fruit for many years in the this space and this paper finally touches on ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "406", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: The paper proposes a model training strategy to achieve higher accuracy. The issue is train a too large model and you going to over-fit and your model will capture noise. Prune models or make", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "370", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 5, "COMMENTS": "Paper Summary This paper proposes an unsupervised learning model in which the network predicts what its state would look like at the next time step (at input layer and potentially other layers). When ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "350", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work is basically a combined pointer network applied on language modelling. The smart point is that this paper aims at language modelling with longer context, where a memory of seen words (especi", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "490", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed a dynamic coattention network for the question answering task with long contextual documents. The model is able to encode co-dependent representations of the question and the docum", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "388", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed a deep multi-task representation learning framework that learns cross-task sharing structure at every layer in a deep network with tensor factorization and end-to-end knowledge sha", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "459", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper focuses on bilingual word representation learning with the following setting: 1. Bilingual representation is learnt in an offline manner i.e., we already have monolingual representations for", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "426", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 3, "COMMENTS": "This paper makes a valuable contribution to provide a more clear understanding of generative adversarial network (GAN) training procedure. With the new insight of the training dynamics of GAN, as well", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "308", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduces SampleRNN, a hierarchical recurrent neural network model of raw audio. The model is trained end-to-end and evaluated using log-likelihood and by human judgement of unconditional s", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "389", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a new, public dataset and tasks for goal-oriented dialogue applications. The dataset and tasks are constructed artificially using rule-based programs, in such a way that different ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "307", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a method for language modeling by first generating a program from a DSL, then learning the count-based parameters of that program. Pros include: The proposed method is innovative a", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "343", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper tests zoneout against a variety of datasets - character level, word level, and pMNIST classification - showing applicability in a wide range of scenarios. While zoneout acts as a regularize", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "394", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a set of experiments investigating what kinds of information are captured in common unsupervised approaches to sentence representation learning. The results are non-trivial and som", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "489", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is an interesting paper about quantized networks that work on temporal difference inputs. The basic idea is that when a network has only to process differences then this is computational much mor", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "413", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper shows that extending deep RL algorithms to decide which action to take as well as how many times to repeat it leads to improved performance on a number of domains. The evaluation is very th", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "452", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper extends the GAN framework to allow for latent variables. The observed data set is expanded by drawing latent variables z from a conditional distribution q(z|x). The joint distribution on x,", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "446", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is an interesting and pleasant paper on superoptimization, that extends the problem approached by the stochastic search STOKE to a learned stochastic search, where the STOKE proposals are the out", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "411", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The framework of Gatys et al. demonstrated that correlation statistics (empirical Gram matrices) of deep feature responses provide an excellent characterisation of visual textures. This paper investig", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "333", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors investigate a variety of existing and two new RNN architectures to obtain more insight about the effectiveness at which these models can store task information in their parameters and acti", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "376", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper puts forward a not entirely new, but also not sufficiently understood interpretation of dropout regularization. The authors derive useful theorems that estimate or put bounds on key quantit", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "498", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary: This is the first work to investigate stick-breaking priors, and corresponding inference methods, for use in VAEs. The background material is explained clearly, as well as the explanation of ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "470", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The problem addressed here is practically important (supervised learning with n<", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "351", "RECOMMENDATION_ORIGINAL": 0.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": 1, "COMMENTS": "This paper essentially presents a new inductive bias in the architecture of (convolutional) neural networks (CNN). The mathematical motivations/derivations of the proposed architecture are detailed an", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "348", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper reads well and the idea is new. Sadly, many details needed for replicating the results (such as layer sizes of the CNNs, learning rates) are missing. The training of the introspection networ", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "401", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper studies in depth the idea of quantizing down convolutional layers to 3 bits, with a different positive and negative per-layer scale. It goes on to provide an exhaustive analysis of performa", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "369", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper gives a theoretical motivation for tieing the word embedding and output projection matrices in RNN LMs. The argument uses an augmented loss function which spreads the output probability mas", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "473", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents an on-policy deep RL method with additional auxiliary intrinsic variables. - The method is a special case of an universal value function based approach and the authors do cite the ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "314", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a new generative model that uses real-valued non-volume preserving transformations in order to achieve efficient and exact inference and sampling of data points. The authors use th", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "433", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper extends batch normalization successfully to RNNs where batch normalization has previously failed or done poorly. The experiments and datasets tackled show definitively the improvement that ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "434", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose to extend the standard attention mechanism, by extending it to consider a distribution over latent structures (e.g., alignments, syntactic parse trees, etc.). These latent variable", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "393", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a hierarchical generative model where the lower level consists of points within datasets and the higher level models unordered sets of datasets. The basic idea is to use a \"double\"", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "358", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Pros (quality, clarity, originality, significance:): This paper presents a novel metacontroller optimization system that learns the best action for a one-shot learning task, but as a framework has the", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "390", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "*** Paper Summary *** This paper formalizes the properties required for addressing (indexing) memory augmented neural networks as well as how to pair the addressing with read/write operation. It then ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "403", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "I'm not familiar enough with mean-field techniques to judge the soundness of Eq 2, but I'm willing to roll with it. Minor point on presentation: Speaking of the \"evolution\" of x_{i;a} as it travels th", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "448", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a simple but effective extension to reinforcement learning algorithms, by adding a temporal repetition component as part of the action space, enabling the policy to select how long", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "452", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Although the trainable parameters might be reduced significantly, unfortunately the training and recognition speech cannot be reduced in this way. Unfortunately, as the results show, the authors could", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 3, "APPROPRIATENESS": null, "ID": "499", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes a novel variant of recurrent networks that is able to learn the hierarchy of information in sequential data (e.g., character->word). Their approach does not require boundary inform", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "496", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper is about improving feature learning in deep reinforcement learning, by augmenting the main policy's optimization problem with terms corresponding to (domain-independent) auxiliary tasks. Th", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "309", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper extends an approach to rate-distortion optimization to deep encoders and decoders, and from a simple entropy encoding scheme to adaptive entropy coding. In addition, the paper discusses the", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "305", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Overview: This paper introduces a biasing term for SGD that, in theoretical results and a toy example, yields solutions with an approximately equal or lower generalization error. This comes at a compu", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "458", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper investigates the benefits of visual servoing using a learned visual representation. The authors propose to first learn an action-conditional bilinear model of the visual features (obtained ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": 2, "ID": "320", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a clever way of training a generative model which allows for exact inference, sampling and log likelihood evaluation. The main idea here is to make the Jacobian that comes when usi", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "433", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper provides an exposition of multiple ways of learning in implicit generative models, of which generative adversarial networks are an example. The paper is very clear, the exposition is insight", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 3, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "534", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 3, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes an elegant solution to a very important problem in VAEs, namely that the model over-regularizes itself by killing off latent dimensions. People have used annealing of the KL term a", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "592", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "A well written paper and an interesting construction - I thoroughly enjoyed reading it. I found the formalism a bit hard to follow without specific examples- that is, it wasn't clear to me at first wh", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "390", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work proposes to train RL agents to also perform auxiliary tasks, positing that doing so will help models learn stronger features. They propose two pseudo-control tasks, control the change in pix", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "309", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": 4, "SUBSTANCE": 3, "CLARITY": null, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "This paper proposes to learn decomposition of sequences (such as words) for speech recognition. It addresses an important issue and I forsee it being useful for other applications such as machine tran", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 4, "APPROPRIATENESS": null, "ID": "430", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a novel way of pruning filters from convolutional neural networks with a strong theoretical justification. The proposed methods is derived from the first order Taylor expansion of ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "381", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper addresses the problem of achieving differential privacy in a very general scenario where a set of teachers is trained on disjoint subsets of sensitive data and the student performs predicti", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "316", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposed a novel SampleRNN to directly model waveform signals and achieved better performance both in terms of objective test NLL and subjective A/B tests. As mentioned in the discussions, t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "389", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Much existing deep learning literature focuses on likelihood based models. However maximum entropy approaches are an equally valid modelling scenario, where information is given in terms of constraint", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "416", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Summary === This paper proposes the Neural Physics Engine (NPE), a network architecture which simulates object interactions. While NPE decides to explicitly represent objects (rather than video frames", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "371", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 3, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposes learning on the fly to represent a dialog as a graph (which acts as the memory), and is first demonstrated on the bAbI tasks. Graph learning is part of the inference process, thoug", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "318", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The method proposes to compress the weight matrices of deep networks using a new density-diversity penalty together with a computing trick (sorting weights) to make computation affordable and a strate", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "365", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": 4, "COMMENTS": "Altogether a very good paper, a nice read, and interesting. The work advances the state of the art on differentially-private deep learning, is quite well-written, and relatively thorough. One caveat i", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "316", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": 4, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper explores an important part of our field, that of automating architecture search. While the technique is currently computationally intensive, this trade-off will likely become better in the ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "312", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "EDIT: Updated score. See additional comment. I quite like the main idea of the paper, which is based on the observation in Sec. 3.0 - that the authors find many predictable patterns in the independent", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "401", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a principled approach to finding flat minima. The motivation to seek such minima is due to their better generalization ability. The idea is to add to the original loss function a n", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "458", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper proposes an extension of the Gated Graph Sequence Neural Network by including in this model the ability to produce complex graph transformations. The underlying idea is to propose a method t", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": 3, "ID": "318", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The authors propose a way to visualize which areas of an image provide mostly influence a certain DNN response mostly. They apply some very elegant and convincing improvements to the basic method by R", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "427", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Variational auto-encoders, adversarial networks, and kernel scoring rules like MMD have recently gained popularity as methods for learning directed generative models and for other applications like do", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "456", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work presents an LSTM based meta-learning framework to learn the optimization algorithm of a another learning algorithm (here a NN). The paper is globally well written and the presentation of the", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": 5, "ID": "306", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work develops a method to quickly produce an ensemble of deep networks that outperform a single network trained for an equivalent amount of time. The basis of this approach is to use a cyclic lea", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "354", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This work explores taking advantage of the stochasticity of neural network outputs under randomized augmentation and regularization techniques to provide targets for unlabeled data in a semi-supervise", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "461", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": 4, "CLARITY": 4, "MEANINGFUL_COMPARISON": null, "COMMENTS": "Sincere apologies for the late review. This paper argues to approach Super-Resolution as amortised MAP estimation. A projection step to keep consistent HR-LR dependencies is proposed and experimentall", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "317", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": 3, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper presents a way of training deep generative models with discrete hidden variables using the reparameterization trick. It then applies it to a particular DBN-like architecture, and shows that", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "475", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper not only shows that a cache model on top of a pre-trained RNN can improve language modeling, but also illustrates a shortcoming of standard RNN models in that they are unable to capture thi", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "339", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper expands a recent mean-field approximation of deep random neural networks to study depth-dependent information propagation, its phase-dependence and the influence of drop-out. The paper is ex", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": null, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "448", "RECOMMENDATION_ORIGINAL": 0.5}, {"IMPACT": null, "SUBSTANCE": 2, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper proposed to use RL and RNN to design the architecture of networks for specific tasks. The idea of the paper is quite promising and the experimental results on two datasets show that method ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 4, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "312", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This paper improves significantly upon the original NPI work, showing that the model generalizes far better when trained on traces in recursive form. The authors show better sample complexity and gene", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 5, "RECOMMENDATION": null, "APPROPRIATENESS": null, "ID": "304", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is the most convincing paper on image compression with deep neural networks that I have read so far. The paper is very well written, the use of the rate-distortion theory in the objective fits sm", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "305", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": 5, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is a very nicely written paper which unifies some value-based and policy-based (regularized policy gradient) methods, by pointing out connections between the value function and policy which have ", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "432", "RECOMMENDATION_ORIGINAL": 2.0}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": 5, "MEANINGFUL_COMPARISON": 5, "COMMENTS": "This paper presents search for optimal neural-net architectures based on actor-critic framework. The method treats DNN as a variable length sequence, and uses RL to find the target architecture, which", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "312", "RECOMMENDATION_ORIGINAL": 2.5}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper introduces a technique for stabilizing the training of Generative Adversrial Networks by unrolling the inner (discriminator) optimization in the GAN loss function several steps and optimizin", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": null, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "418", "RECOMMENDATION_ORIGINAL": 1.5}, {"IMPACT": null, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "This is a strong submission regarding one of the most important and recently introduced methods in neural networks - generative adversarial networks. The authors analyze theoretically the convergence ", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 5, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "308", "RECOMMENDATION_ORIGINAL": 1.0}, {"IMPACT": 4, "SUBSTANCE": null, "CLARITY": null, "MEANINGFUL_COMPARISON": null, "COMMENTS": "The paper is an empirical study to justify that: 1. SGD with smaller batch sizes converges to flatter minima, 2. flatter minima have better generalization ability. Pros and Cons: Although there is lit", "SOUNDNESS_CORRECTNESS": null, "ORIGINALITY": 2, "RECOMMENDATION": 5, "APPROPRIATENESS": null, "ID": "315", "RECOMMENDATION_ORIGINAL": 1.5}]