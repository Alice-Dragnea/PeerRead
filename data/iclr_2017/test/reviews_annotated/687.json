{"conference": "ICLR 2017 conference submission", "title": "The Incredible Shrinking Neural Network: New Perspectives on Learning Representations Through The Lens of Pruning", "abstract": "How much can pruning algorithms teach us about the fundamentals of learning representations in neural networks? A lot, it turns out. Neural network model compression has become a topic of great interest in recent years, and many different techniques have been proposed to address this problem. In general, this is motivated by the idea that smaller models typically lead to better generalization. At the same time, the decision of what to prune and when to prune necessarily forces us to confront our assumptions about how neural networks actually learn to represent patterns in data. In this work we set out to test several long-held hypotheses about neural network learning representations and numerical approaches to pruning. To accomplish this we first reviewed the historical literature and derived a novel algorithm to prune whole neurons (as opposed to the traditional method of pruning weights) from optimally trained networks using a second-order Taylor method. We then set about testing the performance of our algorithm and analyzing the quality of the decisions it made. As a baseline for comparison we used a first-order Taylor method based on the Skeletonization algorithm and an exhaustive brute-force serial pruning algorithm. Our proposed algorithm worked well compared to a first-order method, but not nearly as well as the brute-force method. Our error analysis led us to question the validity of many widely-held assumptions behind pruning algorithms in general and the trade-offs we often make in the interest of reducing computational complexity. We discovered that there is a straightforward way, however expensive, to serially prune 40-70\\% of the neurons in a trained network with minimal effect on the learning representation and without any re-training.", "histories": [], "reviews": [{"IMPACT": 4, "SUBSTANCE": 3, "comments": "The authors have put forward a sincere effort to investigate the \"fundamental nature of learning representations in neural networks\", a topic of great interest and importance to our field. They propos", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "is_meta_review": false, "IS_META_REVIEW": false}, {"IMPACT": 1, "SUBSTANCE": 1, "MEANINGFUL_COMPARISON": 1, "comments": "I did enjoy reading some of the introductions and background, in particular that of reminding readers of popular papers from the late 1980s and early 1990s. The idea of the proposal is straight forwar", "ORIGINALITY": 1, "is_meta_review": false, "RECOMMENDATION": 1, "APPROPRIATENESS": 1, "IS_META_REVIEW": false}, {"IMPACT": 3, "SUBSTANCE": 3, "comments": "The paper introduces a new pruning method for neural networks based on the second-order Taylor expansion and compares the results against a first-order method and brute-force pruning. It performs expe", "SOUNDNESS_CORRECTNESS": 3, "is_meta_review": false, "CLARITY": 5, "IS_META_REVIEW": false}], "authors": "Nikolas Wolfe, Aditya Sharma, Lukas Drude, Bhiksha Raj", "accepted": false, "id": "687"}