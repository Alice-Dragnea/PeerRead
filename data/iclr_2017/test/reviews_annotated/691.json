{"conference": "ICLR 2017 conference submission", "title": "Playing SNES in the Retro Learning Environment", "abstract": "Mastering a video game requires skill, tactics and strategy. While these attributes may be acquired naturally by human players, teaching them to a computer program is a far more challenging task. In recent years, extensive research was carriedout in the field of reinforcement learning and numerous algorithms were introduced, aiming to learn how to perform human tasks such as playing video games. As a result, the Arcade Learning Environment (ALE) (Bellemare et al., 2013) has become a commonly used benchmark environment allowing algorithms to train on various Atari 2600 games. In many games the state-of-the-art algorithms outperform humans. In this paper we introduce a new learning environment, the Retro Learning Environment \u2014 RLE, that can run games on the Super Nintendo Entertainment System (SNES), Sega Genesis and several other gaming consoles. The environment is expandable, allowing for more video games and consoles to be easily added to the environment, while maintaining the same interface as ALE. Moreover, RLE is compatible with Python and Torch. SNES games pose a significant challenge to current algorithms due to their higher level of complexity and versatility.", "histories": [], "reviews": [{"IS_META_REVIEW": false, "CLARITY": 4, "is_meta_review": false, "comments": "This paper introduces a new reinforcement learning environment called The Retro Learning Environment, that interfaces with the open-source LibRetro API to offer access to various emulators and associa", "RECOMMENDATION": 2}, {"IMPACT": 3, "SUBSTANCE": 4, "comments": "The paper presents a new environment, called Retro Learning Environment (RLE), for reinforcement learning. The authors focus on Super Nintendo but claim that the interface supports many others (includ", "is_meta_review": false, "RECOMMENDATION": 3, "CLARITY": 4, "IS_META_REVIEW": false}, {"ORIGINALITY": 1, "is_meta_review": false, "comments": "This paper presents a valuable new collection of video game benchmarks, in an extendable framework, and establishes initial baselines on a few of them. Reward structures: for how many of the possible ", "IS_META_REVIEW": false}], "authors": "Nadav Bhonker, Shai Rozenberg, Itay Hubara", "accepted": false, "id": "691"}