{"conference": "ICLR 2017 conference submission", "title": "Transformation-based Models of Video Sequences", "abstract": "In this work we propose a simple unsupervised approach for next frame prediction in video. Instead of directly predicting the pixels in a frame given past frames, we predict the transformations needed for generating the next frame in a sequence, given the transformations of the past frames. This leads to sharper results, while using a smaller prediction model.  In order to enable a fair comparison between different video frame prediction models, we also propose a new evaluation protocol. We use generated frames as input to a classifier trained with ground truth sequences. This criterion guarantees that models scoring high are those producing sequences which preserve discrim- inative features, as opposed to merely penalizing any deviation, plausible or not, from the ground truth. Our proposed approach compares favourably against more sophisticated ones on the UCF-101 data set, while also being more efficient in terms of the number of parameters and computational cost.", "histories": [], "reviews": [{"IS_META_REVIEW": false, "SOUNDNESS_CORRECTNESS": 3, "is_meta_review": false, "comments": "This paper describes an approach to predict (unseen) future frames of a video given a set of known past frames. The approach is based on a CNN that, in contrast to most related papers, work in the spa", "MEANINGFUL_COMPARISON": 2}, {"IMPACT": 2, "IS_META_REVIEW": false, "is_meta_review": false, "comments": "The paper proposes a method for future frame prediction based on transformation of previous frame rather than direct pixel prediction. Many previous works have proposed similar methods. The authors in", "SOUNDNESS_CORRECTNESS": 2}, {"ORIGINALITY": 3, "CLARITY": 5, "is_meta_review": false, "comments": "Paper Summary This paper makes two contributions - (1) A model for next step prediction, where the inputs and outputs are in the space of affine transforms between adjacent frames. (2) An evaluation m", "IS_META_REVIEW": false}], "authors": "Joost van Amersfoort, Anitha Kannan, Marc'Aurelio Ranzato, Arthur Szlam, Du Tran, Soumith Chintala", "accepted": false, "id": "612"}