{"conference": "ICLR 2017 conference submission", "title": "Parallel Stochastic Gradient Descent with Sound Combiners", "abstract": "Stochastic gradient descent (SGD) is a well-known method for regression and classification tasks. However, it is an inherently sequential algorithm \u2014 at each step, the processing of the current example depends on the parameters learned from the previous examples. Prior approaches to parallelizing SGD, such as Hogwild! and AllReduce, do not honor these dependences across threads and thus can potentially suffer poor convergence rates and/or poor scalability. This paper proposes SymSGD, a parallel SGD algorithm that retains the sequential semantics of SGD in expectation. Each thread in this approach learns a local model and a probabilistic model combiner that allows the local models to be combined to produce the same result as what a sequential SGD would have produced, in expectation. This SymSGD approach is applicable to any linear learner whose update rule is linear. This paper evaluates SymSGD\u2019s accuracy and performance on 9 datasets on a shared-memory machine shows up-to 13\u00d7 speedup over our heavily optimized sequential baseline on 16 cores.", "histories": [], "reviews": [{"IS_META_REVIEW": false, "CLARITY": 3, "is_meta_review": false, "comments": "This paper propose a parallel mechanism for stochastic gradient descent method (SGD) in case of gradient can be computed via linear operations (including least square linear regression and polynomial ", "SOUNDNESS_CORRECTNESS": 3}, {"IMPACT": 4, "APPROPRIATENESS": 2, "comments": "Overall, the idea in this paper is interesting and the paper is well-written and well-motivated. However, I think it is not ready to publish in ICLR for the following reasons: - This paper is not rela", "SOUNDNESS_CORRECTNESS": 3, "is_meta_review": false, "RECOMMENDATION": 2, "CLARITY": 5, "IS_META_REVIEW": false}, {"ORIGINALITY": 5, "is_meta_review": false, "comments": "This paper describes a correction technique to combine updates from multiple SGD to make it statistically equivalent to sequential technique. Comments 1) The proposed method is novel and interesting t", "IS_META_REVIEW": false}], "authors": "Saeed Maleki, Madanlal Musuvathi, Todd Mytkowicz, Yufei Ding", "accepted": false, "id": "745"}