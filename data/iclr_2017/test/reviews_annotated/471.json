{"conference": "ICLR 2017 conference submission", "title": "Batch Policy Gradient  Methods for  Improving Neural Conversation Models", "abstract": "We study reinforcement learning of chat-bots with recurrent neural network architectures when the rewards are noisy and expensive to obtain. For instance, a chat-bot used in automated customer service support can be scored by quality assurance agents, but this process can be expensive, time consuming and noisy.  Previous reinforcement learning work for natural language uses on-policy updates and/or is designed for on-line learning settings. We demonstrate empirically that such strategies are not appropriate for this setting and develop an off-policy batch policy gradient method (\\bpg). We demonstrate the efficacy of our method via a series of synthetic experiments and an Amazon Mechanical Turk experiment on a restaurant recommendations dataset.", "histories": [], "reviews": [{"IMPACT": 3, "IS_META_REVIEW": false, "is_meta_review": false, "comments": "This paper extends neural conversational models into the batch reinforcement learning setting. The idea is that you can collect human scoring data for some responses from a dialogue model, however suc", "SOUNDNESS_CORRECTNESS": 4}, {"IS_META_REVIEW": false, "CLARITY": 4, "is_meta_review": false, "comments": "The author propose to use a off-policy actor-critic algorithm in a batch-setting to improve chat-bots. The approach is well motivated and the paper is well written, except for some intuitions for why ", "SOUNDNESS_CORRECTNESS": 5}, {"ORIGINALITY": 3, "CLARITY": 5, "is_meta_review": false, "comments": "The paper discuss a \"batch\" method for RL setup to improve chat-bots. The authors provide nice overview of the RL setup they are using and present an algorithm which is similar to previously published", "IS_META_REVIEW": false}], "authors": "Kirthevasan Kandasamy, Yoram Bachrach, Ryota Tomioka, Daniel Tarlow, David Carter", "accepted": true, "id": "471"}