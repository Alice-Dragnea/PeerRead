{"conference": "ICLR 2017 conference submission", "title": "Investigating Recurrence and Eligibility Traces in Deep Q-Networks", "abstract": "Eligibility traces in reinforcement learning are used as a bias-variance trade-off and can often speed up training time by propagating knowledge back over time-steps in a single update. We investigate the use of eligibility traces in combination with recurrent networks in the Atari domain.  We illustrate the benefits of both recurrent nets and eligibility traces in some Atari games, and highlight also the importance of the optimization used in the training.", "histories": [], "reviews": [{"SUBSTANCE": 2, "MEANINGFUL_COMPARISON": 3, "comments": "This paper investigates the use of eligibility traces with recurrent DQN agents. As in other recent work on deep RL, the forward view of Sutton and Barto is used to make eligibility traces practical t", "SOUNDNESS_CORRECTNESS": 3, "is_meta_review": false, "CLARITY": 5, "IS_META_REVIEW": false}, {"SUBSTANCE": 3, "comments": "This paper combines DRQN with eligibility traces, and also experiment with the Adam optimizer for optimizing the q-network. This direction is worth exploring, and the experiments demonstrate the benef", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 3, "is_meta_review": false, "CLARITY": 5, "IS_META_REVIEW": false}, {"SUBSTANCE": 3, "MEANINGFUL_COMPARISON": 5, "comments": "The paper presents a deep RL with eligibility traces. The authors combine DRQN with eligibility traces for improved training. The new algorithm is evaluated on a two problems, with a single set of hyp", "ORIGINALITY": 3, "is_meta_review": false, "CLARITY": 5, "IS_META_REVIEW": false}], "authors": "Jean Harb, Doina Precup", "accepted": false, "id": "554"}