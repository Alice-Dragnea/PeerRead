{"conference": "ICLR 2017 conference submission", "title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "histories": [], "reviews": [{"IMPACT": 4, "MEANINGFUL_COMPARISON": 2, "comments": "This paper describes an end-to-end system for speech recognition that uses a linear conditional random field framework. A convnet estimates node potentials, while transition scores are provided by tra", "ORIGINALITY": 4, "IS_META_REVIEW": false, "is_meta_review": false}, {"is_meta_review": false, "comments": "There have been numerous works on learning from raw waveforms and training letter-based CTC networks for speech recognition, however, there are very few works on combining both of them with purely Con", "IS_META_REVIEW": false}, {"IS_META_REVIEW": false, "CLARITY": 5, "is_meta_review": false, "comments": "This submission proposes a letter-level decoder with a variation of the CTC approach they call ASG, where the blank symbol is dropped and replaced by letter repetition symbols, and where explicit norm", "MEANINGFUL_COMPARISON": 3}], "authors": "Ronan Collobert, Christian Puhrsch, Gabriel Synnaeve", "accepted": false, "id": "598"}