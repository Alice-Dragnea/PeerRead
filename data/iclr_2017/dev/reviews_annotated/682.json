{"conference": "ICLR 2017 conference submission", "title": "Annealing Gaussian into ReLU: a New Sampling Strategy for Leaky-ReLU RBM", "abstract": "Restricted Boltzmann Machine (RBM) is a bipartite graphical model that is used as the building block in energy-based deep generative models. Due to numerical stability and quantifiability of the likelihood,  RBM is commonly used with Bernoulli units. Here, we consider an alternative member of exponential family RBM with leaky rectified linear units -- called leaky RBM.  We first study the joint and marginal distributions of leaky RBM under different leakiness, which provides us important insights by connecting the leaky RBM model and truncated Gaussian distributions.  The connection leads us to a simple yet efficient method for sampling from this model, where the basic idea is to anneal the leakiness rather than the energy; -- i.e., start from a fully Gaussian/Linear unit and gradually decrease the leakiness over iterations.  This serves as an alternative to the annealing of the temperature parameter and enables numerical estimation of the likelihood that are more efficient and more accurate than the commonly used annealed importance sampling (AIS).  We further demonstrate that the proposed sampling algorithm enjoys faster mixing property than contrastive divergence algorithm, which benefits the training without any additional computational cost.", "histories": [], "reviews": [{"ORIGINALITY": 3, "IS_META_REVIEW": false, "is_meta_review": false, "comments": "Based on previous work such as the stepped sigmoid units and ReLU hidden units for discriminatively trained supervised models, a Leaky-ReLU model is proposed for generative learning. Pro: what is inte", "SOUNDNESS_CORRECTNESS": 3}, {"SUBSTANCE": 3, "is_meta_review": false, "comments": "The authors proposed to use leaky rectified linear units replacing binary units in Gaussian RBM. A sampling method was presented to train the leaky-ReLU RBM. In the experimental section, AIS estimated", "IS_META_REVIEW": false}, {"ORIGINALITY": 4, "IS_META_REVIEW": false, "is_meta_review": false, "comments": "The authors propose a novel energy-function for RBMs, using the leaky relu max(cx, x) activation function for the hidden-units. Analogous to ReLU units in feed-forward networks, these leaky relu RBMs ", "SOUNDNESS_CORRECTNESS": 3}], "authors": "Chun-Liang Li, Siamak Ravanbakhsh, Barnabas Poczos", "accepted": false, "id": "682"}