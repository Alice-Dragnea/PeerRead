{"conference": "ICLR 2017 conference submission", "title": "Is a picture worth a thousand words? A Deep Multi-Modal Fusion Architecture for Product Classification in e-commerce", "abstract": "Classifying products into categories precisely and efficiently is a major challenge in modern e-commerce. The high traffic of new products uploaded daily and the dynamic nature of the categories raise the need for machine learning models that can reduce the cost and time of human editors. In this paper, we propose a decision level fusion approach for multi-modal product classification using text and image inputs. We train input specific state-of-the-art deep neural networks for each input source, show the potential of forging them together into a multi-modal architecture and train a novel policy network that learns to choose between them. Finally, we demonstrate that our multi-modal network improves the top-1 accuracy $\\%$ over both networks on a real-world large-scale product classification dataset that we collected from Walmart.com. While we focus on image-text fusion that characterizes e-commerce domains, our algorithms can be easily applied to other modalities such as audio, video, physical sensors, etc.", "histories": [], "reviews": [{"IMPACT": 2, "comments": "This paper presents a system approach to combine multiple modalities to perform classification in a practical scenario (e-commerce). In general, I find the proposed approach in the paper sound and sol", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "is_meta_review": false, "RECOMMENDATION": 2, "IS_META_REVIEW": false}, {"IMPACT": 4, "SUBSTANCE": 3, "MEANINGFUL_COMPARISON": 2, "comments": "This paper tackles the problem of multi-modal classification of text and images. Pros: - Interesting dataset and application. Cons: - The results are rather lacklustre, showing a very mild improvement", "IS_META_REVIEW": false, "is_meta_review": false}, {"IMPACT": 5, "SUBSTANCE": 2, "comments": "This paper introduces a large-scale multi-model product classification system. The model consists of three modules, Image CNN (VGG 16 architecture), text CNN (Kim 2014) and decision-level fusion polic", "ORIGINALITY": 2, "is_meta_review": false, "RECOMMENDATION": 2, "CLARITY": 5, "IS_META_REVIEW": false}], "authors": "Tom Zahavy, Alessandro Magnani, Abhinandan Krishnan, Shie Mannor", "accepted": false, "id": "663"}