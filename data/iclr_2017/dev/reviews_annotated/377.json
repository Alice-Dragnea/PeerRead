{"conference": "ICLR 2017 conference submission", "title": "Learning to Perform Physics Experiments via Deep Reinforcement Learning", "abstract": "When encountering novel objects, humans are able to infer a wide range of physical properties such as mass, friction and deformability by interacting with them in a goal driven way. This process of active interaction is in the same spirit as a scientist performing experiments to discover hidden facts. Recent advances in artificial intelligence have yielded machines that can achieve superhuman performance in Go, Atari, natural language processing, and complex control problems; however, it is not clear that these systems can rival the scientific intuition of even a young child. In this work we introduce a basic set of tasks that require agents to estimate properties such as mass and cohesion of objects in an interactive simulated environment where they can manipulate the objects and observe the consequences. We found that deep reinforcement learning methods can learn to perform the experiments necessary to discover such hidden properties. By systematically manipulating the problem difficulty and the cost incurred by the agent for performing experiments, we found that agents learn different strategies that balance the cost of gathering information against the cost of making mistakes in different situations.  We also compare our learned experimentation policies to randomized baselines and show that the learned policies lead to better predictions.", "histories": [], "reviews": [{"ORIGINALITY": 4, "IS_META_REVIEW": false, "is_meta_review": false, "comments": "This paper addresses the question of how to utilize physical interactions to answer questions about physical outcomes. This question falls into a popular stream in ML community -- understanding physic", "RECOMMENDATION": 4}, {"IMPACT": 4, "comments": "This paper presents interesting experimental findings that state-of-the-art deep reinforcement learning methods enable agent learning of latent (physical) properties in its environment. The paper form", "ORIGINALITY": 4, "is_meta_review": false, "CLARITY": 5, "IS_META_REVIEW": false}, {"is_meta_review": false, "comments": "This paper investigates the question of gathering information (answering question) through direct interaction with the environment. In that sense, it is closely related to \"active learning\" in supervi", "IS_META_REVIEW": false}, {"IMPACT": 3, "comments": "This paper purports to investigate the ability of RL agents to perform physics experiments in an environment, to infer physical properties about the objects in that environment. The problem is very we", "ORIGINALITY": 4, "is_meta_review": false, "CLARITY": 5, "IS_META_REVIEW": false}], "authors": "Misha Denil, Pulkit Agrawal, Tejas D Kulkarni, Tom Erez, Peter Battaglia, Nando de Freitas", "accepted": true, "id": "377"}