{"conference": "ICLR 2017 conference submission", "title": "Deep unsupervised learning through spatial contrasting", "abstract": "Convolutional networks have marked their place over the last few years as the best performing model for various visual tasks. They are, however, most suited for supervised learning from large amounts of labeled data. Previous attempts have been made to use unlabeled data to improve model performance by applying unsupervised techniques. These attempts require different architectures and training methods. In this work we present a novel approach for unsupervised training of Convolutional networks that is based on contrasting between spatial regions within images.  This criterion can be employed within conventional neural net- works and trained using standard techniques such as SGD and back-propagation, thus complementing supervised methods.", "histories": [], "reviews": [{"IMPACT": 2, "SUBSTANCE": 3, "MEANINGFUL_COMPARISON": 3, "comments": "This paper proposes an unsupervised training objective based on patch contrasting for visual representation learning using deep neural networks. In particular, the feature representations of the patch", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "is_meta_review": false, "IS_META_REVIEW": false}, {"IS_META_REVIEW": false, "is_meta_review": false, "comments": "The proposed self supervised loss is formulated using a Siamese architecture and encourages patches from the same image to lie closer in feature space than a contrasting patch taken from a different, ", "SOUNDNESS_CORRECTNESS": 5}, {"IMPACT": 4, "comments": "This paper presents a novel way to do unsupervised pretraining in a deep convolutional network setting (though likely applicable to fully-connected nets as well). The method is that of spatial constra", "ORIGINALITY": 4, "is_meta_review": false, "CLARITY": 4, "IS_META_REVIEW": false}], "authors": "Elad Hoffer, Itay Hubara, Nir Ailon", "accepted": false, "id": "791"}