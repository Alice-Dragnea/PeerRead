{"conference": "ICLR 2017 conference submission", "title": "A Convolutional Encoder Model for Neural Machine Translation", "abstract": "The prevalent approach to neural machine translation relies on bi-directional LSTMs to encode the source sentence. In this paper we present a faster and simpler architecture based on a succession of convolutional layers.  This allows to encode the entire source sentence simultaneously compared to recurrent networks for which computation is constrained by temporal dependencies. On WMT'16 English-Romanian translation we achieve competitive accuracy to the state-of-the-art and we outperform several recently published results on the WMT'15 English-German task.  Our models obtain almost the same accuracy as a very deep LSTM setup on WMT'14 English-French translation. Our convolutional encoder speeds up CPU decoding by more than two times at the same or higher accuracy as a strong bi-directional LSTM baseline.", "histories": [], "reviews": [{"IMPACT": 3, "APPROPRIATENESS": 2, "comments": "The paper reports a very clear and easy to understand result that a convolutional network can be used instead of the recurrent encoder for neural machine translation. Apart from the known architectura", "ORIGINALITY": 2, "is_meta_review": false, "CLARITY": 5, "IS_META_REVIEW": false}, {"ORIGINALITY": 5, "APPROPRIATENESS": 3, "is_meta_review": false, "comments": "This paper is the first (I believe) to establish a simple yet important result that Convnets for NMT encoders can be competitive to RNNs. The authors present a convincing set of results over many tran", "IS_META_REVIEW": false}, {"IS_META_REVIEW": false, "APPROPRIATENESS": 2, "is_meta_review": false, "comments": "The system described works comparably to bi-directional LSTM baseline for NMT, and CNN's are naturally parallelizable. Key ideas include the use of two stacked CNN's (one for each of encoding and deco", "SOUNDNESS_CORRECTNESS": 5}], "authors": "Jonas Gehring, Michael Auli, David Grangier, Yann N. Dauphin", "accepted": false, "id": "748"}