{"conference": "ICLR 2017 conference submission", "title": "Attentive Recurrent Comparators", "abstract": "Attentive Recurrent Comparators (ARCs) are a novel class of neural networks built with attention and recurrence that learn to estimate the similarity of a set of objects by cycling through them and making observations. The observations made in one object are conditioned on the observations made in all the other objects. This allows ARCs to learn to focus on the salient aspects needed to ascertain similarity. Our simplistic model that does not use any convolutions performs comparably to Deep Convolutional Siamese Networks on various visual tasks. However using ARCs and convolutional feature extractors in conjunction produces a model that is significantly better than any other method and has superior generalization capabilities. On the Omniglot dataset, ARC based models achieve an error rate of 1.5\\% in the One-Shot classification task - a 2-3x reduction compared to the previous best models. This is also the first Deep Learning model to outperform humans (4.5\\%) and surpass the state of the art accuracy set by the highly specialized Hierarchical Bayesian Program Learning (HBPL) system (3.3\\%).", "histories": [], "reviews": [{"IMPACT": 3, "comments": "This paper describes a method that estimates the similarity between a set of images by alternatively attend each image with a recurrent manner. The idea of the paper is interesting, which mimic the hu", "SOUNDNESS_CORRECTNESS": 1, "ORIGINALITY": 4, "is_meta_review": false, "RECOMMENDATION": 1, "CLARITY": 2, "IS_META_REVIEW": false}, {"SUBSTANCE": 3, "CLARITY": 4, "is_meta_review": false, "comments": "This paper introduces an attention-based recurrent network that learns to compare images by attending iteratively back and forth between a pair of images. Experiments show state-of-the-art results on ", "IS_META_REVIEW": false}, {"SUBSTANCE": 4, "MEANINGFUL_COMPARISON": 3, "comments": "This paper presents an attention based recurrent approach to one-shot learning. It reports quite strong experimental results (surpassing human performance/HBPL) on the Omniglot dataset, which is somew", "SOUNDNESS_CORRECTNESS": 4, "IS_META_REVIEW": false, "is_meta_review": false}], "authors": "Pranav Shyam, Ambedkar Dukkipati", "accepted": false, "id": "569"}