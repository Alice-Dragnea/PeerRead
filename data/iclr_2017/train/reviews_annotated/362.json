{"conference": "ICLR 2017 conference submission", "title": "Learning to Optimize", "abstract": "Algorithm design is a laborious process and often requires many iterations of ideation and validation. In this paper, we explore automating algorithm design and present a method to learn an optimization algorithm. We approach this problem from a reinforcement learning perspective and represent any particular optimization algorithm as a policy. We learn an optimization algorithm using guided policy search and demonstrate that the resulting algorithm outperforms existing hand-engineered algorithms in terms of convergence speed and/or the final objective value.", "histories": [], "reviews": [{"SUBSTANCE": 3, "comments": "This papers adds to the literature on learning optimizers/algorithms that has gained popularity recently. The authors choose to use the framework of guided policy search at the meta-level to train the", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "IS_META_REVIEW": false, "is_meta_review": false}, {"is_meta_review": false, "comments": "The current version of the paper is improved w.r.t. the original arXiv version from June. While the results are exactly the same, the text does not oversell them as much as before. You may also consid", "IS_META_REVIEW": false}, {"ORIGINALITY": 4, "IS_META_REVIEW": false, "is_meta_review": false, "comments": "This paper proposes an approach to learning a custom optimizer for a given class optimization problems. I think in the case of training machine learning algorithms, a class would represent a model lik", "SOUNDNESS_CORRECTNESS": 5}], "authors": "Ke Li, Jitendra Malik", "accepted": true, "id": "362"}