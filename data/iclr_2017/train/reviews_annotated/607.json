{"conference": "ICLR 2017 conference submission", "title": "Memory-augmented Attention Modelling for Videos", "abstract": "Recent works on neural architectures have demonstrated the utility of attention mechanisms for a wide variety of tasks. Attention models used for problems such as image captioning typically depend on the image under consideration, as well as the previous sequence of words that come before the word currently being generated. While these types of models have produced impressive results, they are not able to model the higher-order interactions involved in problems such as video description/captioning, where the relationship between parts of the video and the concepts being depicted is complex. Motivated by these observations, we propose a novel memory-based attention model for video description. Our model utilizes memories of past attention when reasoning about where to attend to in the current time step, similar to the central executive system proposed in human cognition. This allows the model to not only reason about local attention more effectively, it allows it to consider the entire sequence of video frames while generating each word. Evaluation on the challenging and popular MSVD and Charades datasets show that the proposed architecture outperforms all previously proposed methods and leads to a new state of the art results in the video description.", "histories": [], "reviews": [{"IMPACT": 4, "SUBSTANCE": 3, "comments": "The authors propose a \"hierarchical\" attention model for video captioning. They introduce a model composed of three parts: the temporal modeler (TEM) that takes as input the video sequence and outputs", "SOUNDNESS_CORRECTNESS": 3, "is_meta_review": false, "RECOMMENDATION": 2, "IS_META_REVIEW": false}, {"IMPACT": 3, "comments": "This paper addresses video captioning with a TEM-HAM architecture, where a HAM module attends over attended outputs of the TEM module when generating the description. This gives a kind of 2-level atte", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "is_meta_review": false, "CLARITY": 3, "IS_META_REVIEW": false}, {"SUBSTANCE": 3, "comments": "The paper proposes an attention-based approach for video description. The approach uses three LSTMs and two attention mechanisms to sequentially predict words from a sequence of frames. In the LSTM-en", "ORIGINALITY": 3, "is_meta_review": false, "CLARITY": 4, "IS_META_REVIEW": false}], "authors": "Rasool Fakoor, Abdel-rahman Mohamed, Margaret Mitchell, Sing Bing Kang, Pushmeet Kohli", "accepted": false, "id": "607"}