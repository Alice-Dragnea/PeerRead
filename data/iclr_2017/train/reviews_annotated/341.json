{"conference": "ICLR 2017 conference submission", "title": "Third Person Imitation Learning", "abstract": "Reinforcement learning (RL) makes it possible to train agents capable of achieving sophisticated goals in complex and uncertain environments. A key difficulty in reinforcement learning is specifying a reward function for the agent to optimize. Traditionally, imitation learning in RL has been used to overcome this problem. Unfortunately, hitherto imitation learning methods tend to require that demonstrations are supplied in the first-person: the agent is provided with a sequence of states and a specification of the actions that it should have taken. While powerful, this kind of imitation learning is limited by the relatively hard problem of collecting first-person demonstrations. Humans address this problem by learning from third-person demonstrations: they observe other humans perform tasks, infer the task, and accomplish the same task themselves. In this paper, we present a method for unsupervised third-person imitation learning. Here third-person refers to training an agent to correctly achieve a simple goal in a simple environment when it is provided a demonstration of a teacher achieving the same goal but from a different viewpoint; and unsupervised refers to the fact that the agent receives only these third-person demonstrations, and is not provided a correspondence between teacher states and student states. Our methods primary insight is that recent advances from domain confusion can be utilized to yield domain agnostic features which are crucial during the training process. To validate our approach, we report successful experiments on learning from third-person demonstrations in a pointmass domain, a reacher domain, and inverted pendulum.", "histories": [], "reviews": [{"SUBSTANCE": 3, "comments": "This paper proposed a novel adversarial framework to train a model from demonstrations in a third-person perspective, to perform the task in the first-person view. Here the adversarial training is use", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 4, "IS_META_REVIEW": false, "is_meta_review": false}, {"IMPACT": 5, "CLARITY": 5, "is_meta_review": false, "comments": "The paper extends the imitation learning paradigm to the case where the demonstrator and learner have different points of view. This is an important contribution, with several good applications. The m", "IS_META_REVIEW": false}, {"IS_META_REVIEW": false, "SUBSTANCE": 3, "is_meta_review": false, "comments": "The paper presents an interesting new problem setup for imitation learning: an agent tries to imitate a trajectory demonstrated by an expert but said trajectory is demonstrated in a different state or", "MEANINGFUL_COMPARISON": 4}], "authors": "Bradly C Stadie, Pieter Abbeel, Ilya Sutskever", "accepted": true, "id": "341"}