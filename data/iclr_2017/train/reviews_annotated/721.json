{"conference": "ICLR 2017 conference submission", "title": "Transformational Sparse Coding", "abstract": "A fundamental problem faced by object recognition systems is that objects and their features can appear in different locations, scales and orientations. Current deep learning methods attempt to achieve invariance to local translations via pooling, discarding the locations of features in the process.  Other approaches explicitly learn transformed versions of the same feature, leading to representations that quickly explode in size. Instead of discarding the rich and useful information about feature transformations to achieve invariance, we argue that models should learn object features conjointly with their transformations to achieve equivariance.  We propose a new model of unsupervised learning based on sparse coding that can learn object features jointly with their affine transformations directly from images. Results based on learning from natural images indicate that our approach matches the reconstruction quality of traditional sparse coding but with significantly fewer degrees of freedom while simultaneously learning transformations from data. These results open the door to scaling up unsupervised learning to allow deep feature+transformation learning in a manner consistent with the ventral+dorsal stream architecture of the primate visual cortex.", "histories": [], "reviews": [{"SUBSTANCE": 2, "comments": "This paper proposes an approach to unsupervised learning based on a modification to sparse coding that allows for explicit modeling of transformations (such as shift, rotation, etc.), as opposed to si", "SOUNDNESS_CORRECTNESS": 3, "is_meta_review": false, "RECOMMENDATION": 3, "CLARITY": 3, "IS_META_REVIEW": false}, {"IMPACT": 3, "SUBSTANCE": 2, "comments": "A new sparse coding model is introduced that learns features jointly with their transformations. It is found that inference over per-image transformation variables is hard, so the authors suggest tyin", "ORIGINALITY": 3, "is_meta_review": false, "RECOMMENDATION": 2, "CLARITY": 3, "IS_META_REVIEW": false}, {"is_meta_review": false, "comments": "This paper trains a generative model of image patches, where dictionary elements undergo gated linear transformations before being combined. The transformations are motivated in terms of Lie group ope", "IS_META_REVIEW": false}], "authors": "Dimitrios C. Gklezakos, Rajesh P. N. Rao", "accepted": false, "id": "721"}