{"conference": "ICLR 2017 conference submission", "title": "Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data", "abstract": "We introduce Deep Variational Bayes Filters (DVBF), a new method for unsupervised learning and identification of latent Markovian state space models. Leveraging recent advances in Stochastic Gradient Variational Bayes, DVBF can overcome intractable inference distributions via variational inference. Thus, it can handle highly nonlinear input data with temporal and spatial dependencies such as image sequences without domain knowledge. Our experiments show that enabling backpropagation through transitions enforces state space assumptions and significantly improves information content of the latent embedding. This also enables realistic long-term prediction.", "histories": [], "reviews": [{"ORIGINALITY": 4, "IS_META_REVIEW": false, "is_meta_review": false, "comments": "The paper proposes to use the very standard SVGB in a sequential setting like several previous works did. However, they proposes to have a clear state space constraints similar to Linear Gaussian Mode", "SOUNDNESS_CORRECTNESS": 4}, {"CLARITY": 5, "is_meta_review": false, "comments": "This is mainly a (well-written) toy application paper. It explains SGVB can be applied to state-space models. The main idea is to cast a state-space model as a deterministic temporal transformation, w", "IS_META_REVIEW": false}, {"IMPACT": 4, "IS_META_REVIEW": false, "is_meta_review": false, "comments": "This paper presents a variational inference based method for learning nonlinear dynamical systems. Unlike the deep Kalman filter, the proposed method learns a state space model, which forces the laten", "RECOMMENDATION": 5}], "authors": "Maximilian Karl, Maximilian Soelch, Justin Bayer, Patrick van der Smagt", "accepted": true, "id": "422"}