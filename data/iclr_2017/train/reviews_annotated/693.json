{"conference": "ICLR 2017 conference submission", "title": "Fast Adaptation in Generative Models with Generative Matching Networks", "abstract": "Despite recent advances, the remaining bottlenecks in deep generative models are necessity of extensive training and difficulties with generalization from small number of training examples. Both problems may be addressed by conditional generative models that are trained to adapt the generative distribution to additional input data. So far this idea was explored only under certain limitations such as restricting the input data to be a single object or multiple objects representing the same concept.   In this work we develop a new class of deep generative model called generative matching networks which is inspired by the recently proposed matching networks for one-shot learning in discriminative tasks and the ideas from meta-learning. By conditioning on the additional input dataset, generative matching networks may instantly learn new concepts that were not available during the training but conform to a similar generative process, without explicit limitations on the number of additional input objects or the number of concepts they represent.  Our experiments on the Omniglot dataset demonstrate that generative matching networks can significantly improve predictive performance on the fly as more additional data is available to the model and also adapt the latent space which is beneficial in the context of feature extraction.", "histories": [], "reviews": [{"IMPACT": 3, "MEANINGFUL_COMPARISON": 1, "comments": "This paper presents a meta-learning algorithm which learns to learn generative models from a small set of examples. Its similar in structure to the matching networks of Vinyals et al. (2016), and is t", "ORIGINALITY": 3, "is_meta_review": false, "CLARITY": 3, "IS_META_REVIEW": false}, {"CLARITY": 3, "is_meta_review": false, "comments": "This paper proposes an interesting idea for rapidly adapting generative models in the low data regime. The idea is to use similar techniques that are used in one-shot learning, specifically ideas from", "IS_META_REVIEW": false}, {"IS_META_REVIEW": false, "SOUNDNESS_CORRECTNESS": 5, "is_meta_review": false, "comments": "The paper explores a VAE architecture and training procedure that allows to generate new samples of a concept based on several exemplars that are shown to the model. The proposed architecture processe", "MEANINGFUL_COMPARISON": 4}], "authors": "Sergey Bartunov, Dmitry P. Vetrov", "accepted": false, "id": "693"}