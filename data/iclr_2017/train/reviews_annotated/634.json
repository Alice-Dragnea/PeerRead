{"conference": "ICLR 2017 conference submission", "title": "Exploring LOTS in Deep Neural Networks", "abstract": "Deep neural networks have recently demonstrated excellent performance on various tasks. Despite recent advances, our understanding of these learning models is still incomplete, at least, as their unexpected vulnerability to imperceptibly small, non-random perturbations revealed. The existence of these so-called adversarial examples presents a serious problem of the application of vulnerable machine learning models. In this paper, we introduce the layerwise origin-target synthesis (LOTS) that can serve multiple purposes. First, we can use it as a visualization technique that gives us insights into the function of any intermediate feature layer by showing the notion of a particular input in deep neural networks. Second, our approach can be applied to assess the invariance of the learned features captured at any layer with respect to the class of the particular input. Finally, we can also utilize LOTS as a general way of producing a vast amount of diverse adversarial examples that can be used for training to further improve the robustness of machine learning models and their performance as well.", "histories": [], "reviews": [{"ORIGINALITY": 4, "IS_META_REVIEW": false, "is_meta_review": false, "comments": "This paper presents a relatively novel way to visualize the features / hidden units of a neural network and generate adversarial examples. The idea is to do gradient descent in the pixel space, from a", "SOUNDNESS_CORRECTNESS": 4}, {"comments": "This paper proposes the Layerwise Origin Target Synthesis (LOTS) method, which entails computing a difference in representation at a given layer in a neural network and then projecting that difference", "ORIGINALITY": 3, "IS_META_REVIEW": false, "RECOMMENDATION": 4, "APPROPRIATENESS": 2, "is_meta_review": false}, {"ORIGINALITY": 5, "IS_META_REVIEW": false, "is_meta_review": false, "comments": "The paper presents a new exciting layerwise origin-target synthesis method both for generating a large number of diverse adversarials as well as for understanding the robustness of various layers. The", "SOUNDNESS_CORRECTNESS": 5}], "authors": "Andras Rozsa, Manuel Gunther, Terrance E. Boult", "accepted": false, "id": "634"}