{"conference": "ICLR 2017 conference submission", "title": "Learning in Implicit Generative Models", "abstract": "Generative adversarial networks (GANs) provide an algorithmic framework for constructing generative models with several appealing properties: they do not require a likelihood function to be specified, only a generating procedure; they provide samples that are sharp and compelling; and they allow us to harness our knowledge of building highly accurate neural network classifiers. Here, we develop  our understanding of GANs with the aim of forming a rich view of this growing area of machine learning---to build connections to the diverse set of statistical thinking on this topic, of which much can be gained by a mutual exchange of ideas. We frame GANs within the wider landscape of algorithms for learning in implicit generative models---models that only specify a stochastic procedure with which to generate data---and relate these ideas to modelling problems in related fields, such as econometrics and approximate Bayesian computation. We develop likelihood-free inference methods and highlight hypothesis testing as a principle for learning in implicit generative models, using which we are able to derive the objective function used by GANs, and many other related objectives. The testing viewpoint directs our focus to the general problem of density ratio estimation. There are four approaches for density ratio estimation, one of which is a solution using classifiers to distinguish real from generated data. Other approaches such as divergence minimisation and moment matching have also been explored in the GAN literature, and we synthesise these views to form an understanding  in terms of the relationships between them and the wider literature, highlighting avenues for future exploration and cross-pollination.", "histories": [], "reviews": [{"MEANINGFUL_COMPARISON": 3, "comments": "I just noticed I submitted my review as a pre-review question - sorry about this. Here it is again, with a few more thoughts added... The authors present a great and - as far as I can tell - accurate ", "ORIGINALITY": 3, "IS_META_REVIEW": false, "CLARITY": 5, "is_meta_review": false}, {"IMPACT": 4, "IS_META_REVIEW": false, "is_meta_review": false, "comments": "Thank you for an interesting read. Given the huge interest in generative modelling nowadays, this paper is very timely and does provide very clear connections between methods that don't use maximum li", "RECOMMENDATION": 4}, {"IMPACT": 4, "comments": "The paper provides an exposition of multiple ways of learning in implicit generative models, of which generative adversarial networks are an example. The paper is very clear, the exposition is insight", "ORIGINALITY": 3, "is_meta_review": false, "RECOMMENDATION": 4, "CLARITY": 5, "IS_META_REVIEW": false}], "authors": "Shakir Mohamed, Balaji Lakshminarayanan", "accepted": false, "id": "534"}