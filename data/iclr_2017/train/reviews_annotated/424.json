{"conference": "ICLR 2017 conference submission", "title": "Mollifying Networks", "abstract": "The optimization of deep neural networks can be more challenging than the traditional convex optimization problems due to highly non-convex nature of the loss function, e.g. it can involve pathological landscapes such as saddle-surfaces that can be difficult to escape from for algorithms based on simple gradient descent. In this paper, we attack the problem of optimization of highly non-convex neural networks objectives by starting with a smoothed -- or mollified -- objective function which becomes more complex as the training proceeds.  Our proposition is inspired by the recent studies in continuation methods: similarly to curriculum methods, we begin by learning an easier (possibly convex) objective function and let it evolve during training until it eventually becomes the original, difficult to optimize objective function. The complexity of the mollified networks is controlled by a single hyperparameter that is annealed during training. We show improvements on various difficult optimization tasks and establish a relationship between recent works on continuation methods for neural networks and mollifiers.", "histories": [], "reviews": [{"is_meta_review": false, "comments": "The paper shows the relation between stochastically perturbing the parameter of a model at training time, and considering a mollified objective function for optimization. Aside from Eqs. 4-7 where I f", "IS_META_REVIEW": false}, {"ORIGINALITY": 4, "IS_META_REVIEW": false, "is_meta_review": false, "comments": "This paper first discusses a general framework for improving optimization of a complicated function using a series of approximations. If the series of approximations are well-behaved compared to the o", "RECOMMENDATION": 2}, {"comments": "The authors show that the idea of smoothing a highly non-convex loss function can make deep neural networks easier to train. The paper is well-written, the idea is carefully analyzed, and the experime", "SOUNDNESS_CORRECTNESS": 5, "IS_META_REVIEW": false, "RECOMMENDATION": 4, "CLARITY": 5, "is_meta_review": false}], "authors": "Caglar Gulcehre, Marcin Moczulski, Francesco Visin, Yoshua Bengio", "accepted": true, "id": "424"}