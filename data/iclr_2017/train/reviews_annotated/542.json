{"conference": "ICLR 2017 conference submission", "title": "Modular Multitask Reinforcement Learning with Policy Sketches", "abstract": "We describe a framework for multitask deep reinforcement learning guided by policy sketches. Sketches annotate each task with a sequence of named subtasks, providing high-level structural relationships among tasks, but not providing the detailed guidance required by previous work on learning policy abstractions for RL (e.g. intermediate rewards, subtask completion signals, or intrinsic motivations). Our approach associates every subtask with its own modular subpolicy, and jointly optimizes over full task-specific policies by tying parameters across shared subpolicies. This optimization is accomplished via a simple decoupled actor\u2013critic training objective that facilitates learning common behaviors from dissimilar reward functions. We evaluate the effectiveness of our approach on a maze navigation game and a 2-D Minecraft-inspired crafting game. Both games feature extremely sparse rewards that can be obtained only after completing a number of high-level subgoals (e.g. escaping from a sequence of locked rooms or collecting and combining various ingredients in the proper order). Experiments illustrate two main advantages of our approach. First, we outperform standard baselines that learn task-specific or shared monolithic policies. Second, our method naturally induces a library of primitive behaviors that can be recombined to rapidly acquire policies for new tasks.", "histories": [], "reviews": [{"IMPACT": 2, "APPROPRIATENESS": 3, "comments": "The paper proposes a new RL architecture that aims at learning policies from sketches i.e sequence of high-level operations to execute for solving a particular task. The model relies on a hierarchical", "ORIGINALITY": 5, "is_meta_review": false, "CLARITY": 5, "IS_META_REVIEW": false}, {"IMPACT": 4, "MEANINGFUL_COMPARISON": 3, "comments": "The paper presents an approach to learning shared neural representations of temporal abstractions in hierarchical RL, based on actor-critic methods. The approach is illustrated in two tasks: gridworld", "ORIGINALITY": 3, "IS_META_REVIEW": false, "is_meta_review": false}, {"ORIGINALITY": 3, "CLARITY": 4, "is_meta_review": false, "comments": "This paper studies the problem of abstract hierarchical multiagent RL with policy sketches, high level descriptions of abstract actions. The work is related to much previous work in hierarchical RL, a", "IS_META_REVIEW": false}], "authors": "Jacob Andreas, Dan Klein, Sergey Levine", "accepted": false, "id": "542"}