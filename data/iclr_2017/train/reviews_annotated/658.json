{"conference": "ICLR 2017 conference submission", "title": "Encoding and Decoding Representations with Sum- and Max-Product Networks", "abstract": "Sum-Product networks (SPNs) are expressive deep architectures for representing probability distributions, yet allowing exact and efficient inference. SPNs have been successfully applied in several domains, however always as black-box distribution estimators. In this paper, we argue that due to their recursive definition, SPNs can also be naturally employed as hierarchical feature extractors and thus for unsupervised representation learning. Moreover, when converted into Max-Product Networks (MPNs), it is possible to decode such representations back into the original input space. In this way, MPNs can be interpreted as a kind of generative autoencoder, even if they were never trained to reconstruct the input data. We show how these learned representations, if visualized, indeed correspond to \"meaningful parts\" of the training data. They also yield a large improvement when used in structured prediction tasks. As shown in extensive experiments, SPN and MPN encoding and decoding schemes prove very competitive  against the ones employing RBMs and other stacked autoencoder architectures.", "histories": [], "reviews": [{"SUBSTANCE": 2, "comments": "The paper's aim is - as argued in the paper and the responses to other reviewers comments - that SPN and MPN can be interpreted as encoders and decoders of RL. Well - this is an interesting perspectiv", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 4, "is_meta_review": false, "RECOMMENDATION": 1, "CLARITY": 1, "IS_META_REVIEW": false}, {"SUBSTANCE": 5, "CLARITY": 3, "is_meta_review": false, "comments": "The authors propose and evaluate using SPN's to generate embeddings of input and output variables, and using MPN to decode output embeddings to output variables. The advantage of predicting label embe", "IS_META_REVIEW": false}, {"ORIGINALITY": 4, "SUBSTANCE": 3, "is_meta_review": false, "comments": "This paper tries to solve the problem of interpretable representations with focus on Sum Product Networks. The authors argue that SPNs are a powerful linear models that are able to learn parts and the", "IS_META_REVIEW": false}], "authors": "Antonio Vergari, Robert Peharz, Nicola Di Mauro, Floriana Esposito", "accepted": false, "id": "658"}