{"conference": "ICLR 2017 conference submission", "title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "histories": [], "reviews": [{"IMPACT": 3, "comments": "The authors extend their method of causal discovery (Chalupka et al 2016) to include assumptions about sparsity via regularization. They apply this extension to an interesting private dataset from Sut", "ORIGINALITY": 3, "is_meta_review": false, "RECOMMENDATION": 2, "CLARITY": 3, "IS_META_REVIEW": false}, {"IS_META_REVIEW": false, "SUBSTANCE": 3, "is_meta_review": false, "comments": "This paper proposes to use a causality score to weight a sparsity regularizer. In that way, selected variables trade off between being causal and discriminative. The framework is primarily evaluated o", "RECOMMENDATION": 2}, {"MEANINGFUL_COMPARISON": 3, "comments": "The present submission discusses a \"causal regularizer\", which promotes the use of causal dependencies (X -> Y, where X is a feature of the learning problem, and Y is the target variable) in predictiv", "ORIGINALITY": 3, "is_meta_review": false, "RECOMMENDATION": 4, "CLARITY": 4, "IS_META_REVIEW": false}], "authors": "Mohammad Taha Bahadori, Krzysztof Chalupka, Edward Choi, Robert Chen, Walter F. Stewart, Jimeng Sun", "accepted": false, "id": "613"}