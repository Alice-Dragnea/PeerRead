{"conference": "ICLR 2017 conference submission", "title": "Sequence to Sequence Transduction with Hard Monotonic Attention", "abstract": "We present a supervised sequence to sequence transduction model with a hard attention mechanism which combines the more traditional statistical alignment methods with the power of recurrent neural networks. We evaluate the model on the task of morphological inflection generation and show that it provides state of the art results in various setups compared to the previous neural and non-neural approaches. Eventually we present an analysis of the learned representations for both hard and soft attention models, shedding light on the features such models extract in order to solve the task.", "histories": [], "reviews": [{"IMPACT": 2, "SUBSTANCE": 3, "MEANINGFUL_COMPARISON": 3, "comments": "The paper proposes an approach to sequence transduction for the case when a monotonic alignment between the input and the output is plausible. It is assumed that the alignment can be provided as a par", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "is_meta_review": false, "IS_META_REVIEW": false}, {"SUBSTANCE": 5, "comments": "This paper proposes a sequence transduction model that first uses a traditional statistical alignment methods to provide alignments for an encoder-decoder type model. The paper provides experiments on", "ORIGINALITY": 2, "is_meta_review": false, "CLARITY": 5, "IS_META_REVIEW": false}, {"ORIGINALITY": 3, "is_meta_review": false, "comments": "The paper describes a recurrent transducer that uses hard monotonic alignments: at each step a discrete decision is taken either to emit the next symbol or to consume the next input token. The model i", "IS_META_REVIEW": false}], "authors": "Roee Aharoni, Yoav Goldberg", "accepted": false, "id": "659"}