{"conference": "ICLR 2017 conference submission", "title": "Reinforcement Learning through Asynchronous Advantage Actor-Critic on a GPU", "abstract": "We introduce a hybrid CPU/GPU version of the Asynchronous Advantage Actor-Critic (A3C) algorithm, currently the state-of-the-art method in reinforcement learning for various gaming tasks. We analyze its computational traits and concentrate on aspects critical to leveraging the GPU's computational power. We introduce a system of queues and a dynamic scheduling strategy, potentially helpful for other asynchronous algorithms as well. Our hybrid CPU/GPU version of A3C, based on TensorFlow, achieves a significant speed up compared to a CPU implementation; we make it publicly available to other researchers at", "histories": [], "reviews": [{"ORIGINALITY": 3, "is_meta_review": false, "comments": "The paper introduces GA3C, a GPU-based implementation of the A3C algorithm, which was originally designed for multi-core CPUs. The main innovation is the introduction of a system of queues. The queues", "IS_META_REVIEW": false}, {"SUBSTANCE": 3, "is_meta_review": false, "comments": "This paper introduce a variant of A3C model where while agents run on multiple cores on CPU the model computations which is the computationally intensive part is passed to the GPU. And they perform va", "IS_META_REVIEW": false}, {"is_meta_review": false, "comments": "This paper introduces a 'GPU-friendly' variant of A3C which relaxes some synchronicity constraints in the original A3C algorithm to make it more friendly to a high-throughput GPU device. The analysis ", "IS_META_REVIEW": false}], "authors": "Mohammad Babaeizadeh, Iuri Frosio, Stephen Tyree, Jason Clemons, Jan Kautz", "accepted": true, "id": "437"}