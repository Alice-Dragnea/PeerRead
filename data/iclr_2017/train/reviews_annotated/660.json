{"conference": "ICLR 2017 conference submission", "title": "Improving Stochastic Gradient Descent with Feedback", "abstract": "In this paper we propose a simple and efficient method for improving stochastic gradient descent methods by using feedback from the objective function. The method tracks the relative changes in the objective function with a running average, and uses it to adaptively tune the learning rate in stochastic gradient descent. We specifically apply this idea to modify Adam, a popular algorithm for training deep neural networks. We conduct experiments to compare the resulting algorithm, which we call Eve, with state of the art methods used for training deep learning models. We train CNNs for image classification, and RNNs for language modeling and question answering. Our experiments show that Eve outperforms all other algorithms on these benchmark tasks. We also analyze the behavior of the feedback mechanism during the training process.", "histories": [], "reviews": [{"is_meta_review": false, "comments": "As you noted for Figure 5 Left, sometimes it seems sufficient to tune learning rates. I see your argument for Figure 6 Right, but 1) not for all good learning rates make Adam fail, I guess you selecte", "IS_META_REVIEW": false}, {"ORIGINALITY": 2, "CLARITY": 3, "is_meta_review": false, "comments": "The paper introduced an extension of Adam optimizer that automatically adjust learning rate by comparing the subsequent values of the cost function during training. The authors empirically demonstrate", "IS_META_REVIEW": false}, {"ORIGINALITY": 2, "CLARITY": 5, "is_meta_review": false, "comments": "The paper demonstrates a semi-automatic learning rate schedule for the Adam optimizer, called Eve. Originality is somehow limited but the method appears to have a positive effect on neural network tra", "IS_META_REVIEW": false}], "authors": "Jayanth Koushik, Hiroaki Hayashi", "accepted": false, "id": "660"}