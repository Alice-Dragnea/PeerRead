{"conference": "ICLR 2017 conference submission", "title": "Learning Curve Prediction with Bayesian Neural Networks", "abstract": "Different neural network architectures, hyperparameters and training protocols lead to different performances as a function of time. Human experts routinely inspect the resulting learning curves to quickly terminate runs with poor hyperparameter settings and thereby considerably speed up manual hyperparameter optimization. Exploiting the same information in automatic Bayesian hyperparameter optimization requires a probabilistic model of learning curves across hyperparameter settings. Here, we study the use of Bayesian neural networks for this purpose and improve their performance by a specialized learning curve layer.", "histories": [], "reviews": [{"is_meta_review": false, "comments": "This paper proposes a new Bayesian neural network architecture for predicting the values of learning curves during the training of machine learning models. This is an exploratory paper, in that the ul", "IS_META_REVIEW": false}, {"CLARITY": 4, "is_meta_review": false, "comments": "The paper addresses the problem of predicting learning curves. The key difference from prior work is that (1) the authors learn a neural network that generalizes across hyperparameter settings and (2)", "IS_META_REVIEW": false}, {"SUBSTANCE": 3, "comments": "This paper is about using Bayesian neural networks to model learning curves (that arise from training ML algorithms). The application is hyper-parameter optimization: if we can model the learning curv", "ORIGINALITY": 2, "IS_META_REVIEW": false, "RECOMMENDATION": 5, "is_meta_review": false}], "authors": "Aaron Klein, Stefan Falkner, Jost Tobias Springenberg, Frank Hutter", "accepted": true, "id": "361"}