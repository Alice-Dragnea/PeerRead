{"conference": "ICLR 2017 conference submission", "title": "Boosted Generative Models", "abstract": "We propose a new approach for using boosting to create an ensemble of generative models, where models are trained in sequence to correct earlier mistakes. Our algorithm can leverage  many existing base learners, including recent latent variable models. Further, our approach allows the ensemble to leverage discriminative models trained to distinguish real data from model generated data. We show theoretical conditions under which incorporating a new model to the ensemble will improve the fit and empirically demonstrate the effectiveness of boosting on density estimation and sample generation on real and synthetic datasets.", "histories": [], "reviews": [{"ORIGINALITY": 4, "CLARITY": 5, "is_meta_review": false, "comments": "The paper proposes two approaches to boosting generative models, both based on likelihood ratio estimates. The approaches are evaluated on synthetic data, as well as on MNIST dataset for the tasks of ", "IS_META_REVIEW": false}, {"IS_META_REVIEW": false, "is_meta_review": false, "comments": "The authors propose two approaches to combine multiple weak generative models into a stronger one using principles from boosting. The approach is simple and elegant and basically creates an unnormaliz", "SOUNDNESS_CORRECTNESS": 3}, {"IS_META_REVIEW": false, "SUBSTANCE": 3, "is_meta_review": false, "comments": "This paper extends boosting to the task of learning generative models of data. The strong learner is obtained as a geometric average of weak learners, which can themselves be normalized (e.g. VAE) or ", "RECOMMENDATION": 3}], "authors": "Aditya Grover, Stefano Ermon", "accepted": false, "id": "571"}