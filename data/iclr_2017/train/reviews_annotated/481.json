{"conference": "ICLR 2017 conference submission", "title": "Adversarial Machine Learning at Scale", "abstract": "Adversarial examples are malicious inputs designed to fool machine learning models. They often transfer from one model to another, allowing attackers to mount black box attacks without knowledge of the target model's parameters. Adversarial training is the process of explicitly training a model on adversarial examples, in order to make it more robust to attack or to reduce its test error on clean inputs. So far, adversarial training has primarily been applied to small problems. In this research, we apply adversarial training to ImageNet. Our contributions include: (1) recommendations for how to succesfully scale adversarial training to large models and datasets, (2) the observation that adversarial training confers robustness to single-step attack methods, (3) the finding that multi-step attack methods are somewhat less transferable than single-step attack       methods, so single-step attacks are the best for mounting black-box attacks,       and (4) resolution of a ``label leaking'' effect that causes adversarially trained models to perform       better on adversarial examples than on clean examples, because the adversarial       example construction process uses the true label and the model can learn to       exploit regularities in the construction process.", "histories": [], "reviews": [{"IMPACT": 4, "comments": "This paper is a well written paper. This paper can be divided into 2 parts: 1.Adversary training on ImageNet 2.Empirical study of label leak, single/multiple step attack, transferability and importanc", "ORIGINALITY": 5, "is_meta_review": false, "CLARITY": 5, "IS_META_REVIEW": false}, {"ORIGINALITY": 5, "CLARITY": 5, "is_meta_review": false, "comments": "This paper investigate the phenomenon of the adversarial examples and the adversarial training on the dataset of ImageNet. While the final conclusions are still vague, this paper raises several notewo", "IS_META_REVIEW": false}, {"IMPACT": 5, "APPROPRIATENESS": 5, "comments": "This paper has two main contributions: (1) Applying adversarial training to imagenet, a larger dataset than previously considered (2) Comparing different adversarial training approaches, focusing impo", "ORIGINALITY": 5, "is_meta_review": false, "RECOMMENDATION": 5, "CLARITY": 5, "IS_META_REVIEW": false}], "authors": "Alexey Kurakin, Ian J. Goodfellow, Samy Bengio", "accepted": true, "id": "481"}