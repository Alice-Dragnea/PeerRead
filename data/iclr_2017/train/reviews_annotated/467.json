{"conference": "ICLR 2017 conference submission", "title": "Adversarial Feature Learning", "abstract": "The ability of the Generative Adversarial Networks (GANs) framework to learn generative models mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically, with compelling results showing generators learn to \"linearize semantics\" in the latent space of such models. Intuitively, such latent spaces may serve as useful feature representations for auxiliary problems where semantics are relevant. However, in their existing form, GANs have no means of learning the inverse mapping -- projecting data back into the latent space. We propose Bidirectional Generative Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.", "histories": [], "reviews": [{"is_meta_review": false, "comments": "This is a parallel work with ALI. The idea is using auto encoder to provide extra information for discriminator. This approach seems is promising from reported result. For feature learning part of BiG", "IS_META_REVIEW": false}, {"comments": "This paper provides an interesting idea, which extends GAN by taking into account bidirectional network. Totally, the paper is well-written, and easy to follow what is contribution of this paper. From", "ORIGINALITY": 3, "IS_META_REVIEW": false, "RECOMMENDATION": 4, "CLARITY": 5, "is_meta_review": false}, {"CLARITY": 5, "is_meta_review": false, "comments": "The authors extend GANs by an inference path from the data space to the latent space and a discriminator that operates on the joint latend/data space. They show that the theoretical properties of GANs", "IS_META_REVIEW": false}], "authors": "Jeff Donahue, Philipp Kr\u00e4henb\u00fchl, Trevor Darrell", "accepted": true, "id": "467"}