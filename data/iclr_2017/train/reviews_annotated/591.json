{"conference": "ICLR 2017 conference submission", "title": "Sample Importance in Training Deep Neural Networks", "abstract": "The contribution of each sample during model training varies across training iterations and the model's parameters. We define the concept of sample importance as the change in parameters induced by a sample. In this paper, we explored the sample importance in training deep neural networks using stochastic gradient descent. We found that \"easy\" samples -- samples that are correctly and confidently classified at the end of the training -- shape parameters closer to the output, while the \"hard\" samples impact parameters closer to the input to the network. Further, \"easy\" samples are relevant in the early training stages, and \"hard\" in the late training stage. Further, we show that constructing batches which contain samples of comparable difficulties tends to be a poor strategy compared to maintaining a mix of both hard and easy samples in all of the batches. Interestingly, this contradicts some of the results on curriculum learning which suggest that ordering training examples in terms of difficulty can lead to better performance.", "histories": [], "reviews": [{"IMPACT": 4, "SUBSTANCE": 4, "MEANINGFUL_COMPARISON": 5, "comments": "The paper proposes a new criterion (sample importance) to study the impact of samples during the training of deep neural networks. This criterion is not clearly defined (the term \\phi^t_{i,j} is never", "SOUNDNESS_CORRECTNESS": 4, "is_meta_review": false, "CLARITY": 4, "IS_META_REVIEW": false}, {"IS_META_REVIEW": false, "SUBSTANCE": 4, "is_meta_review": false, "comments": "(paper summary) The authors introduce the notion of sample importance, meant to measure the influence of a particular training example on the training of a deep neural network. This quantity is closel", "SOUNDNESS_CORRECTNESS": 2}, {"SUBSTANCE": 4, "is_meta_review": false, "comments": "This paper examines the so called \"Sample Importance\" of each sample of a training data set, and its effect to the overall learning process. The paper shows empirical results that shows different trai", "IS_META_REVIEW": false}], "authors": "Tianxiang Gao, Vladimir Jojic", "accepted": false, "id": "591"}