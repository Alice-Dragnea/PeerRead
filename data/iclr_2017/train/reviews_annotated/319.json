{"conference": "ICLR 2017 conference submission", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "histories": [], "reviews": [{"ORIGINALITY": 2, "CLARITY": 5, "is_meta_review": false, "comments": "This paper proposes to investigate attention transfers between a teacher and a student network. Attention transfer is performed by minimising the l2 distance between the teacher/student attention maps", "IS_META_REVIEW": false}, {"CLARITY": 5, "is_meta_review": false, "comments": "The paper presented a modified knowledge distillation framework that minimizes the difference of the sum of statistics across the a feature map between the teacher and the student network. The authors", "IS_META_REVIEW": false}, {"SUBSTANCE": 3, "is_meta_review": false, "comments": "The paper proposes a new way of transferring knowledge. I like the idea of transferring attention maps instead of activations. However, the experiments dont show a big improvement compared with knowle", "IS_META_REVIEW": false}], "authors": "Sergey Zagoruyko, Nikos Komodakis", "accepted": true, "id": "319"}