{"conference": "ICLR 2017 conference submission", "title": "Loss-aware Binarization of Deep Networks", "abstract": "Deep neural network models, though very powerful and highly successful, are computationally expensive in terms of space and time. Recently, there have been a number of attempts on binarizing the network weights and activations. This greatly reduces the network size, and replaces the underlying multiplications to additions or even XNOR bit operations. However, existing binarization schemes are based on simple matrix approximations and ignore the effect of binarization on the loss. In this paper, we propose a proximal Newton algorithm with diagonal Hessian approximation that directly minimizes the loss w.r.t. the binarized weights. The underlying proximal step has an efficient closed-form solution, and the second-order information can be efficiently obtained from the second moments already computed by the Adam optimizer. Experiments on both feedforward and recurrent networks show that the proposed loss-aware binarization algorithm outperforms existing binarization schemes, and is also more robust for wide and deep networks.", "histories": [], "reviews": [{"IS_META_REVIEW": false, "is_meta_review": false, "comments": "This paper proposed a proximal (quasi-) Newtons method to learn binary DNN. The main contribution is to combine pre-conditioning with binarization in a proximal framework. It is interesting to have a ", "SOUNDNESS_CORRECTNESS": 3}, {"SUBSTANCE": 3, "is_meta_review": false, "comments": "Taking into account the loss in the binarization step through a proximal Newton algorithm is a nice idea. This is at least one approach to bringing in the missing loss in the binarization step, which ", "IS_META_REVIEW": false}, {"SUBSTANCE": 5, "is_meta_review": false, "comments": "The paper presents a second-order method for training a neural networks while ensuring at the same time that weights (and activations) are binary. Through binarization, the method aims to achieve mode", "IS_META_REVIEW": false}], "authors": "Lu Hou, Quanming Yao, James T. Kwok", "accepted": true, "id": "453"}