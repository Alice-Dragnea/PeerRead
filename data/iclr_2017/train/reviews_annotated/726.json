{"conference": "ICLR 2017 conference submission", "title": "Information Dropout: learning optimal representations through noise", "abstract": "We introduce Information Dropout, a generalization of dropout that is motivated by the Information Bottleneck principle and highlights the way in which injecting noise in the activations can help in learning optimal representations of the data. Information Dropout is rooted in information theoretic principles, it includes as special cases several existing dropout methods, like Gaussian Dropout and Variational Dropout, and, unlike classical dropout, it can learn and build representations that are invariant to nuisances of the data, like occlusions and clutter. When the task is the reconstruction of the input, we show that the information dropout method yields a variational autoencoder as a special case, thus providing a link between representation learning, information theory and variational inference. Our experiments validate the theoretical intuitions behind our method, and we find that information dropout achieves a comparable or better generalization performance than binary dropout, especially on smaller models, since it can automatically adapt the noise to the structure of the network, as well as to the test sample.", "histories": [], "reviews": [{"SUBSTANCE": 2, "is_meta_review": false, "comments": "The authors propose \"information dropout\", a variation of dropout with an information theoretic interpretation. A dropout layer limits the amount of information that can be passed through it, and the ", "IS_META_REVIEW": false}, {"SUBSTANCE": 3, "is_meta_review": false, "comments": "An interesting connection is made between dropout, Tishby et al's \"information bottleneck\" and VAEs. Specifically, classification of 'y' from 'x' is split in two faces: an inference model z ~ q(z|x), ", "IS_META_REVIEW": false}, {"IMPACT": 3, "APPROPRIATENESS": 5, "comments": "Paper summary This paper develops a generalization of dropout using information theoretic principles. The basic idea is that when learning a representation z of input x with the aim of predicting y, w", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 4, "is_meta_review": false, "CLARITY": 5, "IS_META_REVIEW": false}], "authors": "Alessandro Achille, Stefano Soatto", "accepted": false, "id": "726"}