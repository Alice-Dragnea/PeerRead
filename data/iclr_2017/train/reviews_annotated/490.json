{"conference": "ICLR 2017 conference submission", "title": "Pointer Sentinel Mixture Models", "abstract": "Recent neural network sequence models with softmax classifiers have achieved their best language modeling performance only with very large hidden states and large vocabularies. Even then they struggle to predict rare or unseen words even if the context makes the prediction unambiguous. We introduce the pointer sentinel mixture architecture for neural sequence models which has the ability to either reproduce a word from the recent context or produce a word from a standard softmax classifier. Our pointer sentinel-LSTM model achieves state of the art language modeling performance on the Penn Treebank (70.9 perplexity) while using far fewer parameters than a standard softmax LSTM. In order to evaluate how well language models can exploit longer contexts and deal with more realistic vocabularies and corpora we also introduce the freely available WikiText corpus.", "histories": [], "reviews": [{"ORIGINALITY": 2, "IS_META_REVIEW": false, "is_meta_review": false, "comments": "This paper proposes augmenting RNN-based language models with a pointer network in order to deal better with rare words. The pointer network can point to words in the recent context, and hence the pre", "SOUNDNESS_CORRECTNESS": 3}, {"IMPACT": 4, "comments": "This work is an extension of previous works on pointer models, that mixes its outputs with standard softmax outputs. The idea is appealing in general for context biasing and the specific approach appe", "ORIGINALITY": 2, "is_meta_review": false, "CLARITY": 5, "IS_META_REVIEW": false}, {"IS_META_REVIEW": false, "CLARITY": 5, "is_meta_review": false, "comments": "This work is basically a combined pointer network applied on language modelling. The smart point is that this paper aims at language modelling with longer context, where a memory of seen words (especi", "RECOMMENDATION": 5}], "authors": "Stephen Merity, Caiming Xiong, James Bradbury, Richard Socher", "accepted": true, "id": "490"}