{"conference": "ICLR 2017 conference submission", "title": "Visualizing Deep Neural Network Decisions: Prediction Difference Analysis", "abstract": "This article presents the prediction difference analysis method for visualizing the response of a deep neural network to a specific input. When classifying images, the method highlights areas in a given input image that provide evidence for or against a certain class. It overcomes several shortcoming of previous methods and provides great additional insight into the decision making process of classifiers. Making neural network decisions interpretable through visualization is important both to improve models and to accelerate the adoption of black-box classifiers in application areas such as medicine. We illustrate the method in experiments on natural images (ImageNet data), as well as medical images (MRI brain scans).", "histories": [], "reviews": [{"CLARITY": 5, "is_meta_review": false, "comments": "The authors of this work propose an interesting approach to visualizing the predictions made by a deep neural network. The manuscript is well written is provides good insight into the problem. I also ", "IS_META_REVIEW": false}, {"ORIGINALITY": 3, "is_meta_review": false, "comments": "The paper presents a theoretically well motivated for visualizing what parts of the input feature map are responsible for the output decision. The key insight is that features that maximally change th", "IS_META_REVIEW": false}, {"IMPACT": 5, "comments": "The authors propose a way to visualize which areas of an image provide mostly influence a certain DNN response mostly. They apply some very elegant and convincing improvements to the basic method by R", "IS_META_REVIEW": false, "RECOMMENDATION": 5, "CLARITY": 5, "is_meta_review": false}], "authors": "Luisa M Zintgraf, Taco S Cohen, Tameem Adel, Max Welling", "accepted": true, "id": "427"}