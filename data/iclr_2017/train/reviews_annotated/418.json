{"conference": "ICLR 2017 conference submission", "title": "Unrolled Generative Adversarial Networks", "abstract": "We introduce a method to stabilize Generative Adversarial Networks (GANs) by defining the generator objective with respect to an unrolled optimization of the discriminator. This allows training to be adjusted between using the optimal discriminator in the generator's objective, which is ideal but infeasible in practice, and using the current value of the discriminator, which is often unstable and leads to poor solutions. We show how this technique solves the common problem of mode collapse, stabilizes training of GANs with complex recurrent generators, and increases diversity and coverage of the data distribution by the generator.", "histories": [], "reviews": [{"ORIGINALITY": 5, "CLARITY": 5, "is_meta_review": false, "comments": "This work introduces a novel method for training GANs by displacing simultaneous SGD, and unrolling the inner optimization in the minmax game as a computational graph. The paper is very clearly writte", "IS_META_REVIEW": false}, {"CLARITY": 5, "is_meta_review": false, "comments": "The paper presents an approach for tackling the instability problem that is present in generative adversarial networks. The general idea is to allow the generator to \"peek ahead\" at how the discrimina", "IS_META_REVIEW": false}, {"IMPACT": 4, "comments": "The paper introduces a technique for stabilizing the training of Generative Adversrial Networks by unrolling the inner (discriminator) optimization in the GAN loss function several steps and optimizin", "SOUNDNESS_CORRECTNESS": 5, "IS_META_REVIEW": false, "RECOMMENDATION": 5, "is_meta_review": false}], "authors": "Luke Metz, Ben Poole, David Pfau, Jascha Sohl-Dickstein", "accepted": true, "id": "418"}