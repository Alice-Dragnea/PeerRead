{"conference": "ICLR 2017 conference submission", "title": "Generating Interpretable Images with Controllable Structure", "abstract": "We demonstrate improved text-to-image synthesis with controllable object locations using an extension of Pixel Convolutional Neural Networks (PixelCNN). In addition to conditioning on text, we show how the model can generate images conditioned on part keypoints and segmentation masks. The character-level text encoder and image generation network are jointly trained end-to-end via maximum likelihood. We establish quantitative baselines in terms of text and structure-conditional pixel log-likelihood for three data sets: Caltech-UCSD Birds (CUB), MPII Human Pose (MHP), and Common Objects in Context (MS-COCO).", "histories": [], "reviews": [{"comments": "This paper proposes an extension of PixelCNN method that can be conditioned on text and spatially-structured constraints (segmentation / keypoints). It is similar to Reed 2016a except the extension is", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "is_meta_review": false, "RECOMMENDATION": 4, "APPROPRIATENESS": 4, "IS_META_REVIEW": false}, {"IS_META_REVIEW": false, "SOUNDNESS_CORRECTNESS": 4, "is_meta_review": false, "comments": "\"First, it allows us to assess whether auto-regressive models are able to match the GAN results of Reed et al. (2016a).\" Does it, though? Because the resolution is so bad. And resolution limitations a", "MEANINGFUL_COMPARISON": 3}, {"IMPACT": 4, "comments": "This work focuses on conditional image synthesis in the autoregressive framework. Based on PixelCNN, it trains models that condition on text as well as segmentation masks or keypoints. Experiments sho", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 2, "is_meta_review": false, "CLARITY": 3, "IS_META_REVIEW": false}], "authors": "Scott Reed, A\u00e4ron van den Oord, Nal Kalchbrenner, Victor Bapst, Matt Botvinick, Nando de Freitas", "accepted": false, "id": "520"}