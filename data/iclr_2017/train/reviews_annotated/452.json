{"conference": "ICLR 2017 conference submission", "title": "Learning to Repeat: Fine Grained Action Repetition for Deep Reinforcement Learning", "abstract": "Reinforcement Learning algorithms can learn complex behavioral patterns for sequential decision making tasks wherein an agent interacts with an environment and acquires feedback in the form of rewards sampled from it. Traditionally, such algorithms make decisions, i.e., select actions to execute, at every single time step of the agent-environment interactions. In this paper, we propose a novel framework, Fine Grained Action Repetition (FiGAR), which enables the agent to decide the action as well as the time scale of repeating it. FiGAR can be used for improving any Deep Reinforcement Learning algorithm which maintains an explicit policy estimate  by enabling temporal abstractions in the action space and implicitly enabling planning through sequences of repetitive macro-actions.   We empirically demonstrate the efficacy of our framework by showing performance improvements on top of three policy search algorithms in different domains: Asynchronous Advantage Actor Critic in the Atari 2600 domain, Trust Region Policy Optimization in Mujoco domain and Deep Deterministic Policy Gradients in the TORCS car racing domain.", "histories": [], "reviews": [{"CLARITY": 4, "is_meta_review": false, "comments": "This paper provides a simple method to handle action repetitions. They make the action a tuple (a,x), where a is the action chosen, and x the number of repetitions. Overall they report some improvemen", "IS_META_REVIEW": false}, {"IMPACT": 5, "comments": "This paper shows that extending deep RL algorithms to decide which action to take as well as how many times to repeat it leads to improved performance on a number of domains. The evaluation is very th", "SOUNDNESS_CORRECTNESS": 5, "IS_META_REVIEW": false, "RECOMMENDATION": 5, "is_meta_review": false}, {"comments": "This paper proposes a simple but effective extension to reinforcement learning algorithms, by adding a temporal repetition component as part of the action space, enabling the policy to select how long", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "IS_META_REVIEW": false, "CLARITY": 5, "is_meta_review": false}], "authors": "Sahil Sharma, Aravind S. Lakshminarayanan, Balaraman Ravindran", "accepted": true, "id": "452"}