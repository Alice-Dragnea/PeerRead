{"conference": "ICLR 2017 conference submission", "title": "Understanding intermediate layers using linear classifier probes", "abstract": "Neural network models have a reputation for being black boxes. We propose a new method to better understand the roles and dynamics of the intermediate layers. This has direct consequences on the design of such models and it enables the expert to be able to justify certain heuristics (such as adding auxiliary losses in middle layers). Our method uses linear classifiers, referred to as ``probes'', where a probe can only use the hidden units of a given intermediate layer as discriminating features. Moreover, these probes cannot affect the training phase of a model, and they are generally added after training. They allow the user to visualize the state of the model at multiple steps of training. We demonstrate how this can be used to develop a better intuition about models and to diagnose potential problems.", "histories": [], "reviews": [{"IMPACT": 3, "SUBSTANCE": 3, "comments": "The authors propose a method to investigate the predictiveness of intermediate layer activations. To do so, they propose training linear classifiers and evaluate the error on the test set. The paper i", "SOUNDNESS_CORRECTNESS": 4, "ORIGINALITY": 4, "is_meta_review": false, "IS_META_REVIEW": false}, {"ORIGINALITY": 3, "is_meta_review": false, "comments": "This paper proposes to use a linear classifier as the probe for the informativeness of the hidden activations from different neural network layers. The training of the linear classifier does not affec", "IS_META_REVIEW": false}, {"ORIGINALITY": 3, "IS_META_REVIEW": false, "is_meta_review": false, "comments": "This paper proposes a method that attempts to \"understand\" what is happening within a neural network by using linear classifier probes which are inserted at various levels of the network. I think the ", "RECOMMENDATION": 2}], "authors": "Guillaume Alain, Yoshua Bengio", "accepted": false, "id": "577"}