{"conference": "ICLR 2017 conference submission", "title": "Learning Continuous Semantic Representations of Symbolic Expressions", "abstract": "The question of how procedural knowledge is represented and inferred is a fundamental problem in machine learning and artificial intelligence. Recent work on program induction has proposed neural architectures, based on abstractions like stacks, Turing machines, and interpreters,  that operate on abstract computational machines or on execution traces. But the recursive abstraction that is central to procedural knowledge is perhaps most naturally represented by symbolic representations that have syntactic structure, such as logical expressions and source code. Combining abstract, symbolic reasoning with continuous neural reasoning is a grand challenge of representation learning. As a step in this direction, we propose a new architecture, called neural equivalence networks, for the problem of learning continuous semantic representations of mathematical and logical expressions. These networks are trained to represent semantic equivalence, even of expressions that are syntactically very different. The challenge is that semantic representations must be computed in a syntax-directed manner, because semantics is compositional, but at the same time, small changes in syntax can lead to very large changes in semantics, which can be difficult for continuous neural architectures. We perform an exhaustive evaluation  on the task of checking equivalence on a highly diverse class of symbolic algebraic and boolean expression types, showing that our model significantly outperforms existing architectures.", "histories": [], "reviews": [{"SUBSTANCE": 3, "comments": "The goal of this paper is to learn vector representation of boolean and polynomial expressions, such that equivalent expressions have similar representations. The model proposed in the paper is based ", "SOUNDNESS_CORRECTNESS": 5, "IS_META_REVIEW": false, "CLARITY": 4, "is_meta_review": false}, {"is_meta_review": false, "comments": "This work proposes to compute embeddings of symbolic expressions (e.g., boolean expressions, or polynomials) such that semantically equivalent expressions are near each other in the embedded space. Th", "IS_META_REVIEW": false}, {"IS_META_REVIEW": false, "is_meta_review": false, "comments": "The authors propose a new model to learn symbolic expression representations. They do a reasonably extensive evaluation with similar approaches and motivate their approach well. As expressed in the pr", "SOUNDNESS_CORRECTNESS": 4}], "authors": "Miltiadis Allamanis, Pankajan Chanthirasegaran, Pushmeet Kohli, Charles Sutton", "accepted": false, "id": "538"}