{"conference": "ICLR 2017 conference submission", "title": "Vocabulary Selection Strategies for Neural Machine Translation", "abstract": "Classical translation models constrain the space of possible outputs by selecting a subset of translation rules based on the input sentence. Recent work on improving the efficiency of neural translation models adopted a similar strategy by restricting the output vocabulary to a subset of likely candidates given the source. In this paper we experiment with context and embedding-based selection methods and extend previous work by examining speed and accuracy trade-offs in more detail. We show that decoding time on CPUs can be reduced by up to 90% and training time by 25% on the WMT15 English-German and WMT16 English-Romanian tasks at the same or only negligible change in accuracy. This brings the time to decode with a state of the art neural translation system to just over 140 words per seconds on a single CPU core for English-German.", "histories": [], "reviews": [{"IMPACT": 5, "comments": "In this paper, the authors present several strategies to select a small subset of target vocabulary to work with per source sentence, which results in significant speedup. The results are convincing a", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 3, "is_meta_review": false, "RECOMMENDATION": 2, "APPROPRIATENESS": 2, "IS_META_REVIEW": false}, {"IMPACT": 3, "SUBSTANCE": 4, "comments": "This paper compares several strategies for guessing a short list of vocabulary for the target language in neural machine translation. The primary findings are that word alignment dictionaries work bet", "SOUNDNESS_CORRECTNESS": 5, "IS_META_REVIEW": false, "is_meta_review": false}, {"SUBSTANCE": 4, "comments": "This paper conducts a comprehensive series of experiments on vocabulary selection strategies to reduce the computational cost of neural machine translation. A range of techniques are investigated, ran", "SOUNDNESS_CORRECTNESS": 5, "ORIGINALITY": 2, "IS_META_REVIEW": false, "is_meta_review": false}, {"APPROPRIATENESS": 2, "is_meta_review": false, "comments": "This paper evaluates several strategies to reduce output vocabulary size in order to speed up NMT decoding and training. It could be quite useful to practitioners, although the main contributions of t", "IS_META_REVIEW": false}], "authors": "Gurvan L'Hostis, David Grangier, Michael Auli", "accepted": false, "id": "779"}