{"conference": "ICLR 2017 conference submission", "title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks", "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.", "histories": [], "reviews": [{"CLARITY": 2, "is_meta_review": false, "comments": "The paper address the problem of detecting if an example is misclassified or out-of-distribution. This is an very important topic and the study provides a good baseline. Although it misses strong nove", "IS_META_REVIEW": false}, {"is_meta_review": false, "comments": "The authors present results on a number of different tasks where the goal is to determine whether a given test example is out-of-domain or likely to be mis-classified. This is accomplished by examinin", "IS_META_REVIEW": false}, {"is_meta_review": false, "comments": "The authors propose the use of statistics of softmax outputs to estimate the probability of error and probability of a test sample being out-of-domain. They contrast the performance of the proposed me", "IS_META_REVIEW": false}], "authors": "Dan Hendrycks, Kevin Gimpel", "accepted": true, "id": "410"}