{"conference": "ICLR 2017 conference submission", "title": "Extrapolation and learning equations", "abstract": "In classical machine learning, regression is treated as a black box process of identifying a suitable function from a hypothesis set without attempting to gain insight into the mechanism connecting inputs and  outputs. In the natural sciences, however, finding an interpretable function for a phenomenon is the prime goal as it allows to understand and  generalize results. This paper proposes a novel type of function learning network, called equation learner (EQL), that can learn analytical expressions and is able to extrapolate to unseen domains. It is implemented as an end-to-end differentiable feed-forward network and allows for efficient gradient based training. Due to sparsity regularization concise interpretable expressions can be obtained. Often the true underlying source expression is identified.", "histories": [], "reviews": [{"IMPACT": 5, "MEANINGFUL_COMPARISON": 1, "comments": "The authors attempt to extract analytical equations governing physical systems from observations - an important task. Being able to capture succinct and interpretable rules which a physical system fol", "SOUNDNESS_CORRECTNESS": 2, "ORIGINALITY": 2, "is_meta_review": false, "IS_META_REVIEW": false}, {"ORIGINALITY": 5, "is_meta_review": false, "comments": "Thank you for an interesting read. To my knowledge, very few papers have looked at transfer learning with **no** target domain data (the authors called this task as \"extrapolation\"). This paper clearl", "IS_META_REVIEW": false}, {"ORIGINALITY": 4, "is_meta_review": false, "comments": "Thank you for an interesting perspective on the neural approaches to approximate physical phenomenon. This paper describes a method to extrapolate a given dataset and predict formulae with naturally o", "IS_META_REVIEW": false}], "authors": "Georg Martius, Christoph H. Lampert", "accepted": false, "id": "546"}