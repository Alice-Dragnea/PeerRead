{"conference": "ICLR 2017 conference submission", "title": "Inference and Introspection in Deep Generative Models of Sparse Data", "abstract": "Deep generative models such as deep latent Gaussian models (DLGMs) are powerful and popular density estimators. However, they have been applied almost exclusively to dense data such as images; DLGMs are rarely applied to sparse, high-dimensional integer data such as word counts or product ratings. One reason is that the standard training procedures find poor local optima when applied to such data. We propose two techniques that alleviate this problem, significantly improving our ability to fit DLGMs to sparse, high-dimensional data. Having fit these models, we are faced with another challenge: how to use and interpret the representation that we have learned? To that end, we propose a method that extracts distributed representations of features via a simple linearization of the model.", "histories": [], "reviews": [{"SUBSTANCE": 3, "comments": "This paper presents a small trick to improve the model quality of variational autoencoders (further optimizing the ELBO while initializing it from the predictions of the q network, instead of just usi", "SOUNDNESS_CORRECTNESS": 3, "ORIGINALITY": 3, "IS_META_REVIEW": false, "is_meta_review": false}, {"CLARITY": 3, "is_meta_review": false, "comments": "This paper introduces three tricks for training deep latent variable models on sparse discrete data: 1) tf-idf weighting 2) Iteratively optimizing variational parameters after initializing them with a", "IS_META_REVIEW": false}, {"CLARITY": 3, "is_meta_review": false, "comments": "The paper claims improved inference for density estimation of sparse data (here text documents) using deep generative Gaussian models (variational auto-encoders), and a method for deriving word embedd", "IS_META_REVIEW": false}, {"ORIGINALITY": 4, "CLARITY": 5, "is_meta_review": false, "comments": "First I would like to apologize for the delay in reviewing. Summary : In this paper a variational inference is adapted to deep generative models, showing improvement for non-negative sparse dataset. T", "IS_META_REVIEW": false}], "authors": "Rahul G. Krishnan, Matthew Hoffman", "accepted": false, "id": "595"}